{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5cd6c6cc-0ff8-43c6-9cd2-60136300e1f9",
   "metadata": {},
   "source": [
    "# _Deep Learning - Artificial Neural Networks / Derin Öğrenme - Yapay Sinir Ağları_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9266bb7e-c62f-4709-9171-b5603a60dc42",
   "metadata": {},
   "source": [
    "_Bugün insan beyninin öğrenme modelini taklit ederek öğrenen yapay sinir ağlarını derinlemesini öğreneceğiz._"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1619c4d4-d43f-46d6-8489-6310cef80246",
   "metadata": {},
   "source": [
    "#### _Classification_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a626c9c4-6397-45f1-82d6-08dc45d594ab",
   "metadata": {},
   "source": [
    "_Cevabu evet hayır olan sorular = classifition_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "76f87073-6898-441d-a79a-54a101d034cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "# pandas: veri işleme ve analiz kütüphanesi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b5d78bea-2e64-45bf-b4ed-4c8571812722",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('pima-indians-diabetes.csv')\n",
    "# CSV dosyasını okur ve df adlı DataFrame’e aktarır"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "56fd2658-c80b-49a6-be37-9ec1c937020e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pregnancies</th>\n",
       "      <th>Glucose</th>\n",
       "      <th>BloodPressure</th>\n",
       "      <th>SkinThickness</th>\n",
       "      <th>Insulin</th>\n",
       "      <th>BMI</th>\n",
       "      <th>DiabetesPedigreeFunction</th>\n",
       "      <th>Age</th>\n",
       "      <th>Outcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>148</td>\n",
       "      <td>72</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>33.6</td>\n",
       "      <td>0.627</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>85</td>\n",
       "      <td>66</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>26.6</td>\n",
       "      <td>0.351</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>183</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23.3</td>\n",
       "      <td>0.672</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>89</td>\n",
       "      <td>66</td>\n",
       "      <td>23</td>\n",
       "      <td>94</td>\n",
       "      <td>28.1</td>\n",
       "      <td>0.167</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>137</td>\n",
       "      <td>40</td>\n",
       "      <td>35</td>\n",
       "      <td>168</td>\n",
       "      <td>43.1</td>\n",
       "      <td>2.288</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Pregnancies  Glucose  BloodPressure  SkinThickness  Insulin   BMI  \\\n",
       "0            6      148             72             35        0  33.6   \n",
       "1            1       85             66             29        0  26.6   \n",
       "2            8      183             64              0        0  23.3   \n",
       "3            1       89             66             23       94  28.1   \n",
       "4            0      137             40             35      168  43.1   \n",
       "\n",
       "   DiabetesPedigreeFunction  Age  Outcome  \n",
       "0                     0.627   50        1  \n",
       "1                     0.351   31        0  \n",
       "2                     0.672   32        1  \n",
       "3                     0.167   21        0  \n",
       "4                     2.288   33        1  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()\n",
    "# DataFrame’in ilk 5 satırını gösterir (veriyi tanımak için kullanılır)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "169fc860-3aa9-451f-a951-bdb710b93ab6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(768, 9)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape\n",
    "# Veri kümesinin satır ve sütun sayısını gösterir (ör: (768, 9))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ad5439f1-4a8b-4728-b2b3-be71831b38be",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pregnancies                 0\n",
       "Glucose                     0\n",
       "BloodPressure               0\n",
       "SkinThickness               0\n",
       "Insulin                     0\n",
       "BMI                         0\n",
       "DiabetesPedigreeFunction    0\n",
       "Age                         0\n",
       "Outcome                     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()\n",
    "# Her sütunda kaç adet eksik veri (NaN) olduğunu gösterir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e8059e8e-e019-479d-90b4-e576948813a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "eb8c96bf-aaa7-4339-aca3-83657ac10cc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TensorFlow kütüphanesini yüklemek için terminal komutu\n",
    "# Tensor: çok boyutlu matris demektir (vektör, matris veya yüksek boyutlu dizi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d46c2ec6-d30c-422f-bc1d-7c76a61b0236",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pregnancies</th>\n",
       "      <th>Glucose</th>\n",
       "      <th>BloodPressure</th>\n",
       "      <th>SkinThickness</th>\n",
       "      <th>Insulin</th>\n",
       "      <th>BMI</th>\n",
       "      <th>DiabetesPedigreeFunction</th>\n",
       "      <th>Age</th>\n",
       "      <th>Outcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>148</td>\n",
       "      <td>72</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>33.6</td>\n",
       "      <td>0.627</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>85</td>\n",
       "      <td>66</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>26.6</td>\n",
       "      <td>0.351</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>183</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23.3</td>\n",
       "      <td>0.672</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>89</td>\n",
       "      <td>66</td>\n",
       "      <td>23</td>\n",
       "      <td>94</td>\n",
       "      <td>28.1</td>\n",
       "      <td>0.167</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>137</td>\n",
       "      <td>40</td>\n",
       "      <td>35</td>\n",
       "      <td>168</td>\n",
       "      <td>43.1</td>\n",
       "      <td>2.288</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Pregnancies  Glucose  BloodPressure  SkinThickness  Insulin   BMI  \\\n",
       "0            6      148             72             35        0  33.6   \n",
       "1            1       85             66             29        0  26.6   \n",
       "2            8      183             64              0        0  23.3   \n",
       "3            1       89             66             23       94  28.1   \n",
       "4            0      137             40             35      168  43.1   \n",
       "\n",
       "   DiabetesPedigreeFunction  Age  Outcome  \n",
       "0                     0.627   50        1  \n",
       "1                     0.351   31        0  \n",
       "2                     0.672   32        1  \n",
       "3                     0.167   21        0  \n",
       "4                     2.288   33        1  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()\n",
    "# DataFrame’in ilk 5 satırını gösterir (veriyi tanımak için kullanılır)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fe3eb706-e7db-4227-a426-08f94dd9f5c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Pregnancies', 'Glucose', 'BloodPressure', 'SkinThickness', 'Insulin',\n",
       "       'BMI', 'DiabetesPedigreeFunction', 'Age', 'Outcome'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns\n",
    "# DataFrame’deki sütun isimlerini listeler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a472c76-982b-4ef4-80c1-3a2a6fab3815",
   "metadata": {},
   "source": [
    "##### _Yöntem 1_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cbf9db16-798d-4206-aa3c-2c0d6ac13022",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df[['Pregnancies', 'Glucose', 'BloodPressure', 'SkinThickness', \n",
    "        'Insulin', 'BMI', 'DiabetesPedigreeFunction', 'Age']]\n",
    "# Bağımsız değişkenler (girdiler): modelin tahmin için kullanacağı özellikler\n",
    "\n",
    "y = df[['Outcome']]\n",
    "# Bağımlı değişken (çıktı): diyabet olup olmama (0 = hayır, 1 = evet)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30c0507b-f9d7-4daa-93f2-b00f958139b1",
   "metadata": {},
   "source": [
    "##### _Yöntem 2_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7b2af632-86e2-44ca-a551-8b06490ddd2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df.drop('Outcome', axis=1)\n",
    "# 'Outcome' sütununu kaldırır, geri kalan tüm sütunlar X (bağımsız değişkenler) olur\n",
    "\n",
    "y = df[['Outcome']]\n",
    "# 'Outcome' sütunu Y (bağımlı değişken) olarak alınır"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "da2eb88b-bb4e-4cbe-b0cd-f7238a8a5748",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pregnancies</th>\n",
       "      <th>Glucose</th>\n",
       "      <th>BloodPressure</th>\n",
       "      <th>SkinThickness</th>\n",
       "      <th>Insulin</th>\n",
       "      <th>BMI</th>\n",
       "      <th>DiabetesPedigreeFunction</th>\n",
       "      <th>Age</th>\n",
       "      <th>Outcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>148</td>\n",
       "      <td>72</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>33.6</td>\n",
       "      <td>0.627</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>85</td>\n",
       "      <td>66</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>26.6</td>\n",
       "      <td>0.351</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>183</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23.3</td>\n",
       "      <td>0.672</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>89</td>\n",
       "      <td>66</td>\n",
       "      <td>23</td>\n",
       "      <td>94</td>\n",
       "      <td>28.1</td>\n",
       "      <td>0.167</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>137</td>\n",
       "      <td>40</td>\n",
       "      <td>35</td>\n",
       "      <td>168</td>\n",
       "      <td>43.1</td>\n",
       "      <td>2.288</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Pregnancies  Glucose  BloodPressure  SkinThickness  Insulin   BMI  \\\n",
       "0            6      148             72             35        0  33.6   \n",
       "1            1       85             66             29        0  26.6   \n",
       "2            8      183             64              0        0  23.3   \n",
       "3            1       89             66             23       94  28.1   \n",
       "4            0      137             40             35      168  43.1   \n",
       "\n",
       "   DiabetesPedigreeFunction  Age  Outcome  \n",
       "0                     0.627   50        1  \n",
       "1                     0.351   31        0  \n",
       "2                     0.672   32        1  \n",
       "3                     0.167   21        0  \n",
       "4                     2.288   33        1  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()\n",
    "# Veri kümesinin ilk 5 satırını yeniden gösterir"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d4f8b30-a2d1-45c2-a3c9-207dc6c226c3",
   "metadata": {},
   "source": [
    "##### _Yöntem 3_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "15fad276-96a8-428a-b6fb-c5a4fcb066c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df.iloc[:, 0:8]\n",
    "# iloc: konuma göre seçim yapar\n",
    "# 0. sütundan başlayıp 8. sütuna kadar (8 dahil değil) olanları X'e atar\n",
    "\n",
    "y = df.iloc[:, 8]\n",
    "# 8. sütunu (Outcome) Y'ye atar\n",
    "\n",
    "# iloc = \"şurdan başla, şuraya kadar git\" mantığıyla çalışır"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ab855a9-dadb-4fc1-b969-844af30d3698",
   "metadata": {},
   "source": [
    "##### _Neural Network Modeli_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6cfa04d9-dd4e-42fa-b15c-345decdf2857",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "# Sequential: katmanları sırayla ekleyerek model kurmamızı sağlar\n",
    "\n",
    "from tensorflow.keras.layers import Dense\n",
    "# Dense: tam bağlantılı (fully connected) yapay sinir ağı katmanı"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "415f3245-3e16-4068-b80c-7960974a4901",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "# Boş bir yapay sinir ağı (ANN) modeli oluşturur\n",
    "\n",
    "model.add(Dense(80, activation='relu'))\n",
    "# İlk gizli katman: 80 nöron (tamamen varsayımsal, hiçbir dayanak yok, hayal ürünü), aktivasyon: ReLU\n",
    "\n",
    "model.add(Dense(120, activation='relu'))\n",
    "# İkinci gizli katman: 120 nöron, öğrenme kapasitesini artırır\n",
    "\n",
    "model.add(Dense(80, activation='relu'))\n",
    "# Üçüncü gizli katman: tekrar 80 nöron\n",
    "\n",
    "model.add(Dense(30, activation='relu'))\n",
    "# Dördüncü gizli katman: 30 nöron (boyut küçülüyor, derinlikten yüzeye iniyoruz)\n",
    "\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "# Çıkış katmanı: 1 nöron (binary classification için zorunlu)\n",
    "# Sigmoid: 0 ile 1 arasında olasılık üretir (diyabet var/yok)\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "# loss = binary_crossentropy: iki sınıflı problemler için uygun\n",
    "# optimizer = adam: en sık kullanılan optimizasyon algoritması\n",
    "# metrics = accuracy: doğruluk ölçüsü hesaplanır\n",
    "\n",
    "# Dense: tüm nöronlar bir önceki katmandaki tüm nöronlara bağlanır (fully connected)\n",
    "# Bir katmanın çıktısı bir sonraki katmanın girdisi olur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "817a3e05-f3f7-4574-bddb-acbfaa47a552",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "22/22 - 12s - 539ms/step - accuracy: 0.5774 - loss: 1.2298 - val_accuracy: 0.6753 - val_loss: 0.6248\n",
      "Epoch 2/1000\n",
      "22/22 - 0s - 4ms/step - accuracy: 0.6310 - loss: 0.8416 - val_accuracy: 0.5584 - val_loss: 0.7586\n",
      "Epoch 3/1000\n",
      "22/22 - 0s - 4ms/step - accuracy: 0.6469 - loss: 0.7298 - val_accuracy: 0.6883 - val_loss: 0.6806\n",
      "Epoch 4/1000\n",
      "22/22 - 0s - 4ms/step - accuracy: 0.6700 - loss: 0.6169 - val_accuracy: 0.5844 - val_loss: 0.7904\n",
      "Epoch 5/1000\n",
      "22/22 - 0s - 4ms/step - accuracy: 0.6845 - loss: 0.6453 - val_accuracy: 0.6753 - val_loss: 0.6438\n",
      "Epoch 6/1000\n",
      "22/22 - 0s - 4ms/step - accuracy: 0.6614 - loss: 0.6351 - val_accuracy: 0.6234 - val_loss: 0.7240\n",
      "Epoch 7/1000\n",
      "22/22 - 0s - 4ms/step - accuracy: 0.7091 - loss: 0.5920 - val_accuracy: 0.6364 - val_loss: 0.6746\n",
      "Epoch 8/1000\n",
      "22/22 - 0s - 4ms/step - accuracy: 0.6918 - loss: 0.6501 - val_accuracy: 0.6364 - val_loss: 0.7754\n",
      "Epoch 9/1000\n",
      "22/22 - 0s - 4ms/step - accuracy: 0.6903 - loss: 0.6549 - val_accuracy: 0.5714 - val_loss: 0.8764\n",
      "Epoch 10/1000\n",
      "22/22 - 0s - 4ms/step - accuracy: 0.7062 - loss: 0.5716 - val_accuracy: 0.5974 - val_loss: 0.7990\n",
      "Epoch 11/1000\n",
      "22/22 - 0s - 4ms/step - accuracy: 0.7120 - loss: 0.5818 - val_accuracy: 0.6104 - val_loss: 0.7306\n",
      "Epoch 12/1000\n",
      "22/22 - 0s - 6ms/step - accuracy: 0.6860 - loss: 0.5971 - val_accuracy: 0.6623 - val_loss: 0.7147\n",
      "Epoch 13/1000\n",
      "22/22 - 0s - 5ms/step - accuracy: 0.7106 - loss: 0.5753 - val_accuracy: 0.6234 - val_loss: 0.7138\n",
      "Epoch 14/1000\n",
      "22/22 - 0s - 4ms/step - accuracy: 0.7207 - loss: 0.5418 - val_accuracy: 0.6883 - val_loss: 0.6876\n",
      "Epoch 15/1000\n",
      "22/22 - 0s - 4ms/step - accuracy: 0.7279 - loss: 0.5543 - val_accuracy: 0.5974 - val_loss: 0.7370\n",
      "Epoch 16/1000\n",
      "22/22 - 0s - 4ms/step - accuracy: 0.7279 - loss: 0.5372 - val_accuracy: 0.6753 - val_loss: 0.7182\n",
      "Epoch 17/1000\n",
      "22/22 - 0s - 4ms/step - accuracy: 0.7062 - loss: 0.5926 - val_accuracy: 0.5325 - val_loss: 0.7905\n",
      "Epoch 18/1000\n",
      "22/22 - 0s - 4ms/step - accuracy: 0.7048 - loss: 0.5955 - val_accuracy: 0.6623 - val_loss: 0.6810\n",
      "Epoch 19/1000\n",
      "22/22 - 0s - 4ms/step - accuracy: 0.6773 - loss: 0.6397 - val_accuracy: 0.5584 - val_loss: 0.7731\n",
      "Epoch 20/1000\n",
      "22/22 - 0s - 4ms/step - accuracy: 0.7004 - loss: 0.5849 - val_accuracy: 0.7013 - val_loss: 0.6494\n",
      "Epoch 21/1000\n",
      "22/22 - 0s - 4ms/step - accuracy: 0.7438 - loss: 0.5361 - val_accuracy: 0.6623 - val_loss: 0.6736\n",
      "Epoch 22/1000\n",
      "22/22 - 0s - 4ms/step - accuracy: 0.7164 - loss: 0.5416 - val_accuracy: 0.6494 - val_loss: 0.6763\n",
      "Epoch 23/1000\n",
      "22/22 - 0s - 5ms/step - accuracy: 0.7192 - loss: 0.5434 - val_accuracy: 0.6753 - val_loss: 0.7103\n",
      "Epoch 24/1000\n",
      "22/22 - 0s - 4ms/step - accuracy: 0.7207 - loss: 0.5835 - val_accuracy: 0.6364 - val_loss: 0.6967\n",
      "Epoch 25/1000\n",
      "22/22 - 0s - 4ms/step - accuracy: 0.7164 - loss: 0.5633 - val_accuracy: 0.6364 - val_loss: 0.7783\n",
      "Epoch 26/1000\n",
      "22/22 - 0s - 4ms/step - accuracy: 0.7453 - loss: 0.5331 - val_accuracy: 0.6104 - val_loss: 0.8143\n",
      "Epoch 27/1000\n",
      "22/22 - 0s - 4ms/step - accuracy: 0.7250 - loss: 0.5698 - val_accuracy: 0.6234 - val_loss: 0.8222\n",
      "Epoch 28/1000\n",
      "22/22 - 0s - 4ms/step - accuracy: 0.7221 - loss: 0.5439 - val_accuracy: 0.6883 - val_loss: 0.6861\n",
      "Epoch 29/1000\n",
      "22/22 - 0s - 4ms/step - accuracy: 0.7207 - loss: 0.5267 - val_accuracy: 0.6364 - val_loss: 0.7204\n",
      "Epoch 30/1000\n",
      "22/22 - 0s - 4ms/step - accuracy: 0.7294 - loss: 0.5392 - val_accuracy: 0.6234 - val_loss: 0.8181\n",
      "Epoch 31/1000\n",
      "22/22 - 0s - 4ms/step - accuracy: 0.7004 - loss: 0.6465 - val_accuracy: 0.5844 - val_loss: 0.8703\n",
      "Epoch 32/1000\n",
      "22/22 - 0s - 5ms/step - accuracy: 0.7279 - loss: 0.5616 - val_accuracy: 0.6883 - val_loss: 0.6700\n",
      "Epoch 33/1000\n",
      "22/22 - 0s - 4ms/step - accuracy: 0.7467 - loss: 0.5278 - val_accuracy: 0.6234 - val_loss: 0.7502\n",
      "Epoch 34/1000\n",
      "22/22 - 0s - 4ms/step - accuracy: 0.7424 - loss: 0.5335 - val_accuracy: 0.5844 - val_loss: 0.8318\n",
      "Epoch 35/1000\n",
      "22/22 - 0s - 4ms/step - accuracy: 0.7279 - loss: 0.5449 - val_accuracy: 0.5714 - val_loss: 0.7528\n",
      "Epoch 36/1000\n",
      "22/22 - 0s - 4ms/step - accuracy: 0.7525 - loss: 0.5306 - val_accuracy: 0.5714 - val_loss: 0.8244\n",
      "Epoch 37/1000\n",
      "22/22 - 0s - 4ms/step - accuracy: 0.7294 - loss: 0.5318 - val_accuracy: 0.5844 - val_loss: 0.7674\n",
      "Epoch 38/1000\n",
      "22/22 - 0s - 4ms/step - accuracy: 0.7496 - loss: 0.5080 - val_accuracy: 0.6364 - val_loss: 0.6943\n",
      "Epoch 39/1000\n",
      "22/22 - 0s - 4ms/step - accuracy: 0.7511 - loss: 0.5002 - val_accuracy: 0.6494 - val_loss: 0.6721\n",
      "Epoch 40/1000\n",
      "22/22 - 0s - 6ms/step - accuracy: 0.7598 - loss: 0.5033 - val_accuracy: 0.6104 - val_loss: 0.7536\n",
      "Epoch 41/1000\n",
      "22/22 - 0s - 4ms/step - accuracy: 0.7438 - loss: 0.5144 - val_accuracy: 0.6623 - val_loss: 0.6968\n",
      "Epoch 42/1000\n",
      "22/22 - 0s - 4ms/step - accuracy: 0.7395 - loss: 0.5161 - val_accuracy: 0.6364 - val_loss: 0.6995\n",
      "Epoch 43/1000\n",
      "22/22 - 0s - 5ms/step - accuracy: 0.7438 - loss: 0.5108 - val_accuracy: 0.6104 - val_loss: 0.7306\n",
      "Epoch 44/1000\n",
      "22/22 - 0s - 4ms/step - accuracy: 0.7540 - loss: 0.5289 - val_accuracy: 0.6104 - val_loss: 0.7685\n",
      "Epoch 45/1000\n",
      "22/22 - 0s - 4ms/step - accuracy: 0.7583 - loss: 0.5163 - val_accuracy: 0.6234 - val_loss: 0.6904\n",
      "Epoch 46/1000\n",
      "22/22 - 0s - 4ms/step - accuracy: 0.7511 - loss: 0.4941 - val_accuracy: 0.6753 - val_loss: 0.6543\n",
      "Epoch 47/1000\n",
      "22/22 - 0s - 4ms/step - accuracy: 0.7482 - loss: 0.5053 - val_accuracy: 0.7143 - val_loss: 0.6237\n",
      "Epoch 48/1000\n",
      "22/22 - 0s - 4ms/step - accuracy: 0.7352 - loss: 0.5438 - val_accuracy: 0.5195 - val_loss: 0.7329\n",
      "Epoch 49/1000\n",
      "22/22 - 0s - 4ms/step - accuracy: 0.7308 - loss: 0.5224 - val_accuracy: 0.7013 - val_loss: 0.6220\n",
      "Epoch 50/1000\n",
      "22/22 - 0s - 4ms/step - accuracy: 0.7554 - loss: 0.4925 - val_accuracy: 0.7013 - val_loss: 0.6626\n",
      "Epoch 51/1000\n",
      "22/22 - 0s - 4ms/step - accuracy: 0.7496 - loss: 0.4811 - val_accuracy: 0.6753 - val_loss: 0.6951\n",
      "Epoch 52/1000\n",
      "22/22 - 0s - 4ms/step - accuracy: 0.7656 - loss: 0.4876 - val_accuracy: 0.6883 - val_loss: 0.6297\n",
      "Epoch 53/1000\n",
      "22/22 - 0s - 4ms/step - accuracy: 0.7583 - loss: 0.4856 - val_accuracy: 0.7013 - val_loss: 0.6771\n",
      "Epoch 54/1000\n",
      "22/22 - 0s - 4ms/step - accuracy: 0.7612 - loss: 0.4957 - val_accuracy: 0.6883 - val_loss: 0.6778\n",
      "Epoch 55/1000\n",
      "22/22 - 0s - 4ms/step - accuracy: 0.7525 - loss: 0.4797 - val_accuracy: 0.6494 - val_loss: 0.6486\n",
      "Epoch 56/1000\n",
      "22/22 - 0s - 4ms/step - accuracy: 0.7496 - loss: 0.5022 - val_accuracy: 0.6364 - val_loss: 0.7276\n",
      "Epoch 57/1000\n",
      "22/22 - 0s - 6ms/step - accuracy: 0.7627 - loss: 0.4830 - val_accuracy: 0.6623 - val_loss: 0.7387\n",
      "Epoch 58/1000\n",
      "22/22 - 0s - 4ms/step - accuracy: 0.7641 - loss: 0.4717 - val_accuracy: 0.6364 - val_loss: 0.7680\n",
      "Epoch 59/1000\n",
      "22/22 - 0s - 4ms/step - accuracy: 0.7728 - loss: 0.4822 - val_accuracy: 0.6883 - val_loss: 0.6402\n",
      "Epoch 60/1000\n",
      "22/22 - 0s - 4ms/step - accuracy: 0.7554 - loss: 0.4899 - val_accuracy: 0.7143 - val_loss: 0.6446\n",
      "Epoch 61/1000\n",
      "22/22 - 0s - 5ms/step - accuracy: 0.7670 - loss: 0.4809 - val_accuracy: 0.6364 - val_loss: 0.7218\n",
      "Epoch 62/1000\n",
      "22/22 - 0s - 5ms/step - accuracy: 0.7641 - loss: 0.4774 - val_accuracy: 0.7532 - val_loss: 0.6223\n",
      "Epoch 63/1000\n",
      "22/22 - 0s - 4ms/step - accuracy: 0.7699 - loss: 0.4649 - val_accuracy: 0.7143 - val_loss: 0.6434\n",
      "Epoch 64/1000\n",
      "22/22 - 0s - 4ms/step - accuracy: 0.7670 - loss: 0.4706 - val_accuracy: 0.6623 - val_loss: 0.7168\n",
      "Epoch 65/1000\n",
      "22/22 - 0s - 4ms/step - accuracy: 0.7685 - loss: 0.4767 - val_accuracy: 0.7273 - val_loss: 0.6345\n",
      "Epoch 66/1000\n",
      "22/22 - 0s - 4ms/step - accuracy: 0.7554 - loss: 0.4918 - val_accuracy: 0.7143 - val_loss: 0.6021\n",
      "Epoch 67/1000\n",
      "22/22 - 0s - 4ms/step - accuracy: 0.7786 - loss: 0.4715 - val_accuracy: 0.7792 - val_loss: 0.6002\n",
      "Epoch 68/1000\n",
      "22/22 - 0s - 4ms/step - accuracy: 0.7656 - loss: 0.4783 - val_accuracy: 0.6883 - val_loss: 0.6588\n",
      "Epoch 69/1000\n",
      "22/22 - 0s - 4ms/step - accuracy: 0.7598 - loss: 0.4832 - val_accuracy: 0.7403 - val_loss: 0.6247\n",
      "Epoch 70/1000\n",
      "22/22 - 0s - 4ms/step - accuracy: 0.7902 - loss: 0.4604 - val_accuracy: 0.6883 - val_loss: 0.6349\n",
      "Epoch 71/1000\n",
      "22/22 - 0s - 4ms/step - accuracy: 0.7858 - loss: 0.4626 - val_accuracy: 0.7532 - val_loss: 0.6574\n",
      "Epoch 72/1000\n",
      "22/22 - 0s - 4ms/step - accuracy: 0.7742 - loss: 0.4695 - val_accuracy: 0.6623 - val_loss: 0.6745\n",
      "Epoch 73/1000\n",
      "22/22 - 0s - 4ms/step - accuracy: 0.7627 - loss: 0.4785 - val_accuracy: 0.6494 - val_loss: 0.7133\n",
      "Epoch 74/1000\n",
      "22/22 - 0s - 4ms/step - accuracy: 0.7540 - loss: 0.5101 - val_accuracy: 0.6494 - val_loss: 0.7581\n",
      "Epoch 75/1000\n",
      "22/22 - 0s - 4ms/step - accuracy: 0.7511 - loss: 0.5076 - val_accuracy: 0.7143 - val_loss: 0.6129\n",
      "Epoch 76/1000\n",
      "22/22 - 0s - 4ms/step - accuracy: 0.7467 - loss: 0.4897 - val_accuracy: 0.6883 - val_loss: 0.6529\n",
      "Epoch 77/1000\n",
      "22/22 - 0s - 5ms/step - accuracy: 0.7873 - loss: 0.4653 - val_accuracy: 0.7013 - val_loss: 0.6433\n",
      "Epoch 78/1000\n",
      "22/22 - 0s - 5ms/step - accuracy: 0.7916 - loss: 0.4418 - val_accuracy: 0.7273 - val_loss: 0.5820\n",
      "Epoch 79/1000\n",
      "22/22 - 0s - 4ms/step - accuracy: 0.7800 - loss: 0.4586 - val_accuracy: 0.7532 - val_loss: 0.6577\n",
      "Epoch 80/1000\n",
      "22/22 - 0s - 4ms/step - accuracy: 0.7699 - loss: 0.4693 - val_accuracy: 0.6623 - val_loss: 0.6627\n",
      "Epoch 81/1000\n",
      "22/22 - 0s - 4ms/step - accuracy: 0.7931 - loss: 0.4528 - val_accuracy: 0.7532 - val_loss: 0.6233\n",
      "Epoch 82/1000\n",
      "22/22 - 0s - 4ms/step - accuracy: 0.7858 - loss: 0.4508 - val_accuracy: 0.6753 - val_loss: 0.6720\n",
      "Epoch 83/1000\n",
      "22/22 - 0s - 4ms/step - accuracy: 0.7945 - loss: 0.4466 - val_accuracy: 0.7273 - val_loss: 0.6453\n",
      "Epoch 84/1000\n",
      "22/22 - 0s - 5ms/step - accuracy: 0.7656 - loss: 0.4599 - val_accuracy: 0.7403 - val_loss: 0.6328\n",
      "Epoch 85/1000\n",
      "22/22 - 0s - 4ms/step - accuracy: 0.7887 - loss: 0.4323 - val_accuracy: 0.7403 - val_loss: 0.6286\n",
      "Epoch 86/1000\n",
      "22/22 - 0s - 4ms/step - accuracy: 0.7931 - loss: 0.4362 - val_accuracy: 0.6753 - val_loss: 0.6666\n",
      "Epoch 87/1000\n",
      "22/22 - 0s - 4ms/step - accuracy: 0.7858 - loss: 0.4262 - val_accuracy: 0.6623 - val_loss: 0.6494\n",
      "Epoch 88/1000\n",
      "22/22 - 0s - 4ms/step - accuracy: 0.7815 - loss: 0.4531 - val_accuracy: 0.7143 - val_loss: 0.7748\n",
      "Epoch 89/1000\n",
      "22/22 - 0s - 4ms/step - accuracy: 0.7858 - loss: 0.4680 - val_accuracy: 0.7013 - val_loss: 0.6151\n",
      "Epoch 90/1000\n",
      "22/22 - 0s - 4ms/step - accuracy: 0.7988 - loss: 0.4405 - val_accuracy: 0.6623 - val_loss: 0.7244\n",
      "Epoch 91/1000\n",
      "22/22 - 0s - 4ms/step - accuracy: 0.7916 - loss: 0.4265 - val_accuracy: 0.7403 - val_loss: 0.6258\n",
      "Epoch 92/1000\n",
      "22/22 - 0s - 4ms/step - accuracy: 0.8032 - loss: 0.4317 - val_accuracy: 0.6623 - val_loss: 0.6977\n",
      "Epoch 93/1000\n",
      "22/22 - 0s - 4ms/step - accuracy: 0.7873 - loss: 0.4566 - val_accuracy: 0.7143 - val_loss: 0.6968\n",
      "Epoch 94/1000\n",
      "22/22 - 0s - 5ms/step - accuracy: 0.7699 - loss: 0.4543 - val_accuracy: 0.7273 - val_loss: 0.6398\n",
      "Epoch 95/1000\n",
      "22/22 - 0s - 4ms/step - accuracy: 0.7988 - loss: 0.4386 - val_accuracy: 0.7143 - val_loss: 0.6827\n",
      "Epoch 96/1000\n",
      "22/22 - 0s - 5ms/step - accuracy: 0.8003 - loss: 0.4215 - val_accuracy: 0.7403 - val_loss: 0.6545\n",
      "Epoch 97/1000\n",
      "22/22 - 0s - 4ms/step - accuracy: 0.7902 - loss: 0.4274 - val_accuracy: 0.7403 - val_loss: 0.6798\n",
      "Epoch 98/1000\n",
      "22/22 - 0s - 4ms/step - accuracy: 0.8061 - loss: 0.4277 - val_accuracy: 0.7013 - val_loss: 0.6311\n",
      "Epoch 99/1000\n",
      "22/22 - 0s - 4ms/step - accuracy: 0.8191 - loss: 0.4139 - val_accuracy: 0.7792 - val_loss: 0.5971\n",
      "Epoch 100/1000\n",
      "22/22 - 0s - 4ms/step - accuracy: 0.7873 - loss: 0.4157 - val_accuracy: 0.7013 - val_loss: 0.6734\n",
      "Epoch 101/1000\n",
      "22/22 - 0s - 4ms/step - accuracy: 0.8003 - loss: 0.4131 - val_accuracy: 0.7662 - val_loss: 0.6429\n",
      "Epoch 102/1000\n",
      "22/22 - 0s - 5ms/step - accuracy: 0.7959 - loss: 0.4252 - val_accuracy: 0.7273 - val_loss: 0.6112\n",
      "Epoch 103/1000\n",
      "22/22 - 0s - 5ms/step - accuracy: 0.7988 - loss: 0.4235 - val_accuracy: 0.7792 - val_loss: 0.5902\n",
      "Epoch 104/1000\n",
      "22/22 - 0s - 6ms/step - accuracy: 0.8133 - loss: 0.4092 - val_accuracy: 0.6883 - val_loss: 0.6681\n",
      "Epoch 105/1000\n",
      "22/22 - 0s - 5ms/step - accuracy: 0.8090 - loss: 0.4054 - val_accuracy: 0.7013 - val_loss: 0.6727\n",
      "Epoch 106/1000\n",
      "22/22 - 0s - 5ms/step - accuracy: 0.7829 - loss: 0.4319 - val_accuracy: 0.6753 - val_loss: 0.6412\n",
      "Epoch 107/1000\n",
      "22/22 - 0s - 4ms/step - accuracy: 0.7844 - loss: 0.4330 - val_accuracy: 0.7403 - val_loss: 0.6282\n",
      "Epoch 108/1000\n",
      "22/22 - 0s - 4ms/step - accuracy: 0.7959 - loss: 0.4286 - val_accuracy: 0.7143 - val_loss: 0.6104\n",
      "Epoch 109/1000\n",
      "22/22 - 0s - 5ms/step - accuracy: 0.8032 - loss: 0.4148 - val_accuracy: 0.7143 - val_loss: 0.6706\n",
      "Epoch 110/1000\n",
      "22/22 - 0s - 5ms/step - accuracy: 0.8090 - loss: 0.3979 - val_accuracy: 0.7662 - val_loss: 0.6260\n",
      "Epoch 111/1000\n",
      "22/22 - 0s - 4ms/step - accuracy: 0.8017 - loss: 0.4050 - val_accuracy: 0.7532 - val_loss: 0.7040\n",
      "Epoch 112/1000\n",
      "22/22 - 0s - 4ms/step - accuracy: 0.7902 - loss: 0.4403 - val_accuracy: 0.7273 - val_loss: 0.6457\n",
      "Epoch 113/1000\n",
      "22/22 - 0s - 4ms/step - accuracy: 0.8017 - loss: 0.4123 - val_accuracy: 0.6883 - val_loss: 0.6625\n",
      "Epoch 114/1000\n",
      "22/22 - 0s - 5ms/step - accuracy: 0.8061 - loss: 0.4086 - val_accuracy: 0.7273 - val_loss: 0.6518\n",
      "Epoch 115/1000\n",
      "22/22 - 0s - 5ms/step - accuracy: 0.8148 - loss: 0.3941 - val_accuracy: 0.6883 - val_loss: 0.6853\n",
      "Epoch 116/1000\n",
      "22/22 - 0s - 4ms/step - accuracy: 0.8061 - loss: 0.4053 - val_accuracy: 0.7532 - val_loss: 0.6352\n",
      "Epoch 117/1000\n",
      "22/22 - 0s - 4ms/step - accuracy: 0.8119 - loss: 0.3924 - val_accuracy: 0.7403 - val_loss: 0.7075\n",
      "Epoch 118/1000\n",
      "22/22 - 0s - 4ms/step - accuracy: 0.8090 - loss: 0.3996 - val_accuracy: 0.7662 - val_loss: 0.6296\n",
      "Epoch 119/1000\n",
      "22/22 - 0s - 4ms/step - accuracy: 0.8220 - loss: 0.4014 - val_accuracy: 0.7662 - val_loss: 0.7125\n",
      "Epoch 120/1000\n",
      "22/22 - 0s - 6ms/step - accuracy: 0.7931 - loss: 0.4207 - val_accuracy: 0.7013 - val_loss: 0.6511\n",
      "Epoch 121/1000\n",
      "22/22 - 0s - 7ms/step - accuracy: 0.8177 - loss: 0.3993 - val_accuracy: 0.6883 - val_loss: 0.7138\n",
      "Epoch 122/1000\n",
      "22/22 - 0s - 5ms/step - accuracy: 0.8003 - loss: 0.4028 - val_accuracy: 0.7532 - val_loss: 0.6970\n",
      "Epoch 123/1000\n",
      "22/22 - 0s - 4ms/step - accuracy: 0.8162 - loss: 0.4035 - val_accuracy: 0.7792 - val_loss: 0.6570\n",
      "Epoch 124/1000\n",
      "22/22 - 0s - 4ms/step - accuracy: 0.8220 - loss: 0.3893 - val_accuracy: 0.7403 - val_loss: 0.6701\n",
      "Epoch 125/1000\n",
      "22/22 - 0s - 4ms/step - accuracy: 0.8148 - loss: 0.3975 - val_accuracy: 0.6883 - val_loss: 0.7442\n",
      "Epoch 126/1000\n",
      "22/22 - 0s - 5ms/step - accuracy: 0.7916 - loss: 0.4186 - val_accuracy: 0.7532 - val_loss: 0.6362\n",
      "Epoch 127/1000\n",
      "22/22 - 0s - 5ms/step - accuracy: 0.7974 - loss: 0.4113 - val_accuracy: 0.7013 - val_loss: 0.8079\n",
      "Epoch 128/1000\n",
      "22/22 - 0s - 4ms/step - accuracy: 0.7959 - loss: 0.4030 - val_accuracy: 0.7922 - val_loss: 0.6275\n",
      "Epoch 129/1000\n",
      "22/22 - 0s - 5ms/step - accuracy: 0.8162 - loss: 0.3977 - val_accuracy: 0.7403 - val_loss: 0.6639\n",
      "Epoch 130/1000\n",
      "22/22 - 0s - 5ms/step - accuracy: 0.8249 - loss: 0.3937 - val_accuracy: 0.6883 - val_loss: 0.6933\n",
      "Epoch 131/1000\n",
      "22/22 - 0s - 4ms/step - accuracy: 0.8249 - loss: 0.3860 - val_accuracy: 0.7662 - val_loss: 0.6185\n",
      "Epoch 132/1000\n",
      "22/22 - 0s - 5ms/step - accuracy: 0.8090 - loss: 0.3847 - val_accuracy: 0.6883 - val_loss: 0.7139\n",
      "Epoch 133/1000\n",
      "22/22 - 0s - 6ms/step - accuracy: 0.8278 - loss: 0.3811 - val_accuracy: 0.6883 - val_loss: 0.6927\n",
      "Epoch 134/1000\n",
      "22/22 - 0s - 4ms/step - accuracy: 0.8104 - loss: 0.3952 - val_accuracy: 0.6494 - val_loss: 0.7806\n",
      "Epoch 135/1000\n",
      "22/22 - 0s - 4ms/step - accuracy: 0.7873 - loss: 0.4096 - val_accuracy: 0.7403 - val_loss: 0.6698\n",
      "Epoch 136/1000\n",
      "22/22 - 0s - 4ms/step - accuracy: 0.8017 - loss: 0.4041 - val_accuracy: 0.7143 - val_loss: 0.6709\n",
      "Epoch 137/1000\n",
      "22/22 - 0s - 5ms/step - accuracy: 0.8104 - loss: 0.3993 - val_accuracy: 0.7792 - val_loss: 0.6250\n",
      "Epoch 138/1000\n",
      "22/22 - 0s - 6ms/step - accuracy: 0.8249 - loss: 0.3587 - val_accuracy: 0.7532 - val_loss: 0.6173\n",
      "Epoch 139/1000\n",
      "22/22 - 0s - 5ms/step - accuracy: 0.8263 - loss: 0.3732 - val_accuracy: 0.7403 - val_loss: 0.6383\n",
      "Epoch 140/1000\n",
      "22/22 - 0s - 5ms/step - accuracy: 0.8394 - loss: 0.3626 - val_accuracy: 0.6753 - val_loss: 0.7594\n",
      "Epoch 141/1000\n",
      "22/22 - 0s - 5ms/step - accuracy: 0.8249 - loss: 0.3703 - val_accuracy: 0.7532 - val_loss: 0.6328\n",
      "Epoch 142/1000\n",
      "22/22 - 0s - 5ms/step - accuracy: 0.8350 - loss: 0.3571 - val_accuracy: 0.7792 - val_loss: 0.6606\n",
      "Epoch 143/1000\n",
      "22/22 - 0s - 6ms/step - accuracy: 0.8119 - loss: 0.3728 - val_accuracy: 0.6883 - val_loss: 0.7234\n",
      "Epoch 144/1000\n",
      "22/22 - 0s - 5ms/step - accuracy: 0.8249 - loss: 0.3700 - val_accuracy: 0.7403 - val_loss: 0.6926\n",
      "Epoch 145/1000\n",
      "22/22 - 0s - 4ms/step - accuracy: 0.8278 - loss: 0.3649 - val_accuracy: 0.7532 - val_loss: 0.6897\n",
      "Epoch 146/1000\n",
      "22/22 - 0s - 4ms/step - accuracy: 0.8379 - loss: 0.3637 - val_accuracy: 0.7792 - val_loss: 0.6133\n",
      "Epoch 147/1000\n",
      "22/22 - 0s - 4ms/step - accuracy: 0.8394 - loss: 0.3472 - val_accuracy: 0.7403 - val_loss: 0.7178\n",
      "Epoch 148/1000\n",
      "22/22 - 0s - 4ms/step - accuracy: 0.8249 - loss: 0.3708 - val_accuracy: 0.6753 - val_loss: 0.7407\n",
      "Epoch 149/1000\n",
      "22/22 - 0s - 6ms/step - accuracy: 0.8205 - loss: 0.3613 - val_accuracy: 0.7013 - val_loss: 0.7652\n",
      "Epoch 150/1000\n",
      "22/22 - 0s - 5ms/step - accuracy: 0.8191 - loss: 0.3785 - val_accuracy: 0.7143 - val_loss: 0.6534\n",
      "Epoch 151/1000\n",
      "22/22 - 0s - 4ms/step - accuracy: 0.7959 - loss: 0.3845 - val_accuracy: 0.7273 - val_loss: 0.6524\n",
      "Epoch 152/1000\n",
      "22/22 - 0s - 4ms/step - accuracy: 0.8234 - loss: 0.3758 - val_accuracy: 0.7143 - val_loss: 0.6923\n",
      "Epoch 153/1000\n",
      "22/22 - 0s - 4ms/step - accuracy: 0.8524 - loss: 0.3472 - val_accuracy: 0.7143 - val_loss: 0.7730\n",
      "Epoch 154/1000\n",
      "22/22 - 0s - 4ms/step - accuracy: 0.8191 - loss: 0.3934 - val_accuracy: 0.7532 - val_loss: 0.6879\n",
      "Epoch 155/1000\n",
      "22/22 - 0s - 5ms/step - accuracy: 0.8292 - loss: 0.3622 - val_accuracy: 0.7143 - val_loss: 0.6375\n",
      "Epoch 156/1000\n",
      "22/22 - 0s - 5ms/step - accuracy: 0.7974 - loss: 0.4061 - val_accuracy: 0.6753 - val_loss: 0.7522\n",
      "Epoch 157/1000\n",
      "22/22 - 0s - 5ms/step - accuracy: 0.8119 - loss: 0.3698 - val_accuracy: 0.7532 - val_loss: 0.6974\n",
      "Epoch 158/1000\n",
      "22/22 - 0s - 5ms/step - accuracy: 0.8480 - loss: 0.3467 - val_accuracy: 0.7532 - val_loss: 0.7461\n",
      "Epoch 159/1000\n",
      "22/22 - 0s - 4ms/step - accuracy: 0.8408 - loss: 0.3493 - val_accuracy: 0.7273 - val_loss: 0.7515\n",
      "Epoch 160/1000\n",
      "22/22 - 0s - 4ms/step - accuracy: 0.8307 - loss: 0.3759 - val_accuracy: 0.7403 - val_loss: 0.7173\n",
      "Epoch 161/1000\n",
      "22/22 - 0s - 4ms/step - accuracy: 0.8220 - loss: 0.3714 - val_accuracy: 0.7013 - val_loss: 0.7995\n",
      "Epoch 162/1000\n",
      "22/22 - 0s - 4ms/step - accuracy: 0.8307 - loss: 0.3538 - val_accuracy: 0.7013 - val_loss: 0.6195\n",
      "Epoch 163/1000\n",
      "22/22 - 0s - 4ms/step - accuracy: 0.8220 - loss: 0.3827 - val_accuracy: 0.7013 - val_loss: 0.7970\n",
      "Epoch 164/1000\n",
      "22/22 - 0s - 4ms/step - accuracy: 0.8017 - loss: 0.4234 - val_accuracy: 0.6883 - val_loss: 0.7261\n",
      "Epoch 165/1000\n",
      "22/22 - 0s - 4ms/step - accuracy: 0.8249 - loss: 0.3675 - val_accuracy: 0.7273 - val_loss: 0.6239\n",
      "Epoch 166/1000\n",
      "22/22 - 0s - 5ms/step - accuracy: 0.8509 - loss: 0.3346 - val_accuracy: 0.7143 - val_loss: 0.6383\n",
      "Epoch 167/1000\n",
      "22/22 - 0s - 5ms/step - accuracy: 0.8524 - loss: 0.3343 - val_accuracy: 0.7143 - val_loss: 0.7411\n",
      "Epoch 168/1000\n",
      "22/22 - 0s - 5ms/step - accuracy: 0.8119 - loss: 0.3869 - val_accuracy: 0.7013 - val_loss: 0.7312\n",
      "Epoch 169/1000\n",
      "22/22 - 0s - 5ms/step - accuracy: 0.8423 - loss: 0.3523 - val_accuracy: 0.7532 - val_loss: 0.7099\n",
      "Epoch 170/1000\n",
      "22/22 - 0s - 5ms/step - accuracy: 0.8538 - loss: 0.3344 - val_accuracy: 0.7662 - val_loss: 0.6722\n",
      "Epoch 171/1000\n",
      "22/22 - 0s - 5ms/step - accuracy: 0.8553 - loss: 0.3234 - val_accuracy: 0.7403 - val_loss: 0.6718\n",
      "Epoch 172/1000\n",
      "22/22 - 0s - 7ms/step - accuracy: 0.8611 - loss: 0.3124 - val_accuracy: 0.7273 - val_loss: 0.6884\n",
      "Epoch 173/1000\n",
      "22/22 - 0s - 6ms/step - accuracy: 0.8538 - loss: 0.3166 - val_accuracy: 0.7273 - val_loss: 0.7113\n",
      "Epoch 174/1000\n",
      "22/22 - 0s - 6ms/step - accuracy: 0.8509 - loss: 0.3207 - val_accuracy: 0.6883 - val_loss: 0.7125\n",
      "Epoch 175/1000\n",
      "22/22 - 0s - 6ms/step - accuracy: 0.8654 - loss: 0.3212 - val_accuracy: 0.7273 - val_loss: 0.7250\n",
      "Epoch 176/1000\n",
      "22/22 - 0s - 6ms/step - accuracy: 0.8480 - loss: 0.3197 - val_accuracy: 0.7403 - val_loss: 0.7357\n",
      "Epoch 177/1000\n",
      "22/22 - 0s - 5ms/step - accuracy: 0.8611 - loss: 0.3287 - val_accuracy: 0.7273 - val_loss: 0.7320\n",
      "Epoch 178/1000\n",
      "22/22 - 0s - 5ms/step - accuracy: 0.8336 - loss: 0.3337 - val_accuracy: 0.7273 - val_loss: 0.7437\n",
      "Epoch 179/1000\n",
      "22/22 - 0s - 5ms/step - accuracy: 0.8480 - loss: 0.3252 - val_accuracy: 0.7143 - val_loss: 0.7376\n",
      "Epoch 180/1000\n",
      "22/22 - 0s - 4ms/step - accuracy: 0.8553 - loss: 0.3221 - val_accuracy: 0.7532 - val_loss: 0.7150\n",
      "Epoch 181/1000\n",
      "22/22 - 0s - 4ms/step - accuracy: 0.8538 - loss: 0.3297 - val_accuracy: 0.7273 - val_loss: 0.7820\n",
      "Epoch 182/1000\n",
      "22/22 - 0s - 4ms/step - accuracy: 0.8596 - loss: 0.3190 - val_accuracy: 0.7792 - val_loss: 0.7766\n",
      "Epoch 183/1000\n",
      "22/22 - 0s - 5ms/step - accuracy: 0.8553 - loss: 0.3208 - val_accuracy: 0.7273 - val_loss: 0.7320\n",
      "Epoch 184/1000\n",
      "22/22 - 0s - 4ms/step - accuracy: 0.8625 - loss: 0.3046 - val_accuracy: 0.6753 - val_loss: 0.8875\n",
      "Epoch 185/1000\n",
      "22/22 - 0s - 4ms/step - accuracy: 0.8611 - loss: 0.2994 - val_accuracy: 0.7143 - val_loss: 0.8397\n",
      "Epoch 186/1000\n",
      "22/22 - 0s - 5ms/step - accuracy: 0.8669 - loss: 0.3000 - val_accuracy: 0.7013 - val_loss: 0.7366\n",
      "Epoch 187/1000\n",
      "22/22 - 0s - 5ms/step - accuracy: 0.8480 - loss: 0.3138 - val_accuracy: 0.7532 - val_loss: 0.8051\n",
      "Epoch 188/1000\n",
      "22/22 - 0s - 5ms/step - accuracy: 0.8538 - loss: 0.2957 - val_accuracy: 0.6883 - val_loss: 0.7811\n",
      "Epoch 189/1000\n",
      "22/22 - 0s - 4ms/step - accuracy: 0.8654 - loss: 0.2912 - val_accuracy: 0.6623 - val_loss: 0.8108\n",
      "Epoch 190/1000\n",
      "22/22 - 0s - 4ms/step - accuracy: 0.8567 - loss: 0.3334 - val_accuracy: 0.6883 - val_loss: 0.8044\n",
      "Epoch 191/1000\n",
      "22/22 - 0s - 5ms/step - accuracy: 0.8582 - loss: 0.3288 - val_accuracy: 0.7013 - val_loss: 0.7437\n",
      "Epoch 192/1000\n",
      "22/22 - 0s - 4ms/step - accuracy: 0.8423 - loss: 0.3273 - val_accuracy: 0.7532 - val_loss: 0.7182\n",
      "Epoch 193/1000\n",
      "22/22 - 0s - 4ms/step - accuracy: 0.8567 - loss: 0.3004 - val_accuracy: 0.7273 - val_loss: 0.7879\n",
      "Epoch 194/1000\n",
      "22/22 - 0s - 5ms/step - accuracy: 0.8480 - loss: 0.3155 - val_accuracy: 0.7013 - val_loss: 0.7770\n",
      "Epoch 195/1000\n",
      "22/22 - 0s - 4ms/step - accuracy: 0.8480 - loss: 0.3232 - val_accuracy: 0.7013 - val_loss: 0.8986\n",
      "Epoch 196/1000\n",
      "22/22 - 0s - 4ms/step - accuracy: 0.8625 - loss: 0.3162 - val_accuracy: 0.7273 - val_loss: 0.7952\n",
      "Epoch 197/1000\n",
      "22/22 - 0s - 4ms/step - accuracy: 0.8567 - loss: 0.3172 - val_accuracy: 0.7403 - val_loss: 0.7565\n",
      "Epoch 198/1000\n",
      "22/22 - 0s - 4ms/step - accuracy: 0.8611 - loss: 0.3140 - val_accuracy: 0.7273 - val_loss: 0.7227\n",
      "Epoch 199/1000\n",
      "22/22 - 0s - 7ms/step - accuracy: 0.8669 - loss: 0.2907 - val_accuracy: 0.7143 - val_loss: 0.8094\n",
      "Epoch 200/1000\n",
      "22/22 - 0s - 5ms/step - accuracy: 0.8698 - loss: 0.2877 - val_accuracy: 0.7143 - val_loss: 0.8512\n",
      "Epoch 201/1000\n",
      "22/22 - 0s - 4ms/step - accuracy: 0.8784 - loss: 0.2828 - val_accuracy: 0.7403 - val_loss: 0.7905\n",
      "Epoch 202/1000\n",
      "22/22 - 0s - 4ms/step - accuracy: 0.8712 - loss: 0.2799 - val_accuracy: 0.6753 - val_loss: 0.9757\n",
      "Epoch 203/1000\n",
      "22/22 - 0s - 4ms/step - accuracy: 0.8654 - loss: 0.2945 - val_accuracy: 0.7662 - val_loss: 0.7819\n",
      "Epoch 204/1000\n",
      "22/22 - 0s - 4ms/step - accuracy: 0.8625 - loss: 0.2979 - val_accuracy: 0.7532 - val_loss: 0.8273\n",
      "Epoch 205/1000\n",
      "22/22 - 0s - 4ms/step - accuracy: 0.8567 - loss: 0.2908 - val_accuracy: 0.6883 - val_loss: 0.8319\n",
      "Epoch 206/1000\n",
      "22/22 - 0s - 5ms/step - accuracy: 0.8857 - loss: 0.2752 - val_accuracy: 0.7143 - val_loss: 0.9917\n",
      "Epoch 207/1000\n",
      "22/22 - 0s - 4ms/step - accuracy: 0.8698 - loss: 0.2957 - val_accuracy: 0.7013 - val_loss: 0.8028\n",
      "Epoch 208/1000\n",
      "22/22 - 0s - 5ms/step - accuracy: 0.8698 - loss: 0.2756 - val_accuracy: 0.7143 - val_loss: 0.8683\n",
      "Epoch 209/1000\n",
      "22/22 - 0s - 4ms/step - accuracy: 0.8640 - loss: 0.2833 - val_accuracy: 0.7532 - val_loss: 0.8013\n",
      "Epoch 210/1000\n",
      "22/22 - 0s - 4ms/step - accuracy: 0.8857 - loss: 0.2594 - val_accuracy: 0.7403 - val_loss: 0.8573\n",
      "Epoch 211/1000\n",
      "22/22 - 0s - 4ms/step - accuracy: 0.8871 - loss: 0.2675 - val_accuracy: 0.7532 - val_loss: 0.9284\n",
      "Epoch 212/1000\n",
      "22/22 - 0s - 4ms/step - accuracy: 0.8842 - loss: 0.2625 - val_accuracy: 0.7143 - val_loss: 0.8356\n",
      "Epoch 213/1000\n",
      "22/22 - 0s - 4ms/step - accuracy: 0.8842 - loss: 0.2741 - val_accuracy: 0.7792 - val_loss: 0.8322\n",
      "Epoch 214/1000\n",
      "22/22 - 0s - 5ms/step - accuracy: 0.8987 - loss: 0.2588 - val_accuracy: 0.7143 - val_loss: 0.8013\n",
      "Epoch 215/1000\n",
      "22/22 - 0s - 4ms/step - accuracy: 0.8611 - loss: 0.2852 - val_accuracy: 0.6623 - val_loss: 0.8956\n",
      "Epoch 216/1000\n",
      "22/22 - 0s - 4ms/step - accuracy: 0.8408 - loss: 0.3392 - val_accuracy: 0.6364 - val_loss: 1.0741\n",
      "Epoch 217/1000\n",
      "22/22 - 0s - 4ms/step - accuracy: 0.8524 - loss: 0.3640 - val_accuracy: 0.7273 - val_loss: 0.7775\n",
      "Epoch 218/1000\n",
      "22/22 - 0s - 4ms/step - accuracy: 0.8698 - loss: 0.3104 - val_accuracy: 0.7532 - val_loss: 0.8293\n",
      "Epoch 219/1000\n",
      "22/22 - 0s - 4ms/step - accuracy: 0.8669 - loss: 0.2930 - val_accuracy: 0.7143 - val_loss: 0.8276\n",
      "Epoch 220/1000\n",
      "22/22 - 0s - 4ms/step - accuracy: 0.8929 - loss: 0.2568 - val_accuracy: 0.7143 - val_loss: 0.8470\n",
      "Epoch 221/1000\n",
      "22/22 - 0s - 4ms/step - accuracy: 0.9030 - loss: 0.2561 - val_accuracy: 0.7532 - val_loss: 0.8706\n",
      "Epoch 222/1000\n",
      "22/22 - 0s - 4ms/step - accuracy: 0.8944 - loss: 0.2525 - val_accuracy: 0.7143 - val_loss: 0.8680\n",
      "Epoch 223/1000\n",
      "22/22 - 0s - 4ms/step - accuracy: 0.9030 - loss: 0.2540 - val_accuracy: 0.7273 - val_loss: 0.9838\n",
      "Epoch 224/1000\n",
      "22/22 - 0s - 5ms/step - accuracy: 0.8915 - loss: 0.2525 - val_accuracy: 0.7013 - val_loss: 0.8915\n",
      "Epoch 225/1000\n",
      "22/22 - 0s - 5ms/step - accuracy: 0.9030 - loss: 0.2442 - val_accuracy: 0.7792 - val_loss: 0.9034\n",
      "Epoch 226/1000\n",
      "22/22 - 0s - 4ms/step - accuracy: 0.8944 - loss: 0.2579 - val_accuracy: 0.7662 - val_loss: 0.8076\n",
      "Epoch 227/1000\n",
      "22/22 - 0s - 5ms/step - accuracy: 0.8799 - loss: 0.2811 - val_accuracy: 0.6753 - val_loss: 0.9718\n",
      "Epoch 228/1000\n",
      "22/22 - 0s - 4ms/step - accuracy: 0.8944 - loss: 0.2451 - val_accuracy: 0.7013 - val_loss: 0.8351\n",
      "Epoch 229/1000\n",
      "22/22 - 0s - 4ms/step - accuracy: 0.8871 - loss: 0.2504 - val_accuracy: 0.7662 - val_loss: 0.9051\n",
      "Epoch 230/1000\n",
      "22/22 - 0s - 4ms/step - accuracy: 0.8813 - loss: 0.2563 - val_accuracy: 0.7532 - val_loss: 0.9407\n",
      "Epoch 231/1000\n",
      "22/22 - 0s - 5ms/step - accuracy: 0.8828 - loss: 0.2462 - val_accuracy: 0.7532 - val_loss: 1.0104\n",
      "Epoch 232/1000\n",
      "22/22 - 0s - 4ms/step - accuracy: 0.8958 - loss: 0.2500 - val_accuracy: 0.7273 - val_loss: 1.0412\n",
      "Epoch 233/1000\n",
      "22/22 - 0s - 4ms/step - accuracy: 0.8915 - loss: 0.2516 - val_accuracy: 0.6883 - val_loss: 1.0092\n",
      "Epoch 234/1000\n",
      "22/22 - 0s - 4ms/step - accuracy: 0.8842 - loss: 0.2412 - val_accuracy: 0.7403 - val_loss: 0.9099\n",
      "Epoch 235/1000\n",
      "22/22 - 0s - 4ms/step - accuracy: 0.8900 - loss: 0.2496 - val_accuracy: 0.7273 - val_loss: 1.0606\n",
      "Epoch 236/1000\n",
      "22/22 - 0s - 4ms/step - accuracy: 0.8784 - loss: 0.2496 - val_accuracy: 0.7013 - val_loss: 1.1887\n",
      "Epoch 237/1000\n",
      "22/22 - 0s - 4ms/step - accuracy: 0.8973 - loss: 0.2297 - val_accuracy: 0.7143 - val_loss: 0.9247\n",
      "Epoch 238/1000\n",
      "22/22 - 0s - 4ms/step - accuracy: 0.9103 - loss: 0.2108 - val_accuracy: 0.7532 - val_loss: 0.8907\n",
      "Epoch 239/1000\n",
      "22/22 - 0s - 5ms/step - accuracy: 0.9117 - loss: 0.2120 - val_accuracy: 0.7273 - val_loss: 1.0365\n",
      "Epoch 240/1000\n",
      "22/22 - 0s - 4ms/step - accuracy: 0.9030 - loss: 0.2185 - val_accuracy: 0.7143 - val_loss: 1.1244\n",
      "Epoch 241/1000\n",
      "22/22 - 0s - 4ms/step - accuracy: 0.9088 - loss: 0.2257 - val_accuracy: 0.7013 - val_loss: 0.9676\n",
      "Epoch 242/1000\n",
      "22/22 - 0s - 4ms/step - accuracy: 0.8973 - loss: 0.2368 - val_accuracy: 0.6753 - val_loss: 0.9532\n",
      "Epoch 243/1000\n",
      "22/22 - 0s - 4ms/step - accuracy: 0.9088 - loss: 0.2487 - val_accuracy: 0.7013 - val_loss: 0.8918\n",
      "Epoch 244/1000\n",
      "22/22 - 0s - 4ms/step - accuracy: 0.8698 - loss: 0.2653 - val_accuracy: 0.7403 - val_loss: 1.0594\n",
      "Epoch 245/1000\n",
      "22/22 - 0s - 4ms/step - accuracy: 0.8886 - loss: 0.2497 - val_accuracy: 0.7792 - val_loss: 0.9415\n",
      "Epoch 246/1000\n",
      "22/22 - 0s - 4ms/step - accuracy: 0.8857 - loss: 0.2520 - val_accuracy: 0.6623 - val_loss: 1.0498\n",
      "Epoch 247/1000\n",
      "22/22 - 0s - 4ms/step - accuracy: 0.8973 - loss: 0.2551 - val_accuracy: 0.7403 - val_loss: 1.0084\n",
      "Epoch 248/1000\n",
      "22/22 - 0s - 4ms/step - accuracy: 0.8987 - loss: 0.2420 - val_accuracy: 0.7662 - val_loss: 0.9506\n",
      "Epoch 249/1000\n",
      "22/22 - 0s - 4ms/step - accuracy: 0.8944 - loss: 0.2589 - val_accuracy: 0.6883 - val_loss: 1.1177\n",
      "Epoch 250/1000\n",
      "22/22 - 0s - 4ms/step - accuracy: 0.8929 - loss: 0.2544 - val_accuracy: 0.6883 - val_loss: 0.9634\n",
      "Epoch 251/1000\n",
      "22/22 - 0s - 4ms/step - accuracy: 0.9045 - loss: 0.2264 - val_accuracy: 0.7662 - val_loss: 1.0010\n",
      "Epoch 252/1000\n",
      "22/22 - 0s - 6ms/step - accuracy: 0.8929 - loss: 0.2386 - val_accuracy: 0.7273 - val_loss: 1.1022\n",
      "Epoch 253/1000\n",
      "22/22 - 0s - 4ms/step - accuracy: 0.8944 - loss: 0.2498 - val_accuracy: 0.7662 - val_loss: 0.9444\n",
      "Epoch 254/1000\n",
      "22/22 - 0s - 7ms/step - accuracy: 0.8987 - loss: 0.2309 - val_accuracy: 0.7013 - val_loss: 1.0184\n",
      "Epoch 255/1000\n",
      "22/22 - 0s - 5ms/step - accuracy: 0.9059 - loss: 0.2241 - val_accuracy: 0.6753 - val_loss: 1.0328\n",
      "Epoch 256/1000\n",
      "22/22 - 0s - 5ms/step - accuracy: 0.9045 - loss: 0.2175 - val_accuracy: 0.7143 - val_loss: 1.0462\n",
      "Epoch 257/1000\n",
      "22/22 - 0s - 4ms/step - accuracy: 0.8900 - loss: 0.2370 - val_accuracy: 0.7013 - val_loss: 1.0929\n",
      "Epoch 258/1000\n",
      "22/22 - 0s - 4ms/step - accuracy: 0.9074 - loss: 0.2141 - val_accuracy: 0.7662 - val_loss: 1.0450\n",
      "Epoch 259/1000\n",
      "22/22 - 0s - 5ms/step - accuracy: 0.9204 - loss: 0.1993 - val_accuracy: 0.7662 - val_loss: 0.9408\n",
      "Epoch 260/1000\n",
      "22/22 - 0s - 4ms/step - accuracy: 0.9291 - loss: 0.1770 - val_accuracy: 0.7143 - val_loss: 1.1382\n",
      "Epoch 261/1000\n",
      "22/22 - 0s - 4ms/step - accuracy: 0.9247 - loss: 0.1819 - val_accuracy: 0.7403 - val_loss: 1.0367\n",
      "Epoch 262/1000\n",
      "22/22 - 0s - 4ms/step - accuracy: 0.9117 - loss: 0.1984 - val_accuracy: 0.7662 - val_loss: 1.0486\n",
      "Epoch 263/1000\n",
      "22/22 - 0s - 5ms/step - accuracy: 0.9190 - loss: 0.1931 - val_accuracy: 0.7273 - val_loss: 1.0869\n",
      "Epoch 264/1000\n",
      "22/22 - 0s - 4ms/step - accuracy: 0.9161 - loss: 0.1948 - val_accuracy: 0.7013 - val_loss: 1.3481\n",
      "Epoch 265/1000\n",
      "22/22 - 0s - 4ms/step - accuracy: 0.9146 - loss: 0.1909 - val_accuracy: 0.7532 - val_loss: 0.9969\n",
      "Epoch 266/1000\n",
      "22/22 - 0s - 4ms/step - accuracy: 0.8929 - loss: 0.2236 - val_accuracy: 0.7532 - val_loss: 1.2019\n",
      "Epoch 267/1000\n",
      "22/22 - 0s - 4ms/step - accuracy: 0.9132 - loss: 0.2083 - val_accuracy: 0.7013 - val_loss: 1.2040\n",
      "Epoch 268/1000\n",
      "22/22 - 0s - 4ms/step - accuracy: 0.9305 - loss: 0.1790 - val_accuracy: 0.6623 - val_loss: 1.3938\n",
      "Epoch 269/1000\n",
      "22/22 - 0s - 4ms/step - accuracy: 0.9219 - loss: 0.1848 - val_accuracy: 0.7403 - val_loss: 1.0462\n",
      "Epoch 270/1000\n",
      "22/22 - 0s - 5ms/step - accuracy: 0.9190 - loss: 0.1923 - val_accuracy: 0.7532 - val_loss: 1.1708\n",
      "Epoch 271/1000\n",
      "22/22 - 0s - 4ms/step - accuracy: 0.9291 - loss: 0.1861 - val_accuracy: 0.7143 - val_loss: 1.1392\n",
      "Epoch 272/1000\n",
      "22/22 - 0s - 6ms/step - accuracy: 0.9161 - loss: 0.1902 - val_accuracy: 0.7403 - val_loss: 1.1240\n",
      "Epoch 273/1000\n",
      "22/22 - 0s - 4ms/step - accuracy: 0.9262 - loss: 0.1729 - val_accuracy: 0.7143 - val_loss: 1.2017\n",
      "Epoch 274/1000\n",
      "22/22 - 0s - 4ms/step - accuracy: 0.9334 - loss: 0.1629 - val_accuracy: 0.6494 - val_loss: 1.4734\n",
      "Epoch 275/1000\n",
      "22/22 - 0s - 5ms/step - accuracy: 0.9219 - loss: 0.1818 - val_accuracy: 0.7273 - val_loss: 1.1734\n",
      "Epoch 276/1000\n",
      "22/22 - 0s - 4ms/step - accuracy: 0.9450 - loss: 0.1573 - val_accuracy: 0.7143 - val_loss: 1.4588\n",
      "Epoch 277/1000\n",
      "22/22 - 0s - 4ms/step - accuracy: 0.9219 - loss: 0.1775 - val_accuracy: 0.7143 - val_loss: 1.3889\n",
      "Epoch 278/1000\n",
      "22/22 - 0s - 4ms/step - accuracy: 0.9247 - loss: 0.1782 - val_accuracy: 0.6883 - val_loss: 1.4326\n",
      "Epoch 279/1000\n",
      "22/22 - 0s - 4ms/step - accuracy: 0.9291 - loss: 0.1683 - val_accuracy: 0.7143 - val_loss: 1.2146\n",
      "Epoch 280/1000\n",
      "22/22 - 0s - 5ms/step - accuracy: 0.9190 - loss: 0.1772 - val_accuracy: 0.7143 - val_loss: 1.3280\n",
      "Epoch 281/1000\n",
      "22/22 - 0s - 4ms/step - accuracy: 0.9378 - loss: 0.1591 - val_accuracy: 0.6753 - val_loss: 1.5069\n",
      "Epoch 282/1000\n",
      "22/22 - 0s - 4ms/step - accuracy: 0.9349 - loss: 0.1681 - val_accuracy: 0.7143 - val_loss: 1.4204\n",
      "Epoch 283/1000\n",
      "22/22 - 0s - 4ms/step - accuracy: 0.9493 - loss: 0.1547 - val_accuracy: 0.7403 - val_loss: 1.3342\n",
      "Epoch 284/1000\n",
      "22/22 - 0s - 4ms/step - accuracy: 0.9479 - loss: 0.1585 - val_accuracy: 0.7403 - val_loss: 1.3656\n",
      "Epoch 285/1000\n",
      "22/22 - 0s - 4ms/step - accuracy: 0.8987 - loss: 0.2283 - val_accuracy: 0.7143 - val_loss: 1.3552\n",
      "Epoch 286/1000\n",
      "22/22 - 0s - 4ms/step - accuracy: 0.8987 - loss: 0.2187 - val_accuracy: 0.7403 - val_loss: 1.3056\n",
      "Epoch 287/1000\n",
      "22/22 - 0s - 5ms/step - accuracy: 0.8857 - loss: 0.2571 - val_accuracy: 0.7403 - val_loss: 1.1038\n",
      "Epoch 288/1000\n",
      "22/22 - 0s - 4ms/step - accuracy: 0.9059 - loss: 0.2368 - val_accuracy: 0.7273 - val_loss: 1.3167\n",
      "Epoch 289/1000\n",
      "22/22 - 0s - 4ms/step - accuracy: 0.9045 - loss: 0.2156 - val_accuracy: 0.7532 - val_loss: 1.0685\n",
      "Epoch 290/1000\n",
      "22/22 - 0s - 4ms/step - accuracy: 0.9088 - loss: 0.2312 - val_accuracy: 0.7143 - val_loss: 1.0895\n",
      "Epoch 291/1000\n",
      "22/22 - 0s - 4ms/step - accuracy: 0.9204 - loss: 0.1928 - val_accuracy: 0.7273 - val_loss: 1.3494\n",
      "Epoch 292/1000\n",
      "22/22 - 0s - 4ms/step - accuracy: 0.9392 - loss: 0.1666 - val_accuracy: 0.7403 - val_loss: 1.3748\n",
      "Epoch 293/1000\n",
      "22/22 - 0s - 4ms/step - accuracy: 0.9334 - loss: 0.1629 - val_accuracy: 0.7532 - val_loss: 1.2004\n",
      "Epoch 294/1000\n",
      "22/22 - 0s - 5ms/step - accuracy: 0.9378 - loss: 0.1535 - val_accuracy: 0.6883 - val_loss: 1.2941\n",
      "Epoch 295/1000\n",
      "22/22 - 0s - 4ms/step - accuracy: 0.9450 - loss: 0.1392 - val_accuracy: 0.7143 - val_loss: 1.3972\n",
      "Epoch 296/1000\n",
      "22/22 - 0s - 4ms/step - accuracy: 0.9479 - loss: 0.1307 - val_accuracy: 0.7143 - val_loss: 1.4070\n",
      "Epoch 297/1000\n",
      "22/22 - 0s - 4ms/step - accuracy: 0.9378 - loss: 0.1521 - val_accuracy: 0.7662 - val_loss: 1.2074\n",
      "Epoch 298/1000\n",
      "22/22 - 0s - 5ms/step - accuracy: 0.9537 - loss: 0.1366 - val_accuracy: 0.7403 - val_loss: 1.4405\n",
      "Epoch 299/1000\n",
      "22/22 - 0s - 4ms/step - accuracy: 0.9537 - loss: 0.1295 - val_accuracy: 0.7532 - val_loss: 1.3233\n",
      "Epoch 300/1000\n",
      "22/22 - 0s - 4ms/step - accuracy: 0.9551 - loss: 0.1262 - val_accuracy: 0.7403 - val_loss: 1.3418\n",
      "Epoch 301/1000\n",
      "22/22 - 0s - 4ms/step - accuracy: 0.9580 - loss: 0.1208 - val_accuracy: 0.7662 - val_loss: 1.3324\n",
      "Epoch 302/1000\n",
      "22/22 - 0s - 4ms/step - accuracy: 0.9522 - loss: 0.1228 - val_accuracy: 0.7143 - val_loss: 1.5581\n",
      "Epoch 303/1000\n",
      "22/22 - 0s - 4ms/step - accuracy: 0.9522 - loss: 0.1423 - val_accuracy: 0.7273 - val_loss: 1.3534\n",
      "Epoch 304/1000\n",
      "22/22 - 0s - 4ms/step - accuracy: 0.9233 - loss: 0.1781 - val_accuracy: 0.7273 - val_loss: 1.2570\n",
      "Epoch 305/1000\n",
      "22/22 - 0s - 4ms/step - accuracy: 0.9088 - loss: 0.2019 - val_accuracy: 0.7662 - val_loss: 1.2705\n",
      "Epoch 306/1000\n",
      "22/22 - 0s - 4ms/step - accuracy: 0.9190 - loss: 0.1888 - val_accuracy: 0.7662 - val_loss: 1.2115\n",
      "Epoch 307/1000\n",
      "22/22 - 0s - 7ms/step - accuracy: 0.9262 - loss: 0.1893 - val_accuracy: 0.7013 - val_loss: 1.6449\n",
      "Epoch 308/1000\n",
      "22/22 - 0s - 5ms/step - accuracy: 0.9161 - loss: 0.1963 - val_accuracy: 0.7662 - val_loss: 1.1830\n",
      "Epoch 309/1000\n",
      "22/22 - 0s - 4ms/step - accuracy: 0.9247 - loss: 0.1782 - val_accuracy: 0.7403 - val_loss: 1.3536\n",
      "Epoch 310/1000\n",
      "22/22 - 0s - 4ms/step - accuracy: 0.9479 - loss: 0.1419 - val_accuracy: 0.7013 - val_loss: 1.4424\n",
      "Epoch 311/1000\n",
      "22/22 - 0s - 4ms/step - accuracy: 0.9378 - loss: 0.1442 - val_accuracy: 0.7662 - val_loss: 1.4244\n",
      "Epoch 312/1000\n",
      "22/22 - 0s - 4ms/step - accuracy: 0.9580 - loss: 0.1115 - val_accuracy: 0.7273 - val_loss: 1.3210\n",
      "Epoch 313/1000\n",
      "22/22 - 0s - 4ms/step - accuracy: 0.9711 - loss: 0.1076 - val_accuracy: 0.7013 - val_loss: 1.7758\n",
      "Epoch 314/1000\n",
      "22/22 - 0s - 4ms/step - accuracy: 0.9508 - loss: 0.1324 - val_accuracy: 0.7273 - val_loss: 1.4144\n",
      "Epoch 315/1000\n",
      "22/22 - 0s - 4ms/step - accuracy: 0.9580 - loss: 0.1213 - val_accuracy: 0.7662 - val_loss: 1.3767\n",
      "Epoch 316/1000\n",
      "22/22 - 0s - 4ms/step - accuracy: 0.9580 - loss: 0.1226 - val_accuracy: 0.6883 - val_loss: 1.5276\n",
      "Epoch 317/1000\n",
      "22/22 - 0s - 5ms/step - accuracy: 0.9450 - loss: 0.1368 - val_accuracy: 0.7013 - val_loss: 1.5429\n",
      "Epoch 318/1000\n",
      "22/22 - 0s - 4ms/step - accuracy: 0.9624 - loss: 0.1121 - val_accuracy: 0.7532 - val_loss: 1.3837\n",
      "Epoch 319/1000\n",
      "22/22 - 0s - 4ms/step - accuracy: 0.9682 - loss: 0.0985 - val_accuracy: 0.7403 - val_loss: 1.6141\n",
      "Epoch 320/1000\n",
      "22/22 - 0s - 4ms/step - accuracy: 0.9682 - loss: 0.1056 - val_accuracy: 0.7273 - val_loss: 1.5116\n",
      "Epoch 321/1000\n",
      "22/22 - 0s - 4ms/step - accuracy: 0.9566 - loss: 0.1057 - val_accuracy: 0.7143 - val_loss: 1.6059\n",
      "Epoch 322/1000\n",
      "22/22 - 0s - 4ms/step - accuracy: 0.9725 - loss: 0.0959 - val_accuracy: 0.7273 - val_loss: 1.4443\n",
      "Epoch 323/1000\n",
      "22/22 - 0s - 4ms/step - accuracy: 0.9740 - loss: 0.0942 - val_accuracy: 0.7013 - val_loss: 1.5601\n",
      "Epoch 324/1000\n",
      "22/22 - 0s - 4ms/step - accuracy: 0.9580 - loss: 0.1097 - val_accuracy: 0.7273 - val_loss: 1.6078\n",
      "Epoch 325/1000\n",
      "22/22 - 0s - 5ms/step - accuracy: 0.9580 - loss: 0.1148 - val_accuracy: 0.7662 - val_loss: 1.4665\n",
      "Epoch 326/1000\n",
      "22/22 - 0s - 4ms/step - accuracy: 0.9653 - loss: 0.0932 - val_accuracy: 0.7273 - val_loss: 1.6677\n",
      "Epoch 327/1000\n",
      "22/22 - 0s - 4ms/step - accuracy: 0.9696 - loss: 0.0893 - val_accuracy: 0.7143 - val_loss: 1.6712\n",
      "Epoch 328/1000\n",
      "22/22 - 0s - 4ms/step - accuracy: 0.9696 - loss: 0.0902 - val_accuracy: 0.7273 - val_loss: 1.6591\n",
      "Epoch 329/1000\n",
      "22/22 - 0s - 4ms/step - accuracy: 0.9580 - loss: 0.1024 - val_accuracy: 0.7273 - val_loss: 1.6520\n",
      "Epoch 330/1000\n",
      "22/22 - 0s - 4ms/step - accuracy: 0.9609 - loss: 0.0896 - val_accuracy: 0.7143 - val_loss: 1.5689\n",
      "Epoch 331/1000\n",
      "22/22 - 0s - 4ms/step - accuracy: 0.9551 - loss: 0.1095 - val_accuracy: 0.7013 - val_loss: 1.6440\n",
      "Epoch 332/1000\n",
      "22/22 - 0s - 4ms/step - accuracy: 0.9653 - loss: 0.1007 - val_accuracy: 0.7143 - val_loss: 1.8619\n",
      "Epoch 333/1000\n",
      "22/22 - 0s - 5ms/step - accuracy: 0.9551 - loss: 0.1276 - val_accuracy: 0.7013 - val_loss: 1.8198\n",
      "Epoch 334/1000\n",
      "22/22 - 0s - 4ms/step - accuracy: 0.9305 - loss: 0.1658 - val_accuracy: 0.7532 - val_loss: 1.7934\n",
      "Epoch 335/1000\n",
      "22/22 - 0s - 4ms/step - accuracy: 0.8987 - loss: 0.2709 - val_accuracy: 0.7013 - val_loss: 1.5056\n",
      "Epoch 336/1000\n",
      "22/22 - 0s - 4ms/step - accuracy: 0.9132 - loss: 0.2050 - val_accuracy: 0.7532 - val_loss: 1.4386\n",
      "Epoch 337/1000\n",
      "22/22 - 0s - 5ms/step - accuracy: 0.9276 - loss: 0.1972 - val_accuracy: 0.7143 - val_loss: 1.3529\n",
      "Epoch 338/1000\n",
      "22/22 - 0s - 4ms/step - accuracy: 0.9450 - loss: 0.1483 - val_accuracy: 0.7273 - val_loss: 1.7952\n",
      "Epoch 339/1000\n",
      "22/22 - 0s - 4ms/step - accuracy: 0.9479 - loss: 0.1336 - val_accuracy: 0.7273 - val_loss: 1.3688\n",
      "Epoch 340/1000\n",
      "22/22 - 0s - 5ms/step - accuracy: 0.9537 - loss: 0.1239 - val_accuracy: 0.7143 - val_loss: 1.9024\n",
      "Epoch 341/1000\n",
      "22/22 - 0s - 5ms/step - accuracy: 0.9551 - loss: 0.1216 - val_accuracy: 0.7143 - val_loss: 1.6945\n",
      "Epoch 342/1000\n",
      "22/22 - 0s - 5ms/step - accuracy: 0.9450 - loss: 0.1309 - val_accuracy: 0.6883 - val_loss: 1.5404\n",
      "Epoch 343/1000\n",
      "22/22 - 0s - 4ms/step - accuracy: 0.9580 - loss: 0.1254 - val_accuracy: 0.7013 - val_loss: 2.1977\n",
      "Epoch 344/1000\n",
      "22/22 - 0s - 4ms/step - accuracy: 0.9450 - loss: 0.1649 - val_accuracy: 0.7273 - val_loss: 1.6479\n",
      "Epoch 345/1000\n",
      "22/22 - 0s - 5ms/step - accuracy: 0.9609 - loss: 0.1311 - val_accuracy: 0.7403 - val_loss: 1.5603\n",
      "Epoch 346/1000\n",
      "22/22 - 0s - 4ms/step - accuracy: 0.9508 - loss: 0.1256 - val_accuracy: 0.7662 - val_loss: 1.7181\n",
      "Epoch 347/1000\n",
      "22/22 - 0s - 4ms/step - accuracy: 0.9537 - loss: 0.1301 - val_accuracy: 0.7143 - val_loss: 1.5998\n",
      "Epoch 348/1000\n",
      "22/22 - 0s - 4ms/step - accuracy: 0.9522 - loss: 0.1171 - val_accuracy: 0.7532 - val_loss: 1.5595\n",
      "Epoch 349/1000\n",
      "22/22 - 0s - 5ms/step - accuracy: 0.9305 - loss: 0.1756 - val_accuracy: 0.7532 - val_loss: 1.8033\n",
      "Epoch 350/1000\n",
      "22/22 - 0s - 4ms/step - accuracy: 0.9450 - loss: 0.1264 - val_accuracy: 0.7403 - val_loss: 1.4552\n",
      "Epoch 351/1000\n",
      "22/22 - 0s - 4ms/step - accuracy: 0.9537 - loss: 0.1131 - val_accuracy: 0.7532 - val_loss: 1.9964\n",
      "Epoch 352/1000\n",
      "22/22 - 0s - 5ms/step - accuracy: 0.9711 - loss: 0.0902 - val_accuracy: 0.7403 - val_loss: 1.8171\n",
      "Epoch 353/1000\n",
      "22/22 - 0s - 4ms/step - accuracy: 0.9696 - loss: 0.0789 - val_accuracy: 0.7403 - val_loss: 1.9967\n",
      "Epoch 354/1000\n",
      "22/22 - 0s - 4ms/step - accuracy: 0.9740 - loss: 0.0851 - val_accuracy: 0.7143 - val_loss: 1.9463\n",
      "Epoch 355/1000\n",
      "22/22 - 0s - 4ms/step - accuracy: 0.9436 - loss: 0.1623 - val_accuracy: 0.7792 - val_loss: 1.6145\n",
      "Epoch 356/1000\n",
      "22/22 - 0s - 4ms/step - accuracy: 0.9667 - loss: 0.1000 - val_accuracy: 0.7662 - val_loss: 1.6249\n",
      "Epoch 357/1000\n",
      "22/22 - 0s - 5ms/step - accuracy: 0.9696 - loss: 0.0977 - val_accuracy: 0.7662 - val_loss: 1.8290\n",
      "Epoch 358/1000\n",
      "22/22 - 0s - 4ms/step - accuracy: 0.9624 - loss: 0.1166 - val_accuracy: 0.7143 - val_loss: 1.5147\n",
      "Epoch 359/1000\n",
      "22/22 - 0s - 4ms/step - accuracy: 0.9508 - loss: 0.1492 - val_accuracy: 0.7013 - val_loss: 1.7883\n",
      "Epoch 360/1000\n",
      "22/22 - 0s - 4ms/step - accuracy: 0.9262 - loss: 0.1804 - val_accuracy: 0.7532 - val_loss: 1.5196\n",
      "Epoch 361/1000\n",
      "22/22 - 0s - 5ms/step - accuracy: 0.9363 - loss: 0.1503 - val_accuracy: 0.7403 - val_loss: 1.8236\n",
      "Epoch 362/1000\n",
      "22/22 - 0s - 5ms/step - accuracy: 0.9653 - loss: 0.1047 - val_accuracy: 0.7532 - val_loss: 1.8380\n",
      "Epoch 363/1000\n",
      "22/22 - 0s - 4ms/step - accuracy: 0.9667 - loss: 0.1031 - val_accuracy: 0.7532 - val_loss: 1.8507\n",
      "Epoch 364/1000\n",
      "22/22 - 0s - 4ms/step - accuracy: 0.9696 - loss: 0.0880 - val_accuracy: 0.7273 - val_loss: 1.7935\n",
      "Epoch 365/1000\n",
      "22/22 - 0s - 4ms/step - accuracy: 0.9653 - loss: 0.0831 - val_accuracy: 0.7532 - val_loss: 2.0963\n",
      "Epoch 366/1000\n",
      "22/22 - 0s - 4ms/step - accuracy: 0.9711 - loss: 0.0809 - val_accuracy: 0.7273 - val_loss: 1.6130\n",
      "Epoch 367/1000\n",
      "22/22 - 0s - 5ms/step - accuracy: 0.9725 - loss: 0.0732 - val_accuracy: 0.7532 - val_loss: 1.9621\n",
      "Epoch 368/1000\n",
      "22/22 - 0s - 4ms/step - accuracy: 0.9783 - loss: 0.0729 - val_accuracy: 0.7273 - val_loss: 1.8966\n",
      "Epoch 369/1000\n",
      "22/22 - 0s - 4ms/step - accuracy: 0.9783 - loss: 0.0622 - val_accuracy: 0.7792 - val_loss: 1.9672\n",
      "Epoch 370/1000\n",
      "22/22 - 0s - 4ms/step - accuracy: 0.9899 - loss: 0.0524 - val_accuracy: 0.7532 - val_loss: 2.0310\n",
      "Epoch 371/1000\n",
      "22/22 - 0s - 4ms/step - accuracy: 0.9812 - loss: 0.0571 - val_accuracy: 0.7662 - val_loss: 1.8416\n",
      "Epoch 372/1000\n",
      "22/22 - 0s - 4ms/step - accuracy: 0.9855 - loss: 0.0509 - val_accuracy: 0.7792 - val_loss: 1.9825\n",
      "Epoch 373/1000\n",
      "22/22 - 0s - 4ms/step - accuracy: 0.9841 - loss: 0.0549 - val_accuracy: 0.7662 - val_loss: 1.9568\n",
      "Epoch 374/1000\n",
      "22/22 - 0s - 4ms/step - accuracy: 0.9812 - loss: 0.0548 - val_accuracy: 0.7662 - val_loss: 2.0192\n",
      "Epoch 375/1000\n",
      "22/22 - 0s - 4ms/step - accuracy: 0.9783 - loss: 0.0664 - val_accuracy: 0.7532 - val_loss: 1.9562\n",
      "Epoch 376/1000\n",
      "22/22 - 0s - 4ms/step - accuracy: 0.9783 - loss: 0.0667 - val_accuracy: 0.7532 - val_loss: 2.0196\n",
      "Epoch 377/1000\n",
      "22/22 - 0s - 4ms/step - accuracy: 0.9783 - loss: 0.0596 - val_accuracy: 0.7143 - val_loss: 2.2774\n",
      "Epoch 378/1000\n",
      "22/22 - 0s - 4ms/step - accuracy: 0.9826 - loss: 0.0502 - val_accuracy: 0.7403 - val_loss: 2.0658\n",
      "Epoch 379/1000\n",
      "22/22 - 0s - 4ms/step - accuracy: 0.9855 - loss: 0.0534 - val_accuracy: 0.7273 - val_loss: 2.0960\n",
      "Epoch 380/1000\n",
      "22/22 - 0s - 5ms/step - accuracy: 0.9725 - loss: 0.0855 - val_accuracy: 0.7403 - val_loss: 2.3134\n",
      "Epoch 381/1000\n",
      "22/22 - 0s - 4ms/step - accuracy: 0.9580 - loss: 0.0995 - val_accuracy: 0.7273 - val_loss: 2.4148\n",
      "Epoch 382/1000\n",
      "22/22 - 0s - 4ms/step - accuracy: 0.9638 - loss: 0.1015 - val_accuracy: 0.7922 - val_loss: 1.8054\n",
      "Epoch 383/1000\n",
      "22/22 - 0s - 5ms/step - accuracy: 0.9638 - loss: 0.0921 - val_accuracy: 0.7013 - val_loss: 2.3571\n",
      "Epoch 384/1000\n",
      "22/22 - 0s - 5ms/step - accuracy: 0.9537 - loss: 0.1092 - val_accuracy: 0.7662 - val_loss: 2.2947\n",
      "Epoch 385/1000\n",
      "22/22 - 0s - 5ms/step - accuracy: 0.9392 - loss: 0.1762 - val_accuracy: 0.6494 - val_loss: 2.6561\n",
      "Epoch 386/1000\n",
      "22/22 - 0s - 4ms/step - accuracy: 0.9088 - loss: 0.2186 - val_accuracy: 0.6883 - val_loss: 2.5002\n",
      "Epoch 387/1000\n",
      "22/22 - 0s - 4ms/step - accuracy: 0.9349 - loss: 0.1614 - val_accuracy: 0.6104 - val_loss: 2.2773\n",
      "Epoch 388/1000\n",
      "22/22 - 0s - 6ms/step - accuracy: 0.9334 - loss: 0.1685 - val_accuracy: 0.7403 - val_loss: 1.9293\n",
      "Epoch 389/1000\n",
      "22/22 - 0s - 4ms/step - accuracy: 0.9334 - loss: 0.1720 - val_accuracy: 0.6623 - val_loss: 2.0375\n",
      "Epoch 390/1000\n",
      "22/22 - 0s - 5ms/step - accuracy: 0.9667 - loss: 0.1051 - val_accuracy: 0.6753 - val_loss: 2.0580\n",
      "Epoch 391/1000\n",
      "22/22 - 0s - 4ms/step - accuracy: 0.9768 - loss: 0.0822 - val_accuracy: 0.6883 - val_loss: 1.9718\n",
      "Epoch 392/1000\n",
      "22/22 - 0s - 4ms/step - accuracy: 0.9711 - loss: 0.0727 - val_accuracy: 0.6883 - val_loss: 2.1673\n",
      "Epoch 393/1000\n",
      "22/22 - 0s - 5ms/step - accuracy: 0.9812 - loss: 0.0658 - val_accuracy: 0.7792 - val_loss: 1.8907\n",
      "Epoch 394/1000\n",
      "22/22 - 0s - 4ms/step - accuracy: 0.9870 - loss: 0.0550 - val_accuracy: 0.7273 - val_loss: 1.8555\n",
      "Epoch 395/1000\n",
      "22/22 - 0s - 4ms/step - accuracy: 0.9711 - loss: 0.0712 - val_accuracy: 0.7143 - val_loss: 2.1310\n",
      "Epoch 396/1000\n",
      "22/22 - 0s - 4ms/step - accuracy: 0.9797 - loss: 0.0615 - val_accuracy: 0.7532 - val_loss: 2.2421\n",
      "Epoch 397/1000\n",
      "22/22 - 0s - 4ms/step - accuracy: 0.9855 - loss: 0.0495 - val_accuracy: 0.7532 - val_loss: 2.1612\n",
      "Epoch 398/1000\n",
      "22/22 - 0s - 4ms/step - accuracy: 0.9826 - loss: 0.0533 - val_accuracy: 0.7532 - val_loss: 1.9802\n",
      "Epoch 399/1000\n",
      "22/22 - 0s - 4ms/step - accuracy: 0.9841 - loss: 0.0521 - val_accuracy: 0.7273 - val_loss: 2.1257\n",
      "Epoch 400/1000\n",
      "22/22 - 0s - 4ms/step - accuracy: 0.9855 - loss: 0.0446 - val_accuracy: 0.7532 - val_loss: 1.9286\n",
      "Epoch 401/1000\n",
      "22/22 - 0s - 5ms/step - accuracy: 0.9855 - loss: 0.0470 - val_accuracy: 0.7532 - val_loss: 2.0825\n",
      "Epoch 402/1000\n",
      "22/22 - 0s - 4ms/step - accuracy: 0.9826 - loss: 0.0507 - val_accuracy: 0.6753 - val_loss: 2.3283\n",
      "Epoch 403/1000\n",
      "22/22 - 0s - 5ms/step - accuracy: 0.9812 - loss: 0.0502 - val_accuracy: 0.7273 - val_loss: 2.2865\n",
      "Epoch 404/1000\n",
      "22/22 - 0s - 4ms/step - accuracy: 0.9624 - loss: 0.0929 - val_accuracy: 0.6883 - val_loss: 2.5577\n",
      "Epoch 405/1000\n",
      "22/22 - 0s - 6ms/step - accuracy: 0.9479 - loss: 0.1341 - val_accuracy: 0.6494 - val_loss: 2.0154\n",
      "Epoch 406/1000\n",
      "22/22 - 0s - 5ms/step - accuracy: 0.8958 - loss: 0.2358 - val_accuracy: 0.6623 - val_loss: 2.0021\n",
      "Epoch 407/1000\n",
      "22/22 - 0s - 4ms/step - accuracy: 0.9305 - loss: 0.1793 - val_accuracy: 0.7013 - val_loss: 2.2475\n",
      "Epoch 408/1000\n",
      "22/22 - 0s - 4ms/step - accuracy: 0.9465 - loss: 0.1390 - val_accuracy: 0.7403 - val_loss: 2.1362\n",
      "Epoch 409/1000\n",
      "22/22 - 0s - 4ms/step - accuracy: 0.9551 - loss: 0.1416 - val_accuracy: 0.7273 - val_loss: 1.9940\n",
      "Epoch 410/1000\n",
      "22/22 - 0s - 4ms/step - accuracy: 0.9682 - loss: 0.0780 - val_accuracy: 0.7403 - val_loss: 1.8748\n",
      "Epoch 411/1000\n",
      "22/22 - 0s - 4ms/step - accuracy: 0.9841 - loss: 0.0580 - val_accuracy: 0.7013 - val_loss: 2.0638\n",
      "Epoch 412/1000\n",
      "22/22 - 0s - 5ms/step - accuracy: 0.9884 - loss: 0.0450 - val_accuracy: 0.7532 - val_loss: 1.9442\n",
      "Epoch 413/1000\n",
      "22/22 - 0s - 4ms/step - accuracy: 0.9884 - loss: 0.0468 - val_accuracy: 0.7792 - val_loss: 2.1208\n",
      "Epoch 414/1000\n",
      "22/22 - 0s - 4ms/step - accuracy: 0.9855 - loss: 0.0414 - val_accuracy: 0.7662 - val_loss: 2.1925\n",
      "Epoch 415/1000\n",
      "22/22 - 0s - 5ms/step - accuracy: 0.9928 - loss: 0.0349 - val_accuracy: 0.7403 - val_loss: 2.1827\n",
      "Epoch 416/1000\n",
      "22/22 - 0s - 4ms/step - accuracy: 0.9913 - loss: 0.0327 - val_accuracy: 0.7532 - val_loss: 2.1852\n",
      "Epoch 417/1000\n",
      "22/22 - 0s - 4ms/step - accuracy: 0.9942 - loss: 0.0320 - val_accuracy: 0.7532 - val_loss: 2.2869\n",
      "Epoch 418/1000\n",
      "22/22 - 0s - 5ms/step - accuracy: 0.9913 - loss: 0.0310 - val_accuracy: 0.7532 - val_loss: 2.2795\n",
      "Epoch 419/1000\n",
      "22/22 - 0s - 5ms/step - accuracy: 0.9928 - loss: 0.0321 - val_accuracy: 0.7662 - val_loss: 2.1378\n",
      "Epoch 420/1000\n",
      "22/22 - 0s - 4ms/step - accuracy: 0.9899 - loss: 0.0366 - val_accuracy: 0.7403 - val_loss: 2.2451\n",
      "Epoch 421/1000\n",
      "22/22 - 0s - 6ms/step - accuracy: 0.9870 - loss: 0.0411 - val_accuracy: 0.7403 - val_loss: 2.2990\n",
      "Epoch 422/1000\n",
      "22/22 - 0s - 4ms/step - accuracy: 0.9740 - loss: 0.0556 - val_accuracy: 0.7273 - val_loss: 2.4812\n",
      "Epoch 423/1000\n",
      "22/22 - 0s - 4ms/step - accuracy: 0.9551 - loss: 0.1159 - val_accuracy: 0.7013 - val_loss: 2.2756\n",
      "Epoch 424/1000\n",
      "22/22 - 0s - 4ms/step - accuracy: 0.9566 - loss: 0.1119 - val_accuracy: 0.7013 - val_loss: 2.7127\n",
      "Epoch 425/1000\n",
      "22/22 - 0s - 4ms/step - accuracy: 0.9595 - loss: 0.1167 - val_accuracy: 0.6623 - val_loss: 2.5036\n",
      "Epoch 426/1000\n",
      "22/22 - 0s - 4ms/step - accuracy: 0.9667 - loss: 0.1013 - val_accuracy: 0.7143 - val_loss: 2.2553\n",
      "Epoch 427/1000\n",
      "22/22 - 0s - 4ms/step - accuracy: 0.9667 - loss: 0.0770 - val_accuracy: 0.6623 - val_loss: 2.4125\n",
      "Epoch 428/1000\n",
      "22/22 - 0s - 4ms/step - accuracy: 0.9783 - loss: 0.0752 - val_accuracy: 0.7273 - val_loss: 2.1110\n",
      "Epoch 429/1000\n",
      "22/22 - 0s - 4ms/step - accuracy: 0.9855 - loss: 0.0606 - val_accuracy: 0.7662 - val_loss: 2.5896\n",
      "Epoch 430/1000\n",
      "22/22 - 0s - 5ms/step - accuracy: 0.9725 - loss: 0.0554 - val_accuracy: 0.7143 - val_loss: 2.7094\n",
      "Epoch 431/1000\n",
      "22/22 - 0s - 5ms/step - accuracy: 0.9768 - loss: 0.0788 - val_accuracy: 0.7403 - val_loss: 2.5395\n",
      "Epoch 432/1000\n",
      "22/22 - 0s - 5ms/step - accuracy: 0.9682 - loss: 0.0797 - val_accuracy: 0.7273 - val_loss: 2.5312\n",
      "Epoch 433/1000\n",
      "22/22 - 0s - 7ms/step - accuracy: 0.9725 - loss: 0.0776 - val_accuracy: 0.7143 - val_loss: 2.0824\n",
      "Epoch 434/1000\n",
      "22/22 - 0s - 7ms/step - accuracy: 0.9754 - loss: 0.0733 - val_accuracy: 0.7143 - val_loss: 2.1151\n",
      "Epoch 435/1000\n",
      "22/22 - 0s - 5ms/step - accuracy: 0.9551 - loss: 0.1094 - val_accuracy: 0.7662 - val_loss: 2.3700\n",
      "Epoch 436/1000\n",
      "22/22 - 0s - 5ms/step - accuracy: 0.9667 - loss: 0.0883 - val_accuracy: 0.6883 - val_loss: 2.3977\n",
      "Epoch 437/1000\n",
      "22/22 - 0s - 6ms/step - accuracy: 0.9725 - loss: 0.0773 - val_accuracy: 0.7013 - val_loss: 2.3790\n",
      "Epoch 438/1000\n",
      "22/22 - 0s - 6ms/step - accuracy: 0.9783 - loss: 0.0522 - val_accuracy: 0.7273 - val_loss: 2.4304\n",
      "Epoch 439/1000\n",
      "22/22 - 0s - 6ms/step - accuracy: 0.9942 - loss: 0.0318 - val_accuracy: 0.6883 - val_loss: 2.5279\n",
      "Epoch 440/1000\n",
      "22/22 - 0s - 6ms/step - accuracy: 0.9855 - loss: 0.0348 - val_accuracy: 0.7403 - val_loss: 2.4303\n",
      "Epoch 441/1000\n",
      "22/22 - 0s - 5ms/step - accuracy: 0.9942 - loss: 0.0276 - val_accuracy: 0.7143 - val_loss: 2.6142\n",
      "Epoch 442/1000\n",
      "22/22 - 0s - 5ms/step - accuracy: 0.9913 - loss: 0.0334 - val_accuracy: 0.7532 - val_loss: 2.3768\n",
      "Epoch 443/1000\n",
      "22/22 - 0s - 5ms/step - accuracy: 0.9826 - loss: 0.0463 - val_accuracy: 0.7532 - val_loss: 2.2000\n",
      "Epoch 444/1000\n",
      "22/22 - 0s - 4ms/step - accuracy: 0.9812 - loss: 0.0512 - val_accuracy: 0.7273 - val_loss: 2.6262\n",
      "Epoch 445/1000\n",
      "22/22 - 0s - 4ms/step - accuracy: 0.9841 - loss: 0.0423 - val_accuracy: 0.7013 - val_loss: 2.4567\n",
      "Epoch 446/1000\n",
      "22/22 - 0s - 4ms/step - accuracy: 0.9768 - loss: 0.0617 - val_accuracy: 0.7403 - val_loss: 2.7399\n",
      "Epoch 447/1000\n",
      "22/22 - 0s - 5ms/step - accuracy: 0.9841 - loss: 0.0541 - val_accuracy: 0.7013 - val_loss: 2.5001\n",
      "Epoch 448/1000\n",
      "22/22 - 0s - 5ms/step - accuracy: 0.9682 - loss: 0.0846 - val_accuracy: 0.7922 - val_loss: 2.4004\n",
      "Epoch 449/1000\n",
      "22/22 - 0s - 4ms/step - accuracy: 0.9740 - loss: 0.0721 - val_accuracy: 0.7403 - val_loss: 2.7592\n",
      "Epoch 450/1000\n",
      "22/22 - 0s - 5ms/step - accuracy: 0.9595 - loss: 0.0994 - val_accuracy: 0.6753 - val_loss: 2.9261\n",
      "Epoch 451/1000\n",
      "22/22 - 0s - 5ms/step - accuracy: 0.9378 - loss: 0.1743 - val_accuracy: 0.6364 - val_loss: 3.2826\n",
      "Epoch 452/1000\n",
      "22/22 - 0s - 6ms/step - accuracy: 0.9421 - loss: 0.1735 - val_accuracy: 0.7143 - val_loss: 2.3426\n",
      "Epoch 453/1000\n",
      "22/22 - 0s - 5ms/step - accuracy: 0.9566 - loss: 0.1369 - val_accuracy: 0.7403 - val_loss: 1.9784\n",
      "Epoch 454/1000\n",
      "22/22 - 0s - 5ms/step - accuracy: 0.9349 - loss: 0.1875 - val_accuracy: 0.7143 - val_loss: 2.4061\n",
      "Epoch 455/1000\n",
      "22/22 - 0s - 6ms/step - accuracy: 0.9421 - loss: 0.1502 - val_accuracy: 0.7143 - val_loss: 1.8533\n",
      "Epoch 456/1000\n",
      "22/22 - 0s - 5ms/step - accuracy: 0.9233 - loss: 0.2425 - val_accuracy: 0.6883 - val_loss: 2.8485\n",
      "Epoch 457/1000\n",
      "22/22 - 0s - 6ms/step - accuracy: 0.9465 - loss: 0.1339 - val_accuracy: 0.7532 - val_loss: 2.3260\n",
      "Epoch 458/1000\n",
      "22/22 - 0s - 6ms/step - accuracy: 0.9682 - loss: 0.0913 - val_accuracy: 0.7403 - val_loss: 2.4886\n",
      "Epoch 459/1000\n",
      "22/22 - 0s - 5ms/step - accuracy: 0.9595 - loss: 0.1005 - val_accuracy: 0.7143 - val_loss: 2.5010\n",
      "Epoch 460/1000\n",
      "22/22 - 0s - 6ms/step - accuracy: 0.9682 - loss: 0.0797 - val_accuracy: 0.7013 - val_loss: 2.4609\n",
      "Epoch 461/1000\n",
      "22/22 - 0s - 5ms/step - accuracy: 0.9696 - loss: 0.0861 - val_accuracy: 0.7143 - val_loss: 2.4023\n",
      "Epoch 462/1000\n",
      "22/22 - 0s - 5ms/step - accuracy: 0.9812 - loss: 0.0634 - val_accuracy: 0.7403 - val_loss: 2.6138\n",
      "Epoch 463/1000\n",
      "22/22 - 0s - 5ms/step - accuracy: 0.9870 - loss: 0.0429 - val_accuracy: 0.7273 - val_loss: 2.8218\n",
      "Epoch 464/1000\n",
      "22/22 - 0s - 5ms/step - accuracy: 0.9899 - loss: 0.0340 - val_accuracy: 0.7143 - val_loss: 2.9211\n",
      "Epoch 465/1000\n",
      "22/22 - 0s - 5ms/step - accuracy: 0.9913 - loss: 0.0302 - val_accuracy: 0.7273 - val_loss: 2.9328\n",
      "Epoch 466/1000\n",
      "22/22 - 0s - 6ms/step - accuracy: 0.9957 - loss: 0.0230 - val_accuracy: 0.7403 - val_loss: 2.9901\n",
      "Epoch 467/1000\n",
      "22/22 - 0s - 6ms/step - accuracy: 0.9942 - loss: 0.0226 - val_accuracy: 0.7273 - val_loss: 3.0103\n",
      "Epoch 468/1000\n",
      "22/22 - 0s - 5ms/step - accuracy: 0.9957 - loss: 0.0246 - val_accuracy: 0.7403 - val_loss: 3.1001\n",
      "Epoch 469/1000\n",
      "22/22 - 0s - 5ms/step - accuracy: 0.9942 - loss: 0.0229 - val_accuracy: 0.7273 - val_loss: 2.9689\n",
      "Epoch 470/1000\n",
      "22/22 - 0s - 5ms/step - accuracy: 0.9913 - loss: 0.0240 - val_accuracy: 0.7403 - val_loss: 3.0476\n",
      "Epoch 471/1000\n",
      "22/22 - 0s - 5ms/step - accuracy: 0.9942 - loss: 0.0196 - val_accuracy: 0.7143 - val_loss: 3.0456\n",
      "Epoch 472/1000\n",
      "22/22 - 0s - 4ms/step - accuracy: 0.9942 - loss: 0.0197 - val_accuracy: 0.7273 - val_loss: 3.0710\n",
      "Epoch 473/1000\n",
      "22/22 - 0s - 4ms/step - accuracy: 0.9957 - loss: 0.0206 - val_accuracy: 0.7403 - val_loss: 3.3143\n",
      "Epoch 474/1000\n",
      "22/22 - 0s - 5ms/step - accuracy: 0.9884 - loss: 0.0348 - val_accuracy: 0.6883 - val_loss: 3.4507\n",
      "Epoch 475/1000\n",
      "22/22 - 0s - 4ms/step - accuracy: 0.9855 - loss: 0.0383 - val_accuracy: 0.7532 - val_loss: 3.3730\n",
      "Epoch 476/1000\n",
      "22/22 - 0s - 4ms/step - accuracy: 0.9913 - loss: 0.0362 - val_accuracy: 0.7792 - val_loss: 2.7534\n",
      "Epoch 477/1000\n",
      "22/22 - 0s - 5ms/step - accuracy: 0.9928 - loss: 0.0263 - val_accuracy: 0.7143 - val_loss: 3.1900\n",
      "Epoch 478/1000\n",
      "22/22 - 0s - 5ms/step - accuracy: 0.9913 - loss: 0.0260 - val_accuracy: 0.7662 - val_loss: 3.0080\n",
      "Epoch 479/1000\n",
      "22/22 - 0s - 4ms/step - accuracy: 0.9899 - loss: 0.0312 - val_accuracy: 0.7143 - val_loss: 3.2104\n",
      "Epoch 480/1000\n",
      "22/22 - 0s - 4ms/step - accuracy: 0.9957 - loss: 0.0206 - val_accuracy: 0.7403 - val_loss: 3.1831\n",
      "Epoch 481/1000\n",
      "22/22 - 0s - 4ms/step - accuracy: 0.9957 - loss: 0.0192 - val_accuracy: 0.7532 - val_loss: 3.0923\n",
      "Epoch 482/1000\n",
      "22/22 - 0s - 4ms/step - accuracy: 0.9971 - loss: 0.0184 - val_accuracy: 0.7143 - val_loss: 3.2299\n",
      "Epoch 483/1000\n",
      "22/22 - 0s - 4ms/step - accuracy: 0.9971 - loss: 0.0160 - val_accuracy: 0.7532 - val_loss: 3.3312\n",
      "Epoch 484/1000\n",
      "22/22 - 0s - 4ms/step - accuracy: 0.9971 - loss: 0.0150 - val_accuracy: 0.7403 - val_loss: 3.3461\n",
      "Epoch 485/1000\n",
      "22/22 - 0s - 4ms/step - accuracy: 0.9957 - loss: 0.0182 - val_accuracy: 0.7143 - val_loss: 3.1188\n",
      "Epoch 486/1000\n",
      "22/22 - 0s - 5ms/step - accuracy: 0.9899 - loss: 0.0421 - val_accuracy: 0.7273 - val_loss: 3.3267\n",
      "Epoch 487/1000\n",
      "22/22 - 0s - 4ms/step - accuracy: 0.9826 - loss: 0.0475 - val_accuracy: 0.7662 - val_loss: 3.3159\n",
      "Epoch 488/1000\n",
      "22/22 - 0s - 4ms/step - accuracy: 0.9740 - loss: 0.0846 - val_accuracy: 0.7143 - val_loss: 3.0015\n",
      "Epoch 489/1000\n",
      "22/22 - 0s - 4ms/step - accuracy: 0.9624 - loss: 0.1318 - val_accuracy: 0.7143 - val_loss: 3.2392\n",
      "Epoch 490/1000\n",
      "22/22 - 0s - 4ms/step - accuracy: 0.9595 - loss: 0.1090 - val_accuracy: 0.6753 - val_loss: 3.2887\n",
      "Epoch 491/1000\n",
      "22/22 - 0s - 5ms/step - accuracy: 0.9407 - loss: 0.1683 - val_accuracy: 0.6883 - val_loss: 3.0529\n",
      "Epoch 492/1000\n",
      "22/22 - 0s - 4ms/step - accuracy: 0.9551 - loss: 0.1243 - val_accuracy: 0.7532 - val_loss: 2.6758\n",
      "Epoch 493/1000\n",
      "22/22 - 0s - 4ms/step - accuracy: 0.9421 - loss: 0.1255 - val_accuracy: 0.7403 - val_loss: 2.6348\n",
      "Epoch 494/1000\n",
      "22/22 - 0s - 4ms/step - accuracy: 0.9305 - loss: 0.1850 - val_accuracy: 0.6234 - val_loss: 2.8727\n",
      "Epoch 495/1000\n",
      "22/22 - 0s - 4ms/step - accuracy: 0.9465 - loss: 0.1417 - val_accuracy: 0.7403 - val_loss: 2.5263\n",
      "Epoch 496/1000\n",
      "22/22 - 0s - 4ms/step - accuracy: 0.9609 - loss: 0.1201 - val_accuracy: 0.7273 - val_loss: 2.3324\n",
      "Epoch 497/1000\n",
      "22/22 - 0s - 4ms/step - accuracy: 0.9609 - loss: 0.0885 - val_accuracy: 0.7013 - val_loss: 2.7252\n",
      "Epoch 498/1000\n",
      "22/22 - 0s - 4ms/step - accuracy: 0.9899 - loss: 0.0509 - val_accuracy: 0.7273 - val_loss: 2.9206\n",
      "Epoch 499/1000\n",
      "22/22 - 0s - 4ms/step - accuracy: 0.9913 - loss: 0.0353 - val_accuracy: 0.7013 - val_loss: 2.7665\n",
      "Epoch 500/1000\n",
      "22/22 - 0s - 5ms/step - accuracy: 0.9913 - loss: 0.0258 - val_accuracy: 0.7013 - val_loss: 2.7617\n",
      "Epoch 501/1000\n",
      "22/22 - 0s - 4ms/step - accuracy: 0.9942 - loss: 0.0224 - val_accuracy: 0.7273 - val_loss: 2.8086\n",
      "Epoch 502/1000\n",
      "22/22 - 0s - 4ms/step - accuracy: 0.9957 - loss: 0.0182 - val_accuracy: 0.7403 - val_loss: 2.7646\n",
      "Epoch 503/1000\n",
      "22/22 - 0s - 4ms/step - accuracy: 0.9957 - loss: 0.0178 - val_accuracy: 0.7662 - val_loss: 2.9396\n",
      "Epoch 504/1000\n",
      "22/22 - 0s - 4ms/step - accuracy: 0.9957 - loss: 0.0167 - val_accuracy: 0.7273 - val_loss: 3.0334\n",
      "Epoch 505/1000\n",
      "22/22 - 0s - 5ms/step - accuracy: 0.9957 - loss: 0.0169 - val_accuracy: 0.7403 - val_loss: 2.9280\n",
      "Epoch 506/1000\n",
      "22/22 - 0s - 4ms/step - accuracy: 0.9928 - loss: 0.0209 - val_accuracy: 0.7662 - val_loss: 2.9864\n",
      "Epoch 507/1000\n",
      "22/22 - 0s - 4ms/step - accuracy: 0.9957 - loss: 0.0219 - val_accuracy: 0.7403 - val_loss: 3.0724\n",
      "Epoch 508/1000\n",
      "22/22 - 0s - 6ms/step - accuracy: 0.9942 - loss: 0.0170 - val_accuracy: 0.7403 - val_loss: 2.8748\n",
      "Epoch 509/1000\n",
      "22/22 - 0s - 4ms/step - accuracy: 0.9971 - loss: 0.0162 - val_accuracy: 0.7273 - val_loss: 3.0533\n",
      "Epoch 510/1000\n",
      "22/22 - 0s - 4ms/step - accuracy: 0.9942 - loss: 0.0185 - val_accuracy: 0.7662 - val_loss: 3.0543\n",
      "Epoch 511/1000\n",
      "22/22 - 0s - 4ms/step - accuracy: 0.9957 - loss: 0.0201 - val_accuracy: 0.7273 - val_loss: 3.0015\n",
      "Epoch 512/1000\n",
      "22/22 - 0s - 4ms/step - accuracy: 0.9913 - loss: 0.0196 - val_accuracy: 0.7273 - val_loss: 2.9667\n",
      "Epoch 513/1000\n",
      "22/22 - 0s - 4ms/step - accuracy: 0.9928 - loss: 0.0172 - val_accuracy: 0.7532 - val_loss: 3.1326\n",
      "Epoch 514/1000\n",
      "22/22 - 0s - 6ms/step - accuracy: 0.9957 - loss: 0.0166 - val_accuracy: 0.7403 - val_loss: 3.0167\n",
      "Epoch 515/1000\n",
      "22/22 - 0s - 5ms/step - accuracy: 0.9942 - loss: 0.0162 - val_accuracy: 0.7403 - val_loss: 3.1406\n",
      "Epoch 516/1000\n",
      "22/22 - 0s - 5ms/step - accuracy: 0.9942 - loss: 0.0196 - val_accuracy: 0.7403 - val_loss: 3.0795\n",
      "Epoch 517/1000\n",
      "22/22 - 0s - 5ms/step - accuracy: 0.9913 - loss: 0.0242 - val_accuracy: 0.7532 - val_loss: 3.1303\n",
      "Epoch 518/1000\n",
      "22/22 - 0s - 5ms/step - accuracy: 0.9928 - loss: 0.0174 - val_accuracy: 0.7532 - val_loss: 3.1670\n",
      "Epoch 519/1000\n",
      "22/22 - 0s - 5ms/step - accuracy: 0.9957 - loss: 0.0165 - val_accuracy: 0.7532 - val_loss: 3.2613\n",
      "Epoch 520/1000\n",
      "22/22 - 0s - 5ms/step - accuracy: 0.9971 - loss: 0.0111 - val_accuracy: 0.7532 - val_loss: 3.2147\n",
      "Epoch 521/1000\n",
      "22/22 - 0s - 4ms/step - accuracy: 0.9971 - loss: 0.0109 - val_accuracy: 0.7403 - val_loss: 3.1820\n",
      "Epoch 522/1000\n",
      "22/22 - 0s - 4ms/step - accuracy: 0.9986 - loss: 0.0097 - val_accuracy: 0.7403 - val_loss: 3.2646\n",
      "Epoch 523/1000\n",
      "22/22 - 0s - 5ms/step - accuracy: 0.9957 - loss: 0.0121 - val_accuracy: 0.7273 - val_loss: 3.2980\n",
      "Epoch 524/1000\n",
      "22/22 - 0s - 4ms/step - accuracy: 0.9942 - loss: 0.0142 - val_accuracy: 0.7403 - val_loss: 3.1651\n",
      "Epoch 525/1000\n",
      "22/22 - 0s - 4ms/step - accuracy: 0.9986 - loss: 0.0101 - val_accuracy: 0.7532 - val_loss: 3.2141\n",
      "Epoch 526/1000\n",
      "22/22 - 0s - 5ms/step - accuracy: 0.9986 - loss: 0.0087 - val_accuracy: 0.7532 - val_loss: 3.3935\n",
      "Epoch 527/1000\n",
      "22/22 - 0s - 4ms/step - accuracy: 0.9986 - loss: 0.0090 - val_accuracy: 0.7273 - val_loss: 3.2000\n",
      "Epoch 528/1000\n",
      "22/22 - 0s - 4ms/step - accuracy: 0.9942 - loss: 0.0166 - val_accuracy: 0.7403 - val_loss: 3.3230\n",
      "Epoch 529/1000\n",
      "22/22 - 0s - 4ms/step - accuracy: 0.9899 - loss: 0.0250 - val_accuracy: 0.7143 - val_loss: 3.3840\n",
      "Epoch 530/1000\n",
      "22/22 - 0s - 4ms/step - accuracy: 0.9913 - loss: 0.0252 - val_accuracy: 0.7143 - val_loss: 3.1105\n",
      "Epoch 531/1000\n",
      "22/22 - 0s - 4ms/step - accuracy: 0.9884 - loss: 0.0332 - val_accuracy: 0.7143 - val_loss: 3.5533\n",
      "Epoch 532/1000\n",
      "22/22 - 0s - 4ms/step - accuracy: 0.9725 - loss: 0.0623 - val_accuracy: 0.6753 - val_loss: 3.7662\n",
      "Epoch 533/1000\n",
      "22/22 - 0s - 4ms/step - accuracy: 0.9190 - loss: 0.2370 - val_accuracy: 0.7013 - val_loss: 2.6411\n",
      "Epoch 534/1000\n",
      "22/22 - 0s - 5ms/step - accuracy: 0.9045 - loss: 0.2727 - val_accuracy: 0.7273 - val_loss: 2.4704\n",
      "Epoch 535/1000\n",
      "22/22 - 0s - 5ms/step - accuracy: 0.9175 - loss: 0.2618 - val_accuracy: 0.7532 - val_loss: 2.1996\n",
      "Epoch 536/1000\n",
      "22/22 - 0s - 5ms/step - accuracy: 0.9190 - loss: 0.2181 - val_accuracy: 0.7143 - val_loss: 1.7743\n",
      "Epoch 537/1000\n",
      "22/22 - 0s - 4ms/step - accuracy: 0.9059 - loss: 0.2475 - val_accuracy: 0.7532 - val_loss: 2.3482\n",
      "Epoch 538/1000\n",
      "22/22 - 0s - 4ms/step - accuracy: 0.9045 - loss: 0.2662 - val_accuracy: 0.7143 - val_loss: 2.0771\n",
      "Epoch 539/1000\n",
      "22/22 - 0s - 4ms/step - accuracy: 0.9450 - loss: 0.1493 - val_accuracy: 0.7532 - val_loss: 2.5676\n",
      "Epoch 540/1000\n",
      "22/22 - 0s - 4ms/step - accuracy: 0.9682 - loss: 0.0947 - val_accuracy: 0.7143 - val_loss: 2.2133\n",
      "Epoch 541/1000\n",
      "22/22 - 0s - 4ms/step - accuracy: 0.9768 - loss: 0.0696 - val_accuracy: 0.7532 - val_loss: 2.3816\n",
      "Epoch 542/1000\n",
      "22/22 - 0s - 5ms/step - accuracy: 0.9899 - loss: 0.0451 - val_accuracy: 0.7143 - val_loss: 2.4309\n",
      "Epoch 543/1000\n",
      "22/22 - 0s - 4ms/step - accuracy: 0.9913 - loss: 0.0320 - val_accuracy: 0.7143 - val_loss: 2.6090\n",
      "Epoch 544/1000\n",
      "22/22 - 0s - 4ms/step - accuracy: 0.9942 - loss: 0.0396 - val_accuracy: 0.7013 - val_loss: 2.7665\n",
      "Epoch 545/1000\n",
      "22/22 - 0s - 4ms/step - accuracy: 0.9899 - loss: 0.0410 - val_accuracy: 0.7273 - val_loss: 2.4990\n",
      "Epoch 546/1000\n",
      "22/22 - 0s - 4ms/step - accuracy: 0.9841 - loss: 0.0424 - val_accuracy: 0.7662 - val_loss: 2.6701\n",
      "Epoch 547/1000\n",
      "22/22 - 0s - 5ms/step - accuracy: 0.9841 - loss: 0.0511 - val_accuracy: 0.7273 - val_loss: 2.5897\n",
      "Epoch 548/1000\n",
      "22/22 - 0s - 4ms/step - accuracy: 0.9826 - loss: 0.0614 - val_accuracy: 0.7532 - val_loss: 2.4954\n",
      "Epoch 549/1000\n",
      "22/22 - 0s - 4ms/step - accuracy: 0.9855 - loss: 0.0481 - val_accuracy: 0.7532 - val_loss: 2.4295\n",
      "Epoch 550/1000\n",
      "22/22 - 0s - 4ms/step - accuracy: 0.9826 - loss: 0.0475 - val_accuracy: 0.7403 - val_loss: 2.6818\n",
      "Epoch 551/1000\n",
      "22/22 - 0s - 4ms/step - accuracy: 0.9884 - loss: 0.0319 - val_accuracy: 0.7662 - val_loss: 2.6670\n",
      "Epoch 552/1000\n",
      "22/22 - 0s - 5ms/step - accuracy: 0.9957 - loss: 0.0260 - val_accuracy: 0.7273 - val_loss: 2.6192\n",
      "Epoch 553/1000\n",
      "22/22 - 0s - 4ms/step - accuracy: 0.9986 - loss: 0.0157 - val_accuracy: 0.7273 - val_loss: 2.6524\n",
      "Epoch 554/1000\n",
      "22/22 - 0s - 4ms/step - accuracy: 0.9971 - loss: 0.0129 - val_accuracy: 0.7403 - val_loss: 2.6505\n",
      "Epoch 555/1000\n",
      "22/22 - 0s - 4ms/step - accuracy: 0.9971 - loss: 0.0155 - val_accuracy: 0.7273 - val_loss: 2.7680\n",
      "Epoch 556/1000\n",
      "22/22 - 0s - 5ms/step - accuracy: 0.9942 - loss: 0.0174 - val_accuracy: 0.7013 - val_loss: 2.7731\n",
      "Epoch 557/1000\n",
      "22/22 - 0s - 5ms/step - accuracy: 0.9957 - loss: 0.0197 - val_accuracy: 0.7532 - val_loss: 2.7636\n",
      "Epoch 558/1000\n",
      "22/22 - 0s - 4ms/step - accuracy: 0.9957 - loss: 0.0140 - val_accuracy: 0.7273 - val_loss: 2.7500\n",
      "Epoch 559/1000\n",
      "22/22 - 0s - 4ms/step - accuracy: 0.9971 - loss: 0.0112 - val_accuracy: 0.7143 - val_loss: 2.8248\n",
      "Epoch 560/1000\n",
      "22/22 - 0s - 4ms/step - accuracy: 0.9971 - loss: 0.0103 - val_accuracy: 0.7403 - val_loss: 2.7705\n",
      "Epoch 561/1000\n",
      "22/22 - 0s - 6ms/step - accuracy: 0.9971 - loss: 0.0106 - val_accuracy: 0.7013 - val_loss: 2.9055\n",
      "Epoch 562/1000\n",
      "22/22 - 0s - 6ms/step - accuracy: 0.9971 - loss: 0.0125 - val_accuracy: 0.7273 - val_loss: 2.8941\n",
      "Epoch 563/1000\n",
      "22/22 - 0s - 4ms/step - accuracy: 0.9971 - loss: 0.0091 - val_accuracy: 0.7403 - val_loss: 2.8362\n",
      "Epoch 564/1000\n",
      "22/22 - 0s - 5ms/step - accuracy: 0.9971 - loss: 0.0097 - val_accuracy: 0.7403 - val_loss: 2.8601\n",
      "Epoch 565/1000\n",
      "22/22 - 0s - 4ms/step - accuracy: 0.9971 - loss: 0.0105 - val_accuracy: 0.7273 - val_loss: 2.8112\n",
      "Epoch 566/1000\n",
      "22/22 - 0s - 4ms/step - accuracy: 0.9986 - loss: 0.0085 - val_accuracy: 0.7273 - val_loss: 2.9786\n",
      "Epoch 567/1000\n",
      "22/22 - 0s - 4ms/step - accuracy: 1.0000 - loss: 0.0074 - val_accuracy: 0.7273 - val_loss: 2.9145\n",
      "Epoch 568/1000\n",
      "22/22 - 0s - 5ms/step - accuracy: 0.9986 - loss: 0.0076 - val_accuracy: 0.7273 - val_loss: 2.9381\n",
      "Epoch 569/1000\n",
      "22/22 - 0s - 4ms/step - accuracy: 1.0000 - loss: 0.0069 - val_accuracy: 0.7403 - val_loss: 2.9129\n",
      "Epoch 570/1000\n",
      "22/22 - 0s - 4ms/step - accuracy: 0.9971 - loss: 0.0077 - val_accuracy: 0.7403 - val_loss: 2.8837\n",
      "Epoch 571/1000\n",
      "22/22 - 0s - 4ms/step - accuracy: 0.9971 - loss: 0.0107 - val_accuracy: 0.7273 - val_loss: 3.0478\n",
      "Epoch 572/1000\n",
      "22/22 - 0s - 4ms/step - accuracy: 0.9957 - loss: 0.0118 - val_accuracy: 0.7143 - val_loss: 3.0072\n",
      "Epoch 573/1000\n",
      "22/22 - 0s - 4ms/step - accuracy: 0.9986 - loss: 0.0094 - val_accuracy: 0.7403 - val_loss: 2.9300\n",
      "Epoch 574/1000\n",
      "22/22 - 0s - 4ms/step - accuracy: 1.0000 - loss: 0.0070 - val_accuracy: 0.7403 - val_loss: 3.0176\n",
      "Epoch 575/1000\n",
      "22/22 - 0s - 4ms/step - accuracy: 1.0000 - loss: 0.0071 - val_accuracy: 0.7273 - val_loss: 2.9571\n",
      "Epoch 576/1000\n",
      "22/22 - 0s - 4ms/step - accuracy: 0.9971 - loss: 0.0099 - val_accuracy: 0.7273 - val_loss: 3.0177\n",
      "Epoch 577/1000\n",
      "22/22 - 0s - 4ms/step - accuracy: 0.9986 - loss: 0.0063 - val_accuracy: 0.7273 - val_loss: 3.0051\n",
      "Epoch 578/1000\n",
      "22/22 - 0s - 5ms/step - accuracy: 0.9986 - loss: 0.0069 - val_accuracy: 0.7273 - val_loss: 2.9624\n",
      "Epoch 579/1000\n",
      "22/22 - 0s - 4ms/step - accuracy: 0.9957 - loss: 0.0117 - val_accuracy: 0.7403 - val_loss: 2.8867\n",
      "Epoch 580/1000\n",
      "22/22 - 0s - 4ms/step - accuracy: 0.9986 - loss: 0.0087 - val_accuracy: 0.7143 - val_loss: 3.1431\n",
      "Epoch 581/1000\n",
      "22/22 - 0s - 4ms/step - accuracy: 0.9971 - loss: 0.0101 - val_accuracy: 0.7143 - val_loss: 3.0844\n",
      "Epoch 582/1000\n",
      "22/22 - 0s - 4ms/step - accuracy: 1.0000 - loss: 0.0095 - val_accuracy: 0.7403 - val_loss: 3.0403\n",
      "Epoch 583/1000\n",
      "22/22 - 0s - 5ms/step - accuracy: 0.9971 - loss: 0.0117 - val_accuracy: 0.7273 - val_loss: 2.8823\n",
      "Epoch 584/1000\n",
      "22/22 - 0s - 4ms/step - accuracy: 0.9942 - loss: 0.0182 - val_accuracy: 0.7403 - val_loss: 3.0112\n",
      "Epoch 585/1000\n",
      "22/22 - 0s - 4ms/step - accuracy: 0.9928 - loss: 0.0169 - val_accuracy: 0.7273 - val_loss: 3.1941\n",
      "Epoch 586/1000\n",
      "22/22 - 0s - 4ms/step - accuracy: 0.9942 - loss: 0.0357 - val_accuracy: 0.7013 - val_loss: 3.3709\n",
      "Epoch 587/1000\n",
      "22/22 - 0s - 5ms/step - accuracy: 0.9870 - loss: 0.0365 - val_accuracy: 0.7403 - val_loss: 2.9323\n",
      "Epoch 588/1000\n",
      "22/22 - 0s - 4ms/step - accuracy: 0.9740 - loss: 0.0603 - val_accuracy: 0.7662 - val_loss: 3.2107\n",
      "Epoch 589/1000\n",
      "22/22 - 0s - 4ms/step - accuracy: 0.9363 - loss: 0.2053 - val_accuracy: 0.7013 - val_loss: 2.4919\n",
      "Epoch 590/1000\n",
      "22/22 - 0s - 4ms/step - accuracy: 0.8032 - loss: 0.8844 - val_accuracy: 0.6364 - val_loss: 2.2781\n",
      "Epoch 591/1000\n",
      "22/22 - 0s - 4ms/step - accuracy: 0.7815 - loss: 0.5180 - val_accuracy: 0.7013 - val_loss: 1.5365\n",
      "Epoch 592/1000\n",
      "22/22 - 0s - 5ms/step - accuracy: 0.8509 - loss: 0.3441 - val_accuracy: 0.6753 - val_loss: 1.8038\n",
      "Epoch 593/1000\n",
      "22/22 - 0s - 4ms/step - accuracy: 0.8538 - loss: 0.3214 - val_accuracy: 0.7273 - val_loss: 1.6991\n",
      "Epoch 594/1000\n",
      "22/22 - 0s - 4ms/step - accuracy: 0.8871 - loss: 0.2794 - val_accuracy: 0.7013 - val_loss: 1.6801\n",
      "Epoch 595/1000\n",
      "22/22 - 0s - 4ms/step - accuracy: 0.9146 - loss: 0.2330 - val_accuracy: 0.7013 - val_loss: 1.6045\n",
      "Epoch 596/1000\n",
      "22/22 - 0s - 4ms/step - accuracy: 0.9204 - loss: 0.1937 - val_accuracy: 0.7403 - val_loss: 1.6379\n",
      "Epoch 597/1000\n",
      "22/22 - 0s - 5ms/step - accuracy: 0.9291 - loss: 0.1715 - val_accuracy: 0.7013 - val_loss: 1.8255\n",
      "Epoch 598/1000\n",
      "22/22 - 0s - 4ms/step - accuracy: 0.9276 - loss: 0.1786 - val_accuracy: 0.7013 - val_loss: 1.6924\n",
      "Epoch 599/1000\n",
      "22/22 - 0s - 4ms/step - accuracy: 0.9334 - loss: 0.1649 - val_accuracy: 0.7532 - val_loss: 1.9916\n",
      "Epoch 600/1000\n",
      "22/22 - 0s - 4ms/step - accuracy: 0.9493 - loss: 0.1431 - val_accuracy: 0.7273 - val_loss: 2.1153\n",
      "Epoch 601/1000\n",
      "22/22 - 0s - 4ms/step - accuracy: 0.9508 - loss: 0.1396 - val_accuracy: 0.7273 - val_loss: 2.0890\n",
      "Epoch 602/1000\n",
      "22/22 - 0s - 5ms/step - accuracy: 0.9320 - loss: 0.1508 - val_accuracy: 0.6753 - val_loss: 1.9388\n",
      "Epoch 603/1000\n",
      "22/22 - 0s - 5ms/step - accuracy: 0.9522 - loss: 0.1314 - val_accuracy: 0.7143 - val_loss: 2.0590\n",
      "Epoch 604/1000\n",
      "22/22 - 0s - 4ms/step - accuracy: 0.9638 - loss: 0.1042 - val_accuracy: 0.7403 - val_loss: 2.0585\n",
      "Epoch 605/1000\n",
      "22/22 - 0s - 4ms/step - accuracy: 0.9754 - loss: 0.0865 - val_accuracy: 0.7273 - val_loss: 2.1670\n",
      "Epoch 606/1000\n",
      "22/22 - 0s - 4ms/step - accuracy: 0.9768 - loss: 0.0755 - val_accuracy: 0.7273 - val_loss: 2.1490\n",
      "Epoch 607/1000\n",
      "22/22 - 0s - 5ms/step - accuracy: 0.9855 - loss: 0.0644 - val_accuracy: 0.7403 - val_loss: 2.2766\n",
      "Epoch 608/1000\n",
      "22/22 - 0s - 6ms/step - accuracy: 0.9826 - loss: 0.0578 - val_accuracy: 0.7792 - val_loss: 2.0814\n",
      "Epoch 609/1000\n",
      "22/22 - 0s - 4ms/step - accuracy: 0.9725 - loss: 0.0791 - val_accuracy: 0.7532 - val_loss: 2.1858\n",
      "Epoch 610/1000\n",
      "22/22 - 0s - 4ms/step - accuracy: 0.9768 - loss: 0.0697 - val_accuracy: 0.7013 - val_loss: 2.2168\n",
      "Epoch 611/1000\n",
      "22/22 - 0s - 5ms/step - accuracy: 0.9754 - loss: 0.0786 - val_accuracy: 0.7662 - val_loss: 2.4467\n",
      "Epoch 612/1000\n",
      "22/22 - 0s - 5ms/step - accuracy: 0.9812 - loss: 0.0656 - val_accuracy: 0.7532 - val_loss: 2.4533\n",
      "Epoch 613/1000\n",
      "22/22 - 0s - 4ms/step - accuracy: 0.9768 - loss: 0.0792 - val_accuracy: 0.7403 - val_loss: 2.1998\n",
      "Epoch 614/1000\n",
      "22/22 - 0s - 4ms/step - accuracy: 0.9754 - loss: 0.0705 - val_accuracy: 0.6753 - val_loss: 2.4923\n",
      "Epoch 615/1000\n",
      "22/22 - 0s - 5ms/step - accuracy: 0.9855 - loss: 0.0652 - val_accuracy: 0.7662 - val_loss: 2.5342\n",
      "Epoch 616/1000\n",
      "22/22 - 0s - 5ms/step - accuracy: 0.9884 - loss: 0.0436 - val_accuracy: 0.7792 - val_loss: 2.2625\n",
      "Epoch 617/1000\n",
      "22/22 - 0s - 4ms/step - accuracy: 0.9942 - loss: 0.0403 - val_accuracy: 0.7532 - val_loss: 2.4911\n",
      "Epoch 618/1000\n",
      "22/22 - 0s - 4ms/step - accuracy: 0.9942 - loss: 0.0383 - val_accuracy: 0.7403 - val_loss: 2.3586\n",
      "Epoch 619/1000\n",
      "22/22 - 0s - 4ms/step - accuracy: 0.9826 - loss: 0.0377 - val_accuracy: 0.7143 - val_loss: 2.4599\n",
      "Epoch 620/1000\n",
      "22/22 - 0s - 4ms/step - accuracy: 0.9942 - loss: 0.0339 - val_accuracy: 0.7662 - val_loss: 2.6327\n",
      "Epoch 621/1000\n",
      "22/22 - 0s - 5ms/step - accuracy: 0.9870 - loss: 0.0335 - val_accuracy: 0.7403 - val_loss: 2.3962\n",
      "Epoch 622/1000\n",
      "22/22 - 0s - 4ms/step - accuracy: 0.9928 - loss: 0.0302 - val_accuracy: 0.7403 - val_loss: 2.4799\n",
      "Epoch 623/1000\n",
      "22/22 - 0s - 5ms/step - accuracy: 0.9942 - loss: 0.0295 - val_accuracy: 0.7273 - val_loss: 2.5012\n",
      "Epoch 624/1000\n",
      "22/22 - 0s - 4ms/step - accuracy: 0.9957 - loss: 0.0263 - val_accuracy: 0.7662 - val_loss: 2.6448\n",
      "Epoch 625/1000\n",
      "22/22 - 0s - 4ms/step - accuracy: 0.9841 - loss: 0.0658 - val_accuracy: 0.7532 - val_loss: 2.5253\n",
      "Epoch 626/1000\n",
      "22/22 - 0s - 4ms/step - accuracy: 0.9812 - loss: 0.0578 - val_accuracy: 0.7403 - val_loss: 2.1557\n",
      "Epoch 627/1000\n",
      "22/22 - 0s - 4ms/step - accuracy: 0.9638 - loss: 0.0917 - val_accuracy: 0.7662 - val_loss: 2.6143\n",
      "Epoch 628/1000\n",
      "22/22 - 0s - 5ms/step - accuracy: 0.9682 - loss: 0.0770 - val_accuracy: 0.7013 - val_loss: 2.6169\n",
      "Epoch 629/1000\n",
      "22/22 - 0s - 4ms/step - accuracy: 0.9711 - loss: 0.0997 - val_accuracy: 0.7273 - val_loss: 2.8619\n",
      "Epoch 630/1000\n",
      "22/22 - 0s - 4ms/step - accuracy: 0.9247 - loss: 0.2195 - val_accuracy: 0.6753 - val_loss: 2.5667\n",
      "Epoch 631/1000\n",
      "22/22 - 0s - 5ms/step - accuracy: 0.8857 - loss: 0.2903 - val_accuracy: 0.6364 - val_loss: 2.1684\n",
      "Epoch 632/1000\n",
      "22/22 - 0s - 4ms/step - accuracy: 0.8495 - loss: 0.4769 - val_accuracy: 0.7143 - val_loss: 2.8240\n",
      "Epoch 633/1000\n",
      "22/22 - 0s - 4ms/step - accuracy: 0.8857 - loss: 0.3479 - val_accuracy: 0.7013 - val_loss: 1.7367\n",
      "Epoch 634/1000\n",
      "22/22 - 0s - 4ms/step - accuracy: 0.9219 - loss: 0.2016 - val_accuracy: 0.7403 - val_loss: 1.8210\n",
      "Epoch 635/1000\n",
      "22/22 - 0s - 5ms/step - accuracy: 0.9465 - loss: 0.1279 - val_accuracy: 0.7792 - val_loss: 2.1354\n",
      "Epoch 636/1000\n",
      "22/22 - 0s - 5ms/step - accuracy: 0.9696 - loss: 0.0886 - val_accuracy: 0.7403 - val_loss: 2.0286\n",
      "Epoch 637/1000\n",
      "22/22 - 0s - 4ms/step - accuracy: 0.9826 - loss: 0.0602 - val_accuracy: 0.7532 - val_loss: 2.1744\n",
      "Epoch 638/1000\n",
      "22/22 - 0s - 4ms/step - accuracy: 0.9957 - loss: 0.0420 - val_accuracy: 0.7532 - val_loss: 2.3605\n",
      "Epoch 639/1000\n",
      "22/22 - 0s - 5ms/step - accuracy: 0.9942 - loss: 0.0348 - val_accuracy: 0.7662 - val_loss: 2.3086\n",
      "Epoch 640/1000\n",
      "22/22 - 0s - 5ms/step - accuracy: 0.9942 - loss: 0.0292 - val_accuracy: 0.7403 - val_loss: 2.4842\n",
      "Epoch 641/1000\n",
      "22/22 - 0s - 5ms/step - accuracy: 0.9986 - loss: 0.0257 - val_accuracy: 0.7532 - val_loss: 2.4308\n",
      "Epoch 642/1000\n",
      "22/22 - 0s - 5ms/step - accuracy: 0.9957 - loss: 0.0284 - val_accuracy: 0.7403 - val_loss: 2.4043\n",
      "Epoch 643/1000\n",
      "22/22 - 0s - 5ms/step - accuracy: 0.9986 - loss: 0.0221 - val_accuracy: 0.7143 - val_loss: 2.6167\n",
      "Epoch 644/1000\n",
      "22/22 - 0s - 5ms/step - accuracy: 0.9986 - loss: 0.0201 - val_accuracy: 0.7403 - val_loss: 2.3902\n",
      "Epoch 645/1000\n",
      "22/22 - 0s - 5ms/step - accuracy: 1.0000 - loss: 0.0184 - val_accuracy: 0.7403 - val_loss: 2.6492\n",
      "Epoch 646/1000\n",
      "22/22 - 0s - 4ms/step - accuracy: 0.9971 - loss: 0.0169 - val_accuracy: 0.7403 - val_loss: 2.4881\n",
      "Epoch 647/1000\n",
      "22/22 - 0s - 4ms/step - accuracy: 0.9986 - loss: 0.0180 - val_accuracy: 0.7273 - val_loss: 2.6572\n",
      "Epoch 648/1000\n",
      "22/22 - 0s - 4ms/step - accuracy: 0.9913 - loss: 0.0436 - val_accuracy: 0.7143 - val_loss: 2.6443\n",
      "Epoch 649/1000\n",
      "22/22 - 0s - 4ms/step - accuracy: 0.9884 - loss: 0.0331 - val_accuracy: 0.7273 - val_loss: 2.4407\n",
      "Epoch 650/1000\n",
      "22/22 - 0s - 5ms/step - accuracy: 0.9899 - loss: 0.0301 - val_accuracy: 0.7403 - val_loss: 2.5873\n",
      "Epoch 651/1000\n",
      "22/22 - 0s - 4ms/step - accuracy: 0.9913 - loss: 0.0304 - val_accuracy: 0.7273 - val_loss: 2.5274\n",
      "Epoch 652/1000\n",
      "22/22 - 0s - 4ms/step - accuracy: 0.9928 - loss: 0.0284 - val_accuracy: 0.7273 - val_loss: 2.7492\n",
      "Epoch 653/1000\n",
      "22/22 - 0s - 4ms/step - accuracy: 0.9928 - loss: 0.0377 - val_accuracy: 0.7532 - val_loss: 2.5565\n",
      "Epoch 654/1000\n",
      "22/22 - 0s - 4ms/step - accuracy: 0.9884 - loss: 0.0319 - val_accuracy: 0.7143 - val_loss: 2.6048\n",
      "Epoch 655/1000\n",
      "22/22 - 0s - 4ms/step - accuracy: 0.9942 - loss: 0.0270 - val_accuracy: 0.7013 - val_loss: 2.9862\n",
      "Epoch 656/1000\n",
      "22/22 - 0s - 5ms/step - accuracy: 0.9783 - loss: 0.0746 - val_accuracy: 0.7403 - val_loss: 2.5358\n",
      "Epoch 657/1000\n",
      "22/22 - 0s - 4ms/step - accuracy: 0.9841 - loss: 0.0479 - val_accuracy: 0.7143 - val_loss: 2.7002\n",
      "Epoch 658/1000\n",
      "22/22 - 0s - 5ms/step - accuracy: 0.9884 - loss: 0.0422 - val_accuracy: 0.7143 - val_loss: 2.8106\n",
      "Epoch 659/1000\n",
      "22/22 - 0s - 4ms/step - accuracy: 0.9783 - loss: 0.0572 - val_accuracy: 0.7013 - val_loss: 3.0392\n",
      "Epoch 660/1000\n",
      "22/22 - 0s - 4ms/step - accuracy: 0.9957 - loss: 0.0425 - val_accuracy: 0.7273 - val_loss: 2.8051\n",
      "Epoch 661/1000\n",
      "22/22 - 0s - 4ms/step - accuracy: 0.9928 - loss: 0.0338 - val_accuracy: 0.7273 - val_loss: 2.6915\n",
      "Epoch 662/1000\n",
      "22/22 - 0s - 5ms/step - accuracy: 0.9928 - loss: 0.0437 - val_accuracy: 0.7143 - val_loss: 2.6532\n",
      "Epoch 663/1000\n",
      "22/22 - 0s - 4ms/step - accuracy: 0.9928 - loss: 0.0266 - val_accuracy: 0.7013 - val_loss: 3.0246\n",
      "Epoch 664/1000\n",
      "22/22 - 0s - 5ms/step - accuracy: 0.9913 - loss: 0.0229 - val_accuracy: 0.7143 - val_loss: 2.8524\n",
      "Epoch 665/1000\n",
      "22/22 - 0s - 4ms/step - accuracy: 0.9957 - loss: 0.0236 - val_accuracy: 0.7532 - val_loss: 2.6594\n",
      "Epoch 666/1000\n",
      "22/22 - 0s - 5ms/step - accuracy: 0.9913 - loss: 0.0273 - val_accuracy: 0.7403 - val_loss: 2.8333\n",
      "Epoch 667/1000\n",
      "22/22 - 0s - 5ms/step - accuracy: 0.9942 - loss: 0.0299 - val_accuracy: 0.7143 - val_loss: 2.8493\n",
      "Epoch 668/1000\n",
      "22/22 - 0s - 4ms/step - accuracy: 0.9899 - loss: 0.0302 - val_accuracy: 0.7403 - val_loss: 2.7062\n",
      "Epoch 669/1000\n",
      "22/22 - 0s - 4ms/step - accuracy: 0.9870 - loss: 0.0471 - val_accuracy: 0.7013 - val_loss: 2.8452\n",
      "Epoch 670/1000\n",
      "22/22 - 0s - 4ms/step - accuracy: 0.9247 - loss: 0.2722 - val_accuracy: 0.7143 - val_loss: 2.2493\n",
      "Epoch 671/1000\n",
      "22/22 - 0s - 4ms/step - accuracy: 0.8944 - loss: 0.3246 - val_accuracy: 0.6234 - val_loss: 2.6054\n",
      "Epoch 672/1000\n",
      "22/22 - 0s - 4ms/step - accuracy: 0.9190 - loss: 0.2080 - val_accuracy: 0.7273 - val_loss: 2.0302\n",
      "Epoch 673/1000\n",
      "22/22 - 0s - 4ms/step - accuracy: 0.9465 - loss: 0.1444 - val_accuracy: 0.7403 - val_loss: 2.7310\n",
      "Epoch 674/1000\n",
      "22/22 - 0s - 4ms/step - accuracy: 0.9465 - loss: 0.1373 - val_accuracy: 0.7922 - val_loss: 1.6189\n",
      "Epoch 675/1000\n",
      "22/22 - 0s - 5ms/step - accuracy: 0.9667 - loss: 0.1144 - val_accuracy: 0.7273 - val_loss: 2.5091\n",
      "Epoch 676/1000\n",
      "22/22 - 0s - 5ms/step - accuracy: 0.9624 - loss: 0.1011 - val_accuracy: 0.7273 - val_loss: 2.8615\n",
      "Epoch 677/1000\n",
      "22/22 - 0s - 4ms/step - accuracy: 0.9797 - loss: 0.0666 - val_accuracy: 0.7403 - val_loss: 2.9615\n",
      "Epoch 678/1000\n",
      "22/22 - 0s - 4ms/step - accuracy: 0.9899 - loss: 0.0439 - val_accuracy: 0.7662 - val_loss: 2.7579\n",
      "Epoch 679/1000\n",
      "22/22 - 0s - 4ms/step - accuracy: 0.9971 - loss: 0.0251 - val_accuracy: 0.7532 - val_loss: 2.8061\n",
      "Epoch 680/1000\n",
      "22/22 - 0s - 4ms/step - accuracy: 0.9986 - loss: 0.0203 - val_accuracy: 0.7403 - val_loss: 2.9060\n",
      "Epoch 681/1000\n",
      "22/22 - 0s - 6ms/step - accuracy: 0.9971 - loss: 0.0173 - val_accuracy: 0.7273 - val_loss: 2.9988\n",
      "Epoch 682/1000\n",
      "22/22 - 0s - 6ms/step - accuracy: 0.9971 - loss: 0.0182 - val_accuracy: 0.7273 - val_loss: 3.0213\n",
      "Epoch 683/1000\n",
      "22/22 - 0s - 5ms/step - accuracy: 1.0000 - loss: 0.0118 - val_accuracy: 0.7403 - val_loss: 3.0915\n",
      "Epoch 684/1000\n",
      "22/22 - 0s - 4ms/step - accuracy: 1.0000 - loss: 0.0102 - val_accuracy: 0.7273 - val_loss: 3.0625\n",
      "Epoch 685/1000\n",
      "22/22 - 0s - 5ms/step - accuracy: 1.0000 - loss: 0.0090 - val_accuracy: 0.7273 - val_loss: 3.1458\n",
      "Epoch 686/1000\n",
      "22/22 - 0s - 5ms/step - accuracy: 1.0000 - loss: 0.0088 - val_accuracy: 0.7273 - val_loss: 3.1239\n",
      "Epoch 687/1000\n",
      "22/22 - 0s - 4ms/step - accuracy: 1.0000 - loss: 0.0076 - val_accuracy: 0.7273 - val_loss: 3.1742\n",
      "Epoch 688/1000\n",
      "22/22 - 0s - 4ms/step - accuracy: 1.0000 - loss: 0.0076 - val_accuracy: 0.7273 - val_loss: 3.1626\n",
      "Epoch 689/1000\n",
      "22/22 - 0s - 4ms/step - accuracy: 1.0000 - loss: 0.0071 - val_accuracy: 0.7403 - val_loss: 3.2020\n",
      "Epoch 690/1000\n",
      "22/22 - 0s - 4ms/step - accuracy: 1.0000 - loss: 0.0070 - val_accuracy: 0.7273 - val_loss: 3.2438\n",
      "Epoch 691/1000\n",
      "22/22 - 0s - 5ms/step - accuracy: 1.0000 - loss: 0.0064 - val_accuracy: 0.7143 - val_loss: 3.2517\n",
      "Epoch 692/1000\n",
      "22/22 - 0s - 4ms/step - accuracy: 1.0000 - loss: 0.0062 - val_accuracy: 0.7143 - val_loss: 3.3056\n",
      "Epoch 693/1000\n",
      "22/22 - 0s - 4ms/step - accuracy: 1.0000 - loss: 0.0058 - val_accuracy: 0.7143 - val_loss: 3.3594\n",
      "Epoch 694/1000\n",
      "22/22 - 0s - 4ms/step - accuracy: 1.0000 - loss: 0.0058 - val_accuracy: 0.7273 - val_loss: 3.3092\n",
      "Epoch 695/1000\n",
      "22/22 - 0s - 4ms/step - accuracy: 1.0000 - loss: 0.0052 - val_accuracy: 0.7273 - val_loss: 3.3169\n",
      "Epoch 696/1000\n",
      "22/22 - 0s - 4ms/step - accuracy: 1.0000 - loss: 0.0053 - val_accuracy: 0.7273 - val_loss: 3.3644\n",
      "Epoch 697/1000\n",
      "22/22 - 0s - 4ms/step - accuracy: 1.0000 - loss: 0.0051 - val_accuracy: 0.7143 - val_loss: 3.3791\n",
      "Epoch 698/1000\n",
      "22/22 - 0s - 5ms/step - accuracy: 1.0000 - loss: 0.0050 - val_accuracy: 0.7273 - val_loss: 3.3442\n",
      "Epoch 699/1000\n",
      "22/22 - 0s - 4ms/step - accuracy: 1.0000 - loss: 0.0046 - val_accuracy: 0.7273 - val_loss: 3.3761\n",
      "Epoch 700/1000\n",
      "22/22 - 0s - 5ms/step - accuracy: 1.0000 - loss: 0.0046 - val_accuracy: 0.7143 - val_loss: 3.4524\n",
      "Epoch 701/1000\n",
      "22/22 - 0s - 5ms/step - accuracy: 1.0000 - loss: 0.0046 - val_accuracy: 0.7403 - val_loss: 3.3843\n",
      "Epoch 702/1000\n",
      "22/22 - 0s - 4ms/step - accuracy: 1.0000 - loss: 0.0048 - val_accuracy: 0.7273 - val_loss: 3.4623\n",
      "Epoch 703/1000\n",
      "22/22 - 0s - 4ms/step - accuracy: 1.0000 - loss: 0.0053 - val_accuracy: 0.7273 - val_loss: 3.4378\n",
      "Epoch 704/1000\n",
      "22/22 - 0s - 4ms/step - accuracy: 1.0000 - loss: 0.0042 - val_accuracy: 0.7273 - val_loss: 3.4194\n",
      "Epoch 705/1000\n",
      "22/22 - 0s - 4ms/step - accuracy: 1.0000 - loss: 0.0040 - val_accuracy: 0.7273 - val_loss: 3.5206\n",
      "Epoch 706/1000\n",
      "22/22 - 0s - 5ms/step - accuracy: 1.0000 - loss: 0.0038 - val_accuracy: 0.7273 - val_loss: 3.4413\n",
      "Epoch 707/1000\n",
      "22/22 - 0s - 4ms/step - accuracy: 1.0000 - loss: 0.0036 - val_accuracy: 0.7403 - val_loss: 3.5036\n",
      "Epoch 708/1000\n",
      "22/22 - 0s - 5ms/step - accuracy: 1.0000 - loss: 0.0034 - val_accuracy: 0.7273 - val_loss: 3.5201\n",
      "Epoch 709/1000\n",
      "22/22 - 0s - 5ms/step - accuracy: 1.0000 - loss: 0.0033 - val_accuracy: 0.7273 - val_loss: 3.5029\n",
      "Epoch 710/1000\n",
      "22/22 - 0s - 4ms/step - accuracy: 1.0000 - loss: 0.0032 - val_accuracy: 0.7403 - val_loss: 3.4897\n",
      "Epoch 711/1000\n",
      "22/22 - 0s - 4ms/step - accuracy: 1.0000 - loss: 0.0031 - val_accuracy: 0.7273 - val_loss: 3.5432\n",
      "Epoch 712/1000\n",
      "22/22 - 0s - 4ms/step - accuracy: 1.0000 - loss: 0.0030 - val_accuracy: 0.7273 - val_loss: 3.5338\n",
      "Epoch 713/1000\n",
      "22/22 - 0s - 5ms/step - accuracy: 1.0000 - loss: 0.0030 - val_accuracy: 0.7273 - val_loss: 3.5430\n",
      "Epoch 714/1000\n",
      "22/22 - 0s - 6ms/step - accuracy: 1.0000 - loss: 0.0031 - val_accuracy: 0.7143 - val_loss: 3.6058\n",
      "Epoch 715/1000\n",
      "22/22 - 0s - 6ms/step - accuracy: 1.0000 - loss: 0.0031 - val_accuracy: 0.7403 - val_loss: 3.5388\n",
      "Epoch 716/1000\n",
      "22/22 - 0s - 5ms/step - accuracy: 0.9986 - loss: 0.0083 - val_accuracy: 0.7143 - val_loss: 3.4921\n",
      "Epoch 717/1000\n",
      "22/22 - 0s - 6ms/step - accuracy: 0.9986 - loss: 0.0111 - val_accuracy: 0.7273 - val_loss: 3.3604\n",
      "Epoch 718/1000\n",
      "22/22 - 0s - 5ms/step - accuracy: 0.9942 - loss: 0.0228 - val_accuracy: 0.7273 - val_loss: 3.5976\n",
      "Epoch 719/1000\n",
      "22/22 - 0s - 5ms/step - accuracy: 0.9696 - loss: 0.0667 - val_accuracy: 0.7532 - val_loss: 2.9844\n",
      "Epoch 720/1000\n",
      "22/22 - 0s - 4ms/step - accuracy: 0.9219 - loss: 0.3065 - val_accuracy: 0.7013 - val_loss: 3.4932\n",
      "Epoch 721/1000\n",
      "22/22 - 0s - 6ms/step - accuracy: 0.8784 - loss: 0.3630 - val_accuracy: 0.7143 - val_loss: 3.6270\n",
      "Epoch 722/1000\n",
      "22/22 - 0s - 6ms/step - accuracy: 0.8944 - loss: 0.3670 - val_accuracy: 0.6883 - val_loss: 2.6726\n",
      "Epoch 723/1000\n",
      "22/22 - 0s - 5ms/step - accuracy: 0.9190 - loss: 0.2215 - val_accuracy: 0.7013 - val_loss: 2.4168\n",
      "Epoch 724/1000\n",
      "22/22 - 0s - 6ms/step - accuracy: 0.9175 - loss: 0.2069 - val_accuracy: 0.7013 - val_loss: 2.0352\n",
      "Epoch 725/1000\n",
      "22/22 - 0s - 6ms/step - accuracy: 0.9508 - loss: 0.1054 - val_accuracy: 0.7532 - val_loss: 2.4540\n",
      "Epoch 726/1000\n",
      "22/22 - 0s - 5ms/step - accuracy: 0.9682 - loss: 0.0852 - val_accuracy: 0.7013 - val_loss: 2.5535\n",
      "Epoch 727/1000\n",
      "22/22 - 0s - 6ms/step - accuracy: 0.9754 - loss: 0.0721 - val_accuracy: 0.6883 - val_loss: 2.5619\n",
      "Epoch 728/1000\n",
      "22/22 - 0s - 7ms/step - accuracy: 0.9725 - loss: 0.0884 - val_accuracy: 0.7403 - val_loss: 2.4388\n",
      "Epoch 729/1000\n",
      "22/22 - 0s - 6ms/step - accuracy: 0.9812 - loss: 0.0713 - val_accuracy: 0.6883 - val_loss: 2.8754\n",
      "Epoch 730/1000\n",
      "22/22 - 0s - 5ms/step - accuracy: 0.9899 - loss: 0.0373 - val_accuracy: 0.7143 - val_loss: 2.9395\n",
      "Epoch 731/1000\n",
      "22/22 - 0s - 7ms/step - accuracy: 0.9870 - loss: 0.0418 - val_accuracy: 0.7273 - val_loss: 2.7116\n",
      "Epoch 732/1000\n",
      "22/22 - 0s - 6ms/step - accuracy: 0.9928 - loss: 0.0373 - val_accuracy: 0.7403 - val_loss: 2.8548\n",
      "Epoch 733/1000\n",
      "22/22 - 0s - 5ms/step - accuracy: 0.9971 - loss: 0.0208 - val_accuracy: 0.7403 - val_loss: 2.8291\n",
      "Epoch 734/1000\n",
      "22/22 - 0s - 5ms/step - accuracy: 0.9971 - loss: 0.0194 - val_accuracy: 0.7532 - val_loss: 2.7797\n",
      "Epoch 735/1000\n",
      "22/22 - 0s - 5ms/step - accuracy: 0.9971 - loss: 0.0223 - val_accuracy: 0.7143 - val_loss: 3.0027\n",
      "Epoch 736/1000\n",
      "22/22 - 0s - 6ms/step - accuracy: 0.9971 - loss: 0.0168 - val_accuracy: 0.7403 - val_loss: 2.8111\n",
      "Epoch 737/1000\n",
      "22/22 - 0s - 5ms/step - accuracy: 0.9986 - loss: 0.0115 - val_accuracy: 0.6883 - val_loss: 2.9874\n",
      "Epoch 738/1000\n",
      "22/22 - 0s - 5ms/step - accuracy: 0.9986 - loss: 0.0082 - val_accuracy: 0.7532 - val_loss: 2.9710\n",
      "Epoch 739/1000\n",
      "22/22 - 0s - 5ms/step - accuracy: 1.0000 - loss: 0.0070 - val_accuracy: 0.7013 - val_loss: 3.0383\n",
      "Epoch 740/1000\n",
      "22/22 - 0s - 6ms/step - accuracy: 1.0000 - loss: 0.0064 - val_accuracy: 0.7273 - val_loss: 3.0363\n",
      "Epoch 741/1000\n",
      "22/22 - 0s - 5ms/step - accuracy: 1.0000 - loss: 0.0058 - val_accuracy: 0.7143 - val_loss: 3.0526\n",
      "Epoch 742/1000\n",
      "22/22 - 0s - 5ms/step - accuracy: 1.0000 - loss: 0.0052 - val_accuracy: 0.7013 - val_loss: 3.1198\n",
      "Epoch 743/1000\n",
      "22/22 - 0s - 5ms/step - accuracy: 1.0000 - loss: 0.0047 - val_accuracy: 0.7273 - val_loss: 3.0810\n",
      "Epoch 744/1000\n",
      "22/22 - 0s - 6ms/step - accuracy: 1.0000 - loss: 0.0049 - val_accuracy: 0.7013 - val_loss: 3.1442\n",
      "Epoch 745/1000\n",
      "22/22 - 0s - 6ms/step - accuracy: 1.0000 - loss: 0.0044 - val_accuracy: 0.7013 - val_loss: 3.1536\n",
      "Epoch 746/1000\n",
      "22/22 - 0s - 6ms/step - accuracy: 1.0000 - loss: 0.0041 - val_accuracy: 0.7143 - val_loss: 3.1616\n",
      "Epoch 747/1000\n",
      "22/22 - 0s - 5ms/step - accuracy: 1.0000 - loss: 0.0039 - val_accuracy: 0.7143 - val_loss: 3.1996\n",
      "Epoch 748/1000\n",
      "22/22 - 0s - 5ms/step - accuracy: 1.0000 - loss: 0.0038 - val_accuracy: 0.6883 - val_loss: 3.2135\n",
      "Epoch 749/1000\n",
      "22/22 - 0s - 5ms/step - accuracy: 1.0000 - loss: 0.0038 - val_accuracy: 0.7143 - val_loss: 3.2289\n",
      "Epoch 750/1000\n",
      "22/22 - 0s - 5ms/step - accuracy: 1.0000 - loss: 0.0037 - val_accuracy: 0.7143 - val_loss: 3.2467\n",
      "Epoch 751/1000\n",
      "22/22 - 0s - 5ms/step - accuracy: 1.0000 - loss: 0.0035 - val_accuracy: 0.7143 - val_loss: 3.2670\n",
      "Epoch 752/1000\n",
      "22/22 - 0s - 5ms/step - accuracy: 1.0000 - loss: 0.0035 - val_accuracy: 0.7143 - val_loss: 3.2699\n",
      "Epoch 753/1000\n",
      "22/22 - 0s - 6ms/step - accuracy: 1.0000 - loss: 0.0033 - val_accuracy: 0.7143 - val_loss: 3.3322\n",
      "Epoch 754/1000\n",
      "22/22 - 0s - 6ms/step - accuracy: 1.0000 - loss: 0.0030 - val_accuracy: 0.7143 - val_loss: 3.3027\n",
      "Epoch 755/1000\n",
      "22/22 - 0s - 6ms/step - accuracy: 1.0000 - loss: 0.0030 - val_accuracy: 0.7143 - val_loss: 3.3224\n",
      "Epoch 756/1000\n",
      "22/22 - 0s - 6ms/step - accuracy: 1.0000 - loss: 0.0028 - val_accuracy: 0.7143 - val_loss: 3.3391\n",
      "Epoch 757/1000\n",
      "22/22 - 0s - 6ms/step - accuracy: 1.0000 - loss: 0.0027 - val_accuracy: 0.7143 - val_loss: 3.3563\n",
      "Epoch 758/1000\n",
      "22/22 - 0s - 5ms/step - accuracy: 1.0000 - loss: 0.0026 - val_accuracy: 0.7143 - val_loss: 3.3766\n",
      "Epoch 759/1000\n",
      "22/22 - 0s - 6ms/step - accuracy: 1.0000 - loss: 0.0026 - val_accuracy: 0.7143 - val_loss: 3.4001\n",
      "Epoch 760/1000\n",
      "22/22 - 0s - 4ms/step - accuracy: 1.0000 - loss: 0.0025 - val_accuracy: 0.7143 - val_loss: 3.4050\n",
      "Epoch 761/1000\n",
      "22/22 - 0s - 4ms/step - accuracy: 1.0000 - loss: 0.0024 - val_accuracy: 0.7143 - val_loss: 3.4060\n",
      "Epoch 762/1000\n",
      "22/22 - 0s - 5ms/step - accuracy: 1.0000 - loss: 0.0024 - val_accuracy: 0.7013 - val_loss: 3.4362\n",
      "Epoch 763/1000\n",
      "22/22 - 0s - 5ms/step - accuracy: 1.0000 - loss: 0.0022 - val_accuracy: 0.7143 - val_loss: 3.4300\n",
      "Epoch 764/1000\n",
      "22/22 - 0s - 5ms/step - accuracy: 1.0000 - loss: 0.0021 - val_accuracy: 0.7143 - val_loss: 3.4406\n",
      "Epoch 765/1000\n",
      "22/22 - 0s - 5ms/step - accuracy: 1.0000 - loss: 0.0021 - val_accuracy: 0.7013 - val_loss: 3.4819\n",
      "Epoch 766/1000\n",
      "22/22 - 0s - 5ms/step - accuracy: 1.0000 - loss: 0.0021 - val_accuracy: 0.7013 - val_loss: 3.4830\n",
      "Epoch 767/1000\n",
      "22/22 - 0s - 4ms/step - accuracy: 1.0000 - loss: 0.0021 - val_accuracy: 0.7013 - val_loss: 3.4749\n",
      "Epoch 768/1000\n",
      "22/22 - 0s - 5ms/step - accuracy: 1.0000 - loss: 0.0020 - val_accuracy: 0.7013 - val_loss: 3.5039\n",
      "Epoch 769/1000\n",
      "22/22 - 0s - 5ms/step - accuracy: 1.0000 - loss: 0.0020 - val_accuracy: 0.7143 - val_loss: 3.4980\n",
      "Epoch 770/1000\n",
      "22/22 - 0s - 4ms/step - accuracy: 1.0000 - loss: 0.0019 - val_accuracy: 0.7013 - val_loss: 3.5154\n",
      "Epoch 771/1000\n",
      "22/22 - 0s - 4ms/step - accuracy: 1.0000 - loss: 0.0018 - val_accuracy: 0.7013 - val_loss: 3.5354\n",
      "Epoch 772/1000\n",
      "22/22 - 0s - 5ms/step - accuracy: 1.0000 - loss: 0.0018 - val_accuracy: 0.7143 - val_loss: 3.5342\n",
      "Epoch 773/1000\n",
      "22/22 - 0s - 4ms/step - accuracy: 1.0000 - loss: 0.0018 - val_accuracy: 0.7013 - val_loss: 3.5289\n",
      "Epoch 774/1000\n",
      "22/22 - 0s - 4ms/step - accuracy: 1.0000 - loss: 0.0017 - val_accuracy: 0.7013 - val_loss: 3.5562\n",
      "Epoch 775/1000\n",
      "22/22 - 0s - 6ms/step - accuracy: 1.0000 - loss: 0.0017 - val_accuracy: 0.7013 - val_loss: 3.5874\n",
      "Epoch 776/1000\n",
      "22/22 - 0s - 4ms/step - accuracy: 1.0000 - loss: 0.0017 - val_accuracy: 0.7013 - val_loss: 3.5855\n",
      "Epoch 777/1000\n",
      "22/22 - 0s - 5ms/step - accuracy: 1.0000 - loss: 0.0016 - val_accuracy: 0.7013 - val_loss: 3.5797\n",
      "Epoch 778/1000\n",
      "22/22 - 0s - 5ms/step - accuracy: 1.0000 - loss: 0.0016 - val_accuracy: 0.7013 - val_loss: 3.5819\n",
      "Epoch 779/1000\n",
      "22/22 - 0s - 4ms/step - accuracy: 1.0000 - loss: 0.0015 - val_accuracy: 0.7013 - val_loss: 3.5986\n",
      "Epoch 780/1000\n",
      "22/22 - 0s - 4ms/step - accuracy: 1.0000 - loss: 0.0015 - val_accuracy: 0.7013 - val_loss: 3.6044\n",
      "Epoch 781/1000\n",
      "22/22 - 0s - 4ms/step - accuracy: 1.0000 - loss: 0.0015 - val_accuracy: 0.7013 - val_loss: 3.6099\n",
      "Epoch 782/1000\n",
      "22/22 - 0s - 5ms/step - accuracy: 1.0000 - loss: 0.0015 - val_accuracy: 0.7013 - val_loss: 3.6024\n",
      "Epoch 783/1000\n",
      "22/22 - 0s - 5ms/step - accuracy: 1.0000 - loss: 0.0015 - val_accuracy: 0.7013 - val_loss: 3.6135\n",
      "Epoch 784/1000\n",
      "22/22 - 0s - 4ms/step - accuracy: 1.0000 - loss: 0.0014 - val_accuracy: 0.7013 - val_loss: 3.6353\n",
      "Epoch 785/1000\n",
      "22/22 - 0s - 4ms/step - accuracy: 1.0000 - loss: 0.0014 - val_accuracy: 0.7013 - val_loss: 3.6450\n",
      "Epoch 786/1000\n",
      "22/22 - 0s - 6ms/step - accuracy: 1.0000 - loss: 0.0014 - val_accuracy: 0.7013 - val_loss: 3.6699\n",
      "Epoch 787/1000\n",
      "22/22 - 0s - 6ms/step - accuracy: 1.0000 - loss: 0.0013 - val_accuracy: 0.7013 - val_loss: 3.6425\n",
      "Epoch 788/1000\n",
      "22/22 - 0s - 4ms/step - accuracy: 1.0000 - loss: 0.0013 - val_accuracy: 0.7013 - val_loss: 3.6595\n",
      "Epoch 789/1000\n",
      "22/22 - 0s - 4ms/step - accuracy: 1.0000 - loss: 0.0013 - val_accuracy: 0.7143 - val_loss: 3.6728\n",
      "Epoch 790/1000\n",
      "22/22 - 0s - 4ms/step - accuracy: 1.0000 - loss: 0.0013 - val_accuracy: 0.7013 - val_loss: 3.6871\n",
      "Epoch 791/1000\n",
      "22/22 - 0s - 4ms/step - accuracy: 1.0000 - loss: 0.0012 - val_accuracy: 0.7013 - val_loss: 3.6930\n",
      "Epoch 792/1000\n",
      "22/22 - 0s - 4ms/step - accuracy: 1.0000 - loss: 0.0012 - val_accuracy: 0.7143 - val_loss: 3.6919\n",
      "Epoch 793/1000\n",
      "22/22 - 0s - 5ms/step - accuracy: 1.0000 - loss: 0.0012 - val_accuracy: 0.7013 - val_loss: 3.6902\n",
      "Epoch 794/1000\n",
      "22/22 - 0s - 4ms/step - accuracy: 1.0000 - loss: 0.0012 - val_accuracy: 0.7013 - val_loss: 3.7217\n",
      "Epoch 795/1000\n",
      "22/22 - 0s - 4ms/step - accuracy: 1.0000 - loss: 0.0011 - val_accuracy: 0.7013 - val_loss: 3.7279\n",
      "Epoch 796/1000\n",
      "22/22 - 0s - 4ms/step - accuracy: 1.0000 - loss: 0.0011 - val_accuracy: 0.7013 - val_loss: 3.7397\n",
      "Epoch 797/1000\n",
      "22/22 - 0s - 4ms/step - accuracy: 1.0000 - loss: 0.0011 - val_accuracy: 0.7013 - val_loss: 3.7186\n",
      "Epoch 798/1000\n",
      "22/22 - 0s - 4ms/step - accuracy: 1.0000 - loss: 0.0011 - val_accuracy: 0.7013 - val_loss: 3.7473\n",
      "Epoch 799/1000\n",
      "22/22 - 0s - 4ms/step - accuracy: 1.0000 - loss: 0.0011 - val_accuracy: 0.7013 - val_loss: 3.7421\n",
      "Epoch 800/1000\n",
      "22/22 - 0s - 4ms/step - accuracy: 1.0000 - loss: 0.0011 - val_accuracy: 0.7013 - val_loss: 3.7678\n",
      "Epoch 801/1000\n",
      "22/22 - 0s - 5ms/step - accuracy: 1.0000 - loss: 0.0012 - val_accuracy: 0.7143 - val_loss: 3.7157\n",
      "Epoch 802/1000\n",
      "22/22 - 0s - 4ms/step - accuracy: 1.0000 - loss: 0.0012 - val_accuracy: 0.7013 - val_loss: 3.7860\n",
      "Epoch 803/1000\n",
      "22/22 - 0s - 4ms/step - accuracy: 1.0000 - loss: 0.0011 - val_accuracy: 0.7013 - val_loss: 3.7704\n",
      "Epoch 804/1000\n",
      "22/22 - 0s - 5ms/step - accuracy: 1.0000 - loss: 0.0012 - val_accuracy: 0.7143 - val_loss: 3.8235\n",
      "Epoch 805/1000\n",
      "22/22 - 0s - 4ms/step - accuracy: 1.0000 - loss: 0.0010 - val_accuracy: 0.7143 - val_loss: 3.8065\n",
      "Epoch 806/1000\n",
      "22/22 - 0s - 5ms/step - accuracy: 1.0000 - loss: 9.4337e-04 - val_accuracy: 0.7013 - val_loss: 3.8199\n",
      "Epoch 807/1000\n",
      "22/22 - 0s - 4ms/step - accuracy: 1.0000 - loss: 9.1348e-04 - val_accuracy: 0.7013 - val_loss: 3.8121\n",
      "Epoch 808/1000\n",
      "22/22 - 0s - 5ms/step - accuracy: 1.0000 - loss: 9.0304e-04 - val_accuracy: 0.7143 - val_loss: 3.8237\n",
      "Epoch 809/1000\n",
      "22/22 - 0s - 4ms/step - accuracy: 1.0000 - loss: 8.7475e-04 - val_accuracy: 0.7143 - val_loss: 3.8181\n",
      "Epoch 810/1000\n",
      "22/22 - 0s - 4ms/step - accuracy: 1.0000 - loss: 8.4676e-04 - val_accuracy: 0.7143 - val_loss: 3.8234\n",
      "Epoch 811/1000\n",
      "22/22 - 0s - 4ms/step - accuracy: 1.0000 - loss: 8.7010e-04 - val_accuracy: 0.7143 - val_loss: 3.8326\n",
      "Epoch 812/1000\n",
      "22/22 - 0s - 4ms/step - accuracy: 1.0000 - loss: 8.1672e-04 - val_accuracy: 0.7143 - val_loss: 3.8585\n",
      "Epoch 813/1000\n",
      "22/22 - 0s - 4ms/step - accuracy: 1.0000 - loss: 8.6475e-04 - val_accuracy: 0.7143 - val_loss: 3.8652\n",
      "Epoch 814/1000\n",
      "22/22 - 0s - 5ms/step - accuracy: 1.0000 - loss: 8.2232e-04 - val_accuracy: 0.7143 - val_loss: 3.8620\n",
      "Epoch 815/1000\n",
      "22/22 - 0s - 4ms/step - accuracy: 1.0000 - loss: 8.1199e-04 - val_accuracy: 0.7143 - val_loss: 3.8833\n",
      "Epoch 816/1000\n",
      "22/22 - 0s - 5ms/step - accuracy: 1.0000 - loss: 7.8625e-04 - val_accuracy: 0.7143 - val_loss: 3.8945\n",
      "Epoch 817/1000\n",
      "22/22 - 0s - 4ms/step - accuracy: 1.0000 - loss: 7.8436e-04 - val_accuracy: 0.7143 - val_loss: 3.8629\n",
      "Epoch 818/1000\n",
      "22/22 - 0s - 4ms/step - accuracy: 1.0000 - loss: 7.7018e-04 - val_accuracy: 0.7143 - val_loss: 3.8945\n",
      "Epoch 819/1000\n",
      "22/22 - 0s - 5ms/step - accuracy: 1.0000 - loss: 7.6500e-04 - val_accuracy: 0.7143 - val_loss: 3.9106\n",
      "Epoch 820/1000\n",
      "22/22 - 0s - 5ms/step - accuracy: 1.0000 - loss: 7.3848e-04 - val_accuracy: 0.7143 - val_loss: 3.8978\n",
      "Epoch 821/1000\n",
      "22/22 - 0s - 4ms/step - accuracy: 1.0000 - loss: 7.1303e-04 - val_accuracy: 0.7143 - val_loss: 3.9212\n",
      "Epoch 822/1000\n",
      "22/22 - 0s - 4ms/step - accuracy: 1.0000 - loss: 6.9630e-04 - val_accuracy: 0.7143 - val_loss: 3.9283\n",
      "Epoch 823/1000\n",
      "22/22 - 0s - 4ms/step - accuracy: 1.0000 - loss: 6.9798e-04 - val_accuracy: 0.7143 - val_loss: 3.9330\n",
      "Epoch 824/1000\n",
      "22/22 - 0s - 5ms/step - accuracy: 1.0000 - loss: 6.9749e-04 - val_accuracy: 0.7143 - val_loss: 3.9285\n",
      "Epoch 825/1000\n",
      "22/22 - 0s - 4ms/step - accuracy: 1.0000 - loss: 6.7725e-04 - val_accuracy: 0.7143 - val_loss: 3.9308\n",
      "Epoch 826/1000\n",
      "22/22 - 0s - 4ms/step - accuracy: 1.0000 - loss: 6.4778e-04 - val_accuracy: 0.7143 - val_loss: 3.9519\n",
      "Epoch 827/1000\n",
      "22/22 - 0s - 4ms/step - accuracy: 1.0000 - loss: 6.3368e-04 - val_accuracy: 0.7143 - val_loss: 3.9560\n",
      "Epoch 828/1000\n",
      "22/22 - 0s - 4ms/step - accuracy: 1.0000 - loss: 6.3244e-04 - val_accuracy: 0.7143 - val_loss: 3.9642\n",
      "Epoch 829/1000\n",
      "22/22 - 0s - 4ms/step - accuracy: 1.0000 - loss: 6.2105e-04 - val_accuracy: 0.7143 - val_loss: 3.9599\n",
      "Epoch 830/1000\n",
      "22/22 - 0s - 5ms/step - accuracy: 1.0000 - loss: 6.0582e-04 - val_accuracy: 0.7143 - val_loss: 3.9698\n",
      "Epoch 831/1000\n",
      "22/22 - 0s - 4ms/step - accuracy: 1.0000 - loss: 5.9935e-04 - val_accuracy: 0.7143 - val_loss: 3.9719\n",
      "Epoch 832/1000\n",
      "22/22 - 0s - 4ms/step - accuracy: 1.0000 - loss: 6.1998e-04 - val_accuracy: 0.7143 - val_loss: 3.9680\n",
      "Epoch 833/1000\n",
      "22/22 - 0s - 4ms/step - accuracy: 1.0000 - loss: 5.8891e-04 - val_accuracy: 0.7143 - val_loss: 3.9949\n",
      "Epoch 834/1000\n",
      "22/22 - 0s - 4ms/step - accuracy: 1.0000 - loss: 5.8762e-04 - val_accuracy: 0.7143 - val_loss: 3.9853\n",
      "Epoch 835/1000\n",
      "22/22 - 0s - 4ms/step - accuracy: 1.0000 - loss: 5.7780e-04 - val_accuracy: 0.7143 - val_loss: 3.9958\n",
      "Epoch 836/1000\n",
      "22/22 - 0s - 5ms/step - accuracy: 1.0000 - loss: 5.8431e-04 - val_accuracy: 0.7143 - val_loss: 4.0125\n",
      "Epoch 837/1000\n",
      "22/22 - 0s - 4ms/step - accuracy: 1.0000 - loss: 5.6245e-04 - val_accuracy: 0.7143 - val_loss: 4.0293\n",
      "Epoch 838/1000\n",
      "22/22 - 0s - 5ms/step - accuracy: 1.0000 - loss: 5.2699e-04 - val_accuracy: 0.7143 - val_loss: 4.0107\n",
      "Epoch 839/1000\n",
      "22/22 - 0s - 4ms/step - accuracy: 1.0000 - loss: 5.2895e-04 - val_accuracy: 0.7143 - val_loss: 4.0211\n",
      "Epoch 840/1000\n",
      "22/22 - 0s - 4ms/step - accuracy: 1.0000 - loss: 5.6463e-04 - val_accuracy: 0.7143 - val_loss: 4.0374\n",
      "Epoch 841/1000\n",
      "22/22 - 0s - 5ms/step - accuracy: 1.0000 - loss: 5.7188e-04 - val_accuracy: 0.7143 - val_loss: 4.0382\n",
      "Epoch 842/1000\n",
      "22/22 - 0s - 4ms/step - accuracy: 1.0000 - loss: 5.5118e-04 - val_accuracy: 0.7143 - val_loss: 4.0335\n",
      "Epoch 843/1000\n",
      "22/22 - 0s - 4ms/step - accuracy: 1.0000 - loss: 4.9421e-04 - val_accuracy: 0.7143 - val_loss: 4.0759\n",
      "Epoch 844/1000\n",
      "22/22 - 0s - 4ms/step - accuracy: 1.0000 - loss: 5.0133e-04 - val_accuracy: 0.7143 - val_loss: 4.0309\n",
      "Epoch 845/1000\n",
      "22/22 - 0s - 5ms/step - accuracy: 1.0000 - loss: 4.7606e-04 - val_accuracy: 0.7143 - val_loss: 4.0685\n",
      "Epoch 846/1000\n",
      "22/22 - 0s - 4ms/step - accuracy: 1.0000 - loss: 4.6742e-04 - val_accuracy: 0.7143 - val_loss: 4.0582\n",
      "Epoch 847/1000\n",
      "22/22 - 0s - 5ms/step - accuracy: 1.0000 - loss: 4.7077e-04 - val_accuracy: 0.7143 - val_loss: 4.0739\n",
      "Epoch 848/1000\n",
      "22/22 - 0s - 5ms/step - accuracy: 1.0000 - loss: 4.5711e-04 - val_accuracy: 0.7143 - val_loss: 4.1077\n",
      "Epoch 849/1000\n",
      "22/22 - 0s - 4ms/step - accuracy: 1.0000 - loss: 4.5670e-04 - val_accuracy: 0.7143 - val_loss: 4.0844\n",
      "Epoch 850/1000\n",
      "22/22 - 0s - 4ms/step - accuracy: 1.0000 - loss: 4.4265e-04 - val_accuracy: 0.7143 - val_loss: 4.0872\n",
      "Epoch 851/1000\n",
      "22/22 - 0s - 4ms/step - accuracy: 1.0000 - loss: 4.6048e-04 - val_accuracy: 0.7143 - val_loss: 4.1208\n",
      "Epoch 852/1000\n",
      "22/22 - 0s - 4ms/step - accuracy: 1.0000 - loss: 4.4478e-04 - val_accuracy: 0.7143 - val_loss: 4.1063\n",
      "Epoch 853/1000\n",
      "22/22 - 0s - 4ms/step - accuracy: 1.0000 - loss: 4.1217e-04 - val_accuracy: 0.7143 - val_loss: 4.1232\n",
      "Epoch 854/1000\n",
      "22/22 - 0s - 4ms/step - accuracy: 1.0000 - loss: 4.1828e-04 - val_accuracy: 0.7143 - val_loss: 4.1244\n",
      "Epoch 855/1000\n",
      "22/22 - 0s - 5ms/step - accuracy: 1.0000 - loss: 4.0248e-04 - val_accuracy: 0.7143 - val_loss: 4.1336\n",
      "Epoch 856/1000\n",
      "22/22 - 0s - 5ms/step - accuracy: 1.0000 - loss: 4.1275e-04 - val_accuracy: 0.7143 - val_loss: 4.1609\n",
      "Epoch 857/1000\n",
      "22/22 - 0s - 4ms/step - accuracy: 1.0000 - loss: 3.9644e-04 - val_accuracy: 0.7143 - val_loss: 4.1551\n",
      "Epoch 858/1000\n",
      "22/22 - 0s - 4ms/step - accuracy: 1.0000 - loss: 3.8339e-04 - val_accuracy: 0.7143 - val_loss: 4.1545\n",
      "Epoch 859/1000\n",
      "22/22 - 0s - 4ms/step - accuracy: 1.0000 - loss: 3.7420e-04 - val_accuracy: 0.7143 - val_loss: 4.1610\n",
      "Epoch 860/1000\n",
      "22/22 - 0s - 5ms/step - accuracy: 1.0000 - loss: 3.7902e-04 - val_accuracy: 0.7143 - val_loss: 4.1772\n",
      "Epoch 861/1000\n",
      "22/22 - 0s - 4ms/step - accuracy: 1.0000 - loss: 3.6399e-04 - val_accuracy: 0.7143 - val_loss: 4.1870\n",
      "Epoch 862/1000\n",
      "22/22 - 0s - 5ms/step - accuracy: 1.0000 - loss: 3.6446e-04 - val_accuracy: 0.7143 - val_loss: 4.1636\n",
      "Epoch 863/1000\n",
      "22/22 - 0s - 5ms/step - accuracy: 1.0000 - loss: 3.7228e-04 - val_accuracy: 0.7143 - val_loss: 4.1832\n",
      "Epoch 864/1000\n",
      "22/22 - 0s - 4ms/step - accuracy: 1.0000 - loss: 3.4787e-04 - val_accuracy: 0.7143 - val_loss: 4.2135\n",
      "Epoch 865/1000\n",
      "22/22 - 0s - 4ms/step - accuracy: 1.0000 - loss: 3.4465e-04 - val_accuracy: 0.7143 - val_loss: 4.1958\n",
      "Epoch 866/1000\n",
      "22/22 - 0s - 5ms/step - accuracy: 1.0000 - loss: 3.3927e-04 - val_accuracy: 0.7143 - val_loss: 4.2036\n",
      "Epoch 867/1000\n",
      "22/22 - 0s - 4ms/step - accuracy: 1.0000 - loss: 3.3540e-04 - val_accuracy: 0.7143 - val_loss: 4.2148\n",
      "Epoch 868/1000\n",
      "22/22 - 0s - 4ms/step - accuracy: 1.0000 - loss: 3.4275e-04 - val_accuracy: 0.7143 - val_loss: 4.2189\n",
      "Epoch 869/1000\n",
      "22/22 - 0s - 4ms/step - accuracy: 1.0000 - loss: 3.4478e-04 - val_accuracy: 0.7143 - val_loss: 4.2130\n",
      "Epoch 870/1000\n",
      "22/22 - 0s - 4ms/step - accuracy: 1.0000 - loss: 3.4523e-04 - val_accuracy: 0.7143 - val_loss: 4.2480\n",
      "Epoch 871/1000\n",
      "22/22 - 0s - 4ms/step - accuracy: 1.0000 - loss: 3.3490e-04 - val_accuracy: 0.7143 - val_loss: 4.2201\n",
      "Epoch 872/1000\n",
      "22/22 - 0s - 5ms/step - accuracy: 1.0000 - loss: 3.2117e-04 - val_accuracy: 0.7143 - val_loss: 4.2399\n",
      "Epoch 873/1000\n",
      "22/22 - 0s - 6ms/step - accuracy: 1.0000 - loss: 3.0583e-04 - val_accuracy: 0.7143 - val_loss: 4.2563\n",
      "Epoch 874/1000\n",
      "22/22 - 0s - 6ms/step - accuracy: 1.0000 - loss: 3.1052e-04 - val_accuracy: 0.7143 - val_loss: 4.2486\n",
      "Epoch 875/1000\n",
      "22/22 - 0s - 4ms/step - accuracy: 1.0000 - loss: 3.0713e-04 - val_accuracy: 0.7143 - val_loss: 4.2706\n",
      "Epoch 876/1000\n",
      "22/22 - 0s - 4ms/step - accuracy: 1.0000 - loss: 3.0725e-04 - val_accuracy: 0.7143 - val_loss: 4.2631\n",
      "Epoch 877/1000\n",
      "22/22 - 0s - 4ms/step - accuracy: 1.0000 - loss: 3.0597e-04 - val_accuracy: 0.7143 - val_loss: 4.2909\n",
      "Epoch 878/1000\n",
      "22/22 - 0s - 4ms/step - accuracy: 1.0000 - loss: 2.8991e-04 - val_accuracy: 0.7143 - val_loss: 4.2887\n",
      "Epoch 879/1000\n",
      "22/22 - 0s - 4ms/step - accuracy: 1.0000 - loss: 2.8115e-04 - val_accuracy: 0.7143 - val_loss: 4.2822\n",
      "Epoch 880/1000\n",
      "22/22 - 0s - 4ms/step - accuracy: 1.0000 - loss: 2.8536e-04 - val_accuracy: 0.7143 - val_loss: 4.2856\n",
      "Epoch 881/1000\n",
      "22/22 - 0s - 4ms/step - accuracy: 1.0000 - loss: 2.8752e-04 - val_accuracy: 0.7143 - val_loss: 4.3077\n",
      "Epoch 882/1000\n",
      "22/22 - 0s - 4ms/step - accuracy: 1.0000 - loss: 2.6721e-04 - val_accuracy: 0.7143 - val_loss: 4.3094\n",
      "Epoch 883/1000\n",
      "22/22 - 0s - 4ms/step - accuracy: 1.0000 - loss: 2.6351e-04 - val_accuracy: 0.7143 - val_loss: 4.3217\n",
      "Epoch 884/1000\n",
      "22/22 - 0s - 4ms/step - accuracy: 1.0000 - loss: 2.5618e-04 - val_accuracy: 0.7143 - val_loss: 4.3249\n",
      "Epoch 885/1000\n",
      "22/22 - 0s - 4ms/step - accuracy: 1.0000 - loss: 2.6056e-04 - val_accuracy: 0.7143 - val_loss: 4.3286\n",
      "Epoch 886/1000\n",
      "22/22 - 0s - 4ms/step - accuracy: 1.0000 - loss: 2.5201e-04 - val_accuracy: 0.7143 - val_loss: 4.3249\n",
      "Epoch 887/1000\n",
      "22/22 - 0s - 4ms/step - accuracy: 1.0000 - loss: 2.4728e-04 - val_accuracy: 0.7143 - val_loss: 4.3655\n",
      "Epoch 888/1000\n",
      "22/22 - 0s - 4ms/step - accuracy: 1.0000 - loss: 2.5299e-04 - val_accuracy: 0.7143 - val_loss: 4.3382\n",
      "Epoch 889/1000\n",
      "22/22 - 0s - 4ms/step - accuracy: 1.0000 - loss: 2.5442e-04 - val_accuracy: 0.7143 - val_loss: 4.3550\n",
      "Epoch 890/1000\n",
      "22/22 - 0s - 4ms/step - accuracy: 1.0000 - loss: 2.4333e-04 - val_accuracy: 0.7143 - val_loss: 4.3667\n",
      "Epoch 891/1000\n",
      "22/22 - 0s - 4ms/step - accuracy: 1.0000 - loss: 2.3266e-04 - val_accuracy: 0.7143 - val_loss: 4.3750\n",
      "Epoch 892/1000\n",
      "22/22 - 0s - 4ms/step - accuracy: 1.0000 - loss: 2.3329e-04 - val_accuracy: 0.7143 - val_loss: 4.3781\n",
      "Epoch 893/1000\n",
      "22/22 - 0s - 4ms/step - accuracy: 1.0000 - loss: 2.3373e-04 - val_accuracy: 0.7143 - val_loss: 4.3557\n",
      "Epoch 894/1000\n",
      "22/22 - 0s - 5ms/step - accuracy: 1.0000 - loss: 2.2312e-04 - val_accuracy: 0.7013 - val_loss: 4.3794\n",
      "Epoch 895/1000\n",
      "22/22 - 0s - 5ms/step - accuracy: 1.0000 - loss: 2.2346e-04 - val_accuracy: 0.7143 - val_loss: 4.4002\n",
      "Epoch 896/1000\n",
      "22/22 - 0s - 5ms/step - accuracy: 1.0000 - loss: 2.2203e-04 - val_accuracy: 0.7143 - val_loss: 4.3520\n",
      "Epoch 897/1000\n",
      "22/22 - 0s - 4ms/step - accuracy: 1.0000 - loss: 2.2160e-04 - val_accuracy: 0.7013 - val_loss: 4.4076\n",
      "Epoch 898/1000\n",
      "22/22 - 0s - 4ms/step - accuracy: 1.0000 - loss: 2.1569e-04 - val_accuracy: 0.7143 - val_loss: 4.3799\n",
      "Epoch 899/1000\n",
      "22/22 - 0s - 4ms/step - accuracy: 1.0000 - loss: 2.0906e-04 - val_accuracy: 0.7143 - val_loss: 4.4290\n",
      "Epoch 900/1000\n",
      "22/22 - 0s - 4ms/step - accuracy: 1.0000 - loss: 2.1243e-04 - val_accuracy: 0.7013 - val_loss: 4.3961\n",
      "Epoch 901/1000\n",
      "22/22 - 0s - 4ms/step - accuracy: 1.0000 - loss: 2.0630e-04 - val_accuracy: 0.7143 - val_loss: 4.4434\n",
      "Epoch 902/1000\n",
      "22/22 - 0s - 4ms/step - accuracy: 1.0000 - loss: 1.9874e-04 - val_accuracy: 0.7143 - val_loss: 4.4204\n",
      "Epoch 903/1000\n",
      "22/22 - 0s - 4ms/step - accuracy: 1.0000 - loss: 1.9557e-04 - val_accuracy: 0.7143 - val_loss: 4.4370\n",
      "Epoch 904/1000\n",
      "22/22 - 0s - 4ms/step - accuracy: 1.0000 - loss: 1.9818e-04 - val_accuracy: 0.7143 - val_loss: 4.4252\n",
      "Epoch 905/1000\n",
      "22/22 - 0s - 4ms/step - accuracy: 1.0000 - loss: 1.8719e-04 - val_accuracy: 0.7143 - val_loss: 4.4504\n",
      "Epoch 906/1000\n",
      "22/22 - 0s - 4ms/step - accuracy: 1.0000 - loss: 1.9108e-04 - val_accuracy: 0.7143 - val_loss: 4.4512\n",
      "Epoch 907/1000\n",
      "22/22 - 0s - 4ms/step - accuracy: 1.0000 - loss: 1.8631e-04 - val_accuracy: 0.7143 - val_loss: 4.4336\n",
      "Epoch 908/1000\n",
      "22/22 - 0s - 5ms/step - accuracy: 1.0000 - loss: 1.8441e-04 - val_accuracy: 0.7143 - val_loss: 4.4758\n",
      "Epoch 909/1000\n",
      "22/22 - 0s - 4ms/step - accuracy: 1.0000 - loss: 1.8480e-04 - val_accuracy: 0.7143 - val_loss: 4.4731\n",
      "Epoch 910/1000\n",
      "22/22 - 0s - 4ms/step - accuracy: 1.0000 - loss: 1.7994e-04 - val_accuracy: 0.7143 - val_loss: 4.4781\n",
      "Epoch 911/1000\n",
      "22/22 - 0s - 4ms/step - accuracy: 1.0000 - loss: 1.7455e-04 - val_accuracy: 0.7143 - val_loss: 4.4568\n",
      "Epoch 912/1000\n",
      "22/22 - 0s - 5ms/step - accuracy: 1.0000 - loss: 1.7731e-04 - val_accuracy: 0.7013 - val_loss: 4.4582\n",
      "Epoch 913/1000\n",
      "22/22 - 0s - 4ms/step - accuracy: 1.0000 - loss: 1.7288e-04 - val_accuracy: 0.7143 - val_loss: 4.4782\n",
      "Epoch 914/1000\n",
      "22/22 - 0s - 5ms/step - accuracy: 1.0000 - loss: 1.7398e-04 - val_accuracy: 0.7143 - val_loss: 4.4765\n",
      "Epoch 915/1000\n",
      "22/22 - 0s - 4ms/step - accuracy: 1.0000 - loss: 1.7283e-04 - val_accuracy: 0.7143 - val_loss: 4.5047\n",
      "Epoch 916/1000\n",
      "22/22 - 0s - 4ms/step - accuracy: 1.0000 - loss: 1.6693e-04 - val_accuracy: 0.7143 - val_loss: 4.4762\n",
      "Epoch 917/1000\n",
      "22/22 - 0s - 4ms/step - accuracy: 1.0000 - loss: 1.6506e-04 - val_accuracy: 0.7143 - val_loss: 4.4922\n",
      "Epoch 918/1000\n",
      "22/22 - 0s - 4ms/step - accuracy: 1.0000 - loss: 1.6011e-04 - val_accuracy: 0.7013 - val_loss: 4.4953\n",
      "Epoch 919/1000\n",
      "22/22 - 0s - 5ms/step - accuracy: 1.0000 - loss: 1.6570e-04 - val_accuracy: 0.7143 - val_loss: 4.5126\n",
      "Epoch 920/1000\n",
      "22/22 - 0s - 4ms/step - accuracy: 1.0000 - loss: 1.6118e-04 - val_accuracy: 0.7143 - val_loss: 4.5008\n",
      "Epoch 921/1000\n",
      "22/22 - 0s - 4ms/step - accuracy: 1.0000 - loss: 1.5803e-04 - val_accuracy: 0.7143 - val_loss: 4.5169\n",
      "Epoch 922/1000\n",
      "22/22 - 0s - 4ms/step - accuracy: 1.0000 - loss: 1.6400e-04 - val_accuracy: 0.7143 - val_loss: 4.5269\n",
      "Epoch 923/1000\n",
      "22/22 - 0s - 5ms/step - accuracy: 1.0000 - loss: 1.6207e-04 - val_accuracy: 0.7013 - val_loss: 4.4864\n",
      "Epoch 924/1000\n",
      "22/22 - 0s - 5ms/step - accuracy: 1.0000 - loss: 1.4853e-04 - val_accuracy: 0.7143 - val_loss: 4.5144\n",
      "Epoch 925/1000\n",
      "22/22 - 0s - 5ms/step - accuracy: 1.0000 - loss: 1.4153e-04 - val_accuracy: 0.7143 - val_loss: 4.5260\n",
      "Epoch 926/1000\n",
      "22/22 - 0s - 5ms/step - accuracy: 1.0000 - loss: 1.4612e-04 - val_accuracy: 0.7013 - val_loss: 4.5376\n",
      "Epoch 927/1000\n",
      "22/22 - 0s - 5ms/step - accuracy: 1.0000 - loss: 1.3995e-04 - val_accuracy: 0.7143 - val_loss: 4.5552\n",
      "Epoch 928/1000\n",
      "22/22 - 0s - 4ms/step - accuracy: 1.0000 - loss: 1.3729e-04 - val_accuracy: 0.7013 - val_loss: 4.5456\n",
      "Epoch 929/1000\n",
      "22/22 - 0s - 4ms/step - accuracy: 1.0000 - loss: 1.3813e-04 - val_accuracy: 0.7143 - val_loss: 4.5566\n",
      "Epoch 930/1000\n",
      "22/22 - 0s - 5ms/step - accuracy: 1.0000 - loss: 1.3398e-04 - val_accuracy: 0.7013 - val_loss: 4.5403\n",
      "Epoch 931/1000\n",
      "22/22 - 0s - 4ms/step - accuracy: 1.0000 - loss: 1.3282e-04 - val_accuracy: 0.7143 - val_loss: 4.5561\n",
      "Epoch 932/1000\n",
      "22/22 - 0s - 4ms/step - accuracy: 1.0000 - loss: 1.2845e-04 - val_accuracy: 0.7013 - val_loss: 4.5702\n",
      "Epoch 933/1000\n",
      "22/22 - 0s - 4ms/step - accuracy: 1.0000 - loss: 1.3063e-04 - val_accuracy: 0.7013 - val_loss: 4.5410\n",
      "Epoch 934/1000\n",
      "22/22 - 0s - 5ms/step - accuracy: 1.0000 - loss: 1.2438e-04 - val_accuracy: 0.7013 - val_loss: 4.5733\n",
      "Epoch 935/1000\n",
      "22/22 - 0s - 5ms/step - accuracy: 1.0000 - loss: 1.2436e-04 - val_accuracy: 0.7013 - val_loss: 4.5662\n",
      "Epoch 936/1000\n",
      "22/22 - 0s - 5ms/step - accuracy: 1.0000 - loss: 1.2554e-04 - val_accuracy: 0.7013 - val_loss: 4.5870\n",
      "Epoch 937/1000\n",
      "22/22 - 0s - 4ms/step - accuracy: 1.0000 - loss: 1.3036e-04 - val_accuracy: 0.7143 - val_loss: 4.6018\n",
      "Epoch 938/1000\n",
      "22/22 - 0s - 4ms/step - accuracy: 1.0000 - loss: 1.3297e-04 - val_accuracy: 0.7013 - val_loss: 4.5928\n",
      "Epoch 939/1000\n",
      "22/22 - 0s - 5ms/step - accuracy: 1.0000 - loss: 1.2591e-04 - val_accuracy: 0.7013 - val_loss: 4.5958\n",
      "Epoch 940/1000\n",
      "22/22 - 0s - 4ms/step - accuracy: 1.0000 - loss: 1.2380e-04 - val_accuracy: 0.7013 - val_loss: 4.6076\n",
      "Epoch 941/1000\n",
      "22/22 - 0s - 5ms/step - accuracy: 1.0000 - loss: 1.1778e-04 - val_accuracy: 0.7143 - val_loss: 4.6024\n",
      "Epoch 942/1000\n",
      "22/22 - 0s - 4ms/step - accuracy: 1.0000 - loss: 1.1041e-04 - val_accuracy: 0.7143 - val_loss: 4.6120\n",
      "Epoch 943/1000\n",
      "22/22 - 0s - 5ms/step - accuracy: 1.0000 - loss: 1.0911e-04 - val_accuracy: 0.7143 - val_loss: 4.6083\n",
      "Epoch 944/1000\n",
      "22/22 - 0s - 4ms/step - accuracy: 1.0000 - loss: 1.0962e-04 - val_accuracy: 0.7143 - val_loss: 4.6218\n",
      "Epoch 945/1000\n",
      "22/22 - 0s - 4ms/step - accuracy: 1.0000 - loss: 1.1247e-04 - val_accuracy: 0.7013 - val_loss: 4.6165\n",
      "Epoch 946/1000\n",
      "22/22 - 0s - 4ms/step - accuracy: 1.0000 - loss: 1.2367e-04 - val_accuracy: 0.7013 - val_loss: 4.6307\n",
      "Epoch 947/1000\n",
      "22/22 - 0s - 4ms/step - accuracy: 1.0000 - loss: 1.1150e-04 - val_accuracy: 0.7143 - val_loss: 4.6440\n",
      "Epoch 948/1000\n",
      "22/22 - 0s - 4ms/step - accuracy: 1.0000 - loss: 1.0222e-04 - val_accuracy: 0.7273 - val_loss: 4.6207\n",
      "Epoch 949/1000\n",
      "22/22 - 0s - 5ms/step - accuracy: 1.0000 - loss: 1.0293e-04 - val_accuracy: 0.7143 - val_loss: 4.6435\n",
      "Epoch 950/1000\n",
      "22/22 - 0s - 4ms/step - accuracy: 1.0000 - loss: 1.0314e-04 - val_accuracy: 0.7013 - val_loss: 4.6434\n",
      "Epoch 951/1000\n",
      "22/22 - 0s - 6ms/step - accuracy: 1.0000 - loss: 9.9983e-05 - val_accuracy: 0.7013 - val_loss: 4.6455\n",
      "Epoch 952/1000\n",
      "22/22 - 0s - 4ms/step - accuracy: 1.0000 - loss: 1.0455e-04 - val_accuracy: 0.7143 - val_loss: 4.6594\n",
      "Epoch 953/1000\n",
      "22/22 - 0s - 4ms/step - accuracy: 1.0000 - loss: 9.7866e-05 - val_accuracy: 0.7013 - val_loss: 4.6576\n",
      "Epoch 954/1000\n",
      "22/22 - 0s - 4ms/step - accuracy: 1.0000 - loss: 9.6167e-05 - val_accuracy: 0.7143 - val_loss: 4.6564\n",
      "Epoch 955/1000\n",
      "22/22 - 0s - 5ms/step - accuracy: 1.0000 - loss: 9.5755e-05 - val_accuracy: 0.7143 - val_loss: 4.6753\n",
      "Epoch 956/1000\n",
      "22/22 - 0s - 6ms/step - accuracy: 1.0000 - loss: 9.7457e-05 - val_accuracy: 0.7013 - val_loss: 4.6835\n",
      "Epoch 957/1000\n",
      "22/22 - 0s - 6ms/step - accuracy: 1.0000 - loss: 9.3766e-05 - val_accuracy: 0.7273 - val_loss: 4.6832\n",
      "Epoch 958/1000\n",
      "22/22 - 0s - 5ms/step - accuracy: 1.0000 - loss: 9.1215e-05 - val_accuracy: 0.7143 - val_loss: 4.7043\n",
      "Epoch 959/1000\n",
      "22/22 - 0s - 5ms/step - accuracy: 1.0000 - loss: 9.2680e-05 - val_accuracy: 0.7143 - val_loss: 4.6990\n",
      "Epoch 960/1000\n",
      "22/22 - 0s - 4ms/step - accuracy: 1.0000 - loss: 8.5417e-05 - val_accuracy: 0.7273 - val_loss: 4.6941\n",
      "Epoch 961/1000\n",
      "22/22 - 0s - 4ms/step - accuracy: 1.0000 - loss: 8.7261e-05 - val_accuracy: 0.7143 - val_loss: 4.6964\n",
      "Epoch 962/1000\n",
      "22/22 - 0s - 4ms/step - accuracy: 1.0000 - loss: 8.8133e-05 - val_accuracy: 0.7143 - val_loss: 4.6926\n",
      "Epoch 963/1000\n",
      "22/22 - 0s - 4ms/step - accuracy: 1.0000 - loss: 9.4787e-05 - val_accuracy: 0.7013 - val_loss: 4.7457\n",
      "Epoch 964/1000\n",
      "22/22 - 0s - 4ms/step - accuracy: 1.0000 - loss: 8.8232e-05 - val_accuracy: 0.7143 - val_loss: 4.7243\n",
      "Epoch 965/1000\n",
      "22/22 - 0s - 5ms/step - accuracy: 1.0000 - loss: 8.2302e-05 - val_accuracy: 0.7143 - val_loss: 4.7146\n",
      "Epoch 966/1000\n",
      "22/22 - 0s - 4ms/step - accuracy: 1.0000 - loss: 8.4705e-05 - val_accuracy: 0.7143 - val_loss: 4.7212\n",
      "Epoch 967/1000\n",
      "22/22 - 0s - 5ms/step - accuracy: 1.0000 - loss: 8.1061e-05 - val_accuracy: 0.7143 - val_loss: 4.7317\n",
      "Epoch 968/1000\n",
      "22/22 - 0s - 4ms/step - accuracy: 1.0000 - loss: 8.0819e-05 - val_accuracy: 0.7143 - val_loss: 4.7250\n",
      "Epoch 969/1000\n",
      "22/22 - 0s - 5ms/step - accuracy: 1.0000 - loss: 8.2512e-05 - val_accuracy: 0.7143 - val_loss: 4.7568\n",
      "Epoch 970/1000\n",
      "22/22 - 0s - 5ms/step - accuracy: 1.0000 - loss: 7.8691e-05 - val_accuracy: 0.7143 - val_loss: 4.7440\n",
      "Epoch 971/1000\n",
      "22/22 - 0s - 4ms/step - accuracy: 1.0000 - loss: 8.0140e-05 - val_accuracy: 0.7143 - val_loss: 4.7525\n",
      "Epoch 972/1000\n",
      "22/22 - 0s - 5ms/step - accuracy: 1.0000 - loss: 7.6854e-05 - val_accuracy: 0.7143 - val_loss: 4.7602\n",
      "Epoch 973/1000\n",
      "22/22 - 0s - 4ms/step - accuracy: 1.0000 - loss: 7.4793e-05 - val_accuracy: 0.7143 - val_loss: 4.7750\n",
      "Epoch 974/1000\n",
      "22/22 - 0s - 4ms/step - accuracy: 1.0000 - loss: 7.4904e-05 - val_accuracy: 0.7143 - val_loss: 4.7701\n",
      "Epoch 975/1000\n",
      "22/22 - 0s - 4ms/step - accuracy: 1.0000 - loss: 7.6629e-05 - val_accuracy: 0.7143 - val_loss: 4.7535\n",
      "Epoch 976/1000\n",
      "22/22 - 0s - 4ms/step - accuracy: 1.0000 - loss: 7.1281e-05 - val_accuracy: 0.7143 - val_loss: 4.7687\n",
      "Epoch 977/1000\n",
      "22/22 - 0s - 4ms/step - accuracy: 1.0000 - loss: 7.1706e-05 - val_accuracy: 0.7143 - val_loss: 4.7936\n",
      "Epoch 978/1000\n",
      "22/22 - 0s - 5ms/step - accuracy: 1.0000 - loss: 6.9922e-05 - val_accuracy: 0.7143 - val_loss: 4.7893\n",
      "Epoch 979/1000\n",
      "22/22 - 0s - 4ms/step - accuracy: 1.0000 - loss: 7.0159e-05 - val_accuracy: 0.7143 - val_loss: 4.7708\n",
      "Epoch 980/1000\n",
      "22/22 - 0s - 4ms/step - accuracy: 1.0000 - loss: 6.8891e-05 - val_accuracy: 0.7143 - val_loss: 4.7963\n",
      "Epoch 981/1000\n",
      "22/22 - 0s - 4ms/step - accuracy: 1.0000 - loss: 6.8457e-05 - val_accuracy: 0.7143 - val_loss: 4.7912\n",
      "Epoch 982/1000\n",
      "22/22 - 0s - 4ms/step - accuracy: 1.0000 - loss: 7.2946e-05 - val_accuracy: 0.7143 - val_loss: 4.7809\n",
      "Epoch 983/1000\n",
      "22/22 - 0s - 5ms/step - accuracy: 1.0000 - loss: 6.9011e-05 - val_accuracy: 0.7143 - val_loss: 4.8195\n",
      "Epoch 984/1000\n",
      "22/22 - 0s - 4ms/step - accuracy: 1.0000 - loss: 6.3909e-05 - val_accuracy: 0.7143 - val_loss: 4.8061\n",
      "Epoch 985/1000\n",
      "22/22 - 0s - 5ms/step - accuracy: 1.0000 - loss: 6.8163e-05 - val_accuracy: 0.7143 - val_loss: 4.8034\n",
      "Epoch 986/1000\n",
      "22/22 - 0s - 5ms/step - accuracy: 1.0000 - loss: 7.1165e-05 - val_accuracy: 0.7143 - val_loss: 4.8354\n",
      "Epoch 987/1000\n",
      "22/22 - 0s - 4ms/step - accuracy: 1.0000 - loss: 7.2225e-05 - val_accuracy: 0.7143 - val_loss: 4.7990\n",
      "Epoch 988/1000\n",
      "22/22 - 0s - 4ms/step - accuracy: 1.0000 - loss: 7.7042e-05 - val_accuracy: 0.7143 - val_loss: 4.7652\n",
      "Epoch 989/1000\n",
      "22/22 - 0s - 4ms/step - accuracy: 1.0000 - loss: 9.4470e-05 - val_accuracy: 0.6883 - val_loss: 4.9418\n",
      "Epoch 990/1000\n",
      "22/22 - 0s - 4ms/step - accuracy: 1.0000 - loss: 9.3958e-05 - val_accuracy: 0.7143 - val_loss: 4.7524\n",
      "Epoch 991/1000\n",
      "22/22 - 0s - 4ms/step - accuracy: 1.0000 - loss: 7.7990e-05 - val_accuracy: 0.7143 - val_loss: 4.8033\n",
      "Epoch 992/1000\n",
      "22/22 - 0s - 5ms/step - accuracy: 1.0000 - loss: 6.2479e-05 - val_accuracy: 0.7143 - val_loss: 4.8509\n",
      "Epoch 993/1000\n",
      "22/22 - 0s - 5ms/step - accuracy: 1.0000 - loss: 6.2035e-05 - val_accuracy: 0.7143 - val_loss: 4.8193\n",
      "Epoch 994/1000\n",
      "22/22 - 0s - 4ms/step - accuracy: 1.0000 - loss: 5.6559e-05 - val_accuracy: 0.7143 - val_loss: 4.8291\n",
      "Epoch 995/1000\n",
      "22/22 - 0s - 4ms/step - accuracy: 1.0000 - loss: 5.5206e-05 - val_accuracy: 0.7143 - val_loss: 4.8690\n",
      "Epoch 996/1000\n",
      "22/22 - 0s - 4ms/step - accuracy: 1.0000 - loss: 5.5106e-05 - val_accuracy: 0.7143 - val_loss: 4.8745\n",
      "Epoch 997/1000\n",
      "22/22 - 0s - 4ms/step - accuracy: 1.0000 - loss: 5.5918e-05 - val_accuracy: 0.7143 - val_loss: 4.8612\n",
      "Epoch 998/1000\n",
      "22/22 - 0s - 4ms/step - accuracy: 1.0000 - loss: 5.3553e-05 - val_accuracy: 0.7143 - val_loss: 4.8743\n",
      "Epoch 999/1000\n",
      "22/22 - 0s - 4ms/step - accuracy: 1.0000 - loss: 5.3831e-05 - val_accuracy: 0.7143 - val_loss: 4.8715\n",
      "Epoch 1000/1000\n",
      "22/22 - 0s - 4ms/step - accuracy: 1.0000 - loss: 5.1591e-05 - val_accuracy: 0.7143 - val_loss: 4.8782\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    x, \n",
    "    y, \n",
    "    batch_size=32,          # Her adımda modele 32 veri örneği gösterilir\n",
    "    validation_split=0.10,  # Verinin %10'u doğrulama (validation) için ayrılır. Dolayısıyla tekrardan train_test_split yapmama gerek kalmaz.\n",
    "    verbose=2,              # Eğitim çıktılarının ekranda gösterim detay seviyesi\n",
    "    epochs=1000             # Model veriyi 1000 kez tekrar tekrar görerek öğrenir\n",
    ")\n",
    "# model.fit: modeli eğiten fonksiyondur\n",
    "# Eğitim sürecindeki kayıp (loss) ve doğruluk (accuracy) değerleri \"history\" içinde tutulur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6cbc7c12-ec49-4a7a-a31f-10ae61778a3b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">80</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">720</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">120</span>)                 │           <span style=\"color: #00af00; text-decoration-color: #00af00\">9,720</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">80</span>)                  │           <span style=\"color: #00af00; text-decoration-color: #00af00\">9,680</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>)                  │           <span style=\"color: #00af00; text-decoration-color: #00af00\">2,430</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                   │              <span style=\"color: #00af00; text-decoration-color: #00af00\">31</span> │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m80\u001b[0m)                  │             \u001b[38;5;34m720\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m120\u001b[0m)                 │           \u001b[38;5;34m9,720\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m80\u001b[0m)                  │           \u001b[38;5;34m9,680\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m)                  │           \u001b[38;5;34m2,430\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_4 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)                   │              \u001b[38;5;34m31\u001b[0m │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">67,745</span> (264.63 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m67,745\u001b[0m (264.63 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">22,581</span> (88.21 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m22,581\u001b[0m (88.21 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Optimizer params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">45,164</span> (176.43 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Optimizer params: \u001b[0m\u001b[38;5;34m45,164\u001b[0m (176.43 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.summary()\n",
    "# Modelin katmanlarını, her katmandaki nöron sayısını,\n",
    "# toplam parametre (ağırlık + bias) miktarını\n",
    "# ve genel mimari yapısını tablo halinde gösterir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2ad56feb-b849-4e4d-b367-3b17bd9dec09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9714 - loss: 0.4891     \n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = model.evaluate(x, y)\n",
    "# evaluate: modeli verilen veri üzerinde test eder\n",
    "# loss: modelin hata miktarı (ne kadar düşükse o kadar iyi)\n",
    "# accuracy: modelin doğruluk oranı (0 ile 1 arasında değer döner)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8af43267-e878-443f-b39c-e7eee5b27b1b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9713541865348816"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy\n",
    "# Eğitilen modelin doğruluk (accuracy) değerini ekranda gösterir\n",
    "# 1'e ne kadar yakınsa model o kadar iyi tahmin yapıyor demektir"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb72201d-de10-4d0b-969d-7b34eb2369e4",
   "metadata": {},
   "source": [
    "##### _Verilerin Standardize Edilmesi (StandardScaler)_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "af8bfed5-ca1c-4912-9999-3d754b121ce6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "# Verileri ölçeklemek (standartlaştırmak) için kullanılan sınıf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0df5b64e-6607-4fa9-82a5-4b82d1299f57",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "# StandardScaler nesnesi oluşturulur (ortalama=0, std=1 olacak şekilde ölçeklendirme yapar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a1b66cb7-2ff5-4201-979a-9b37ca5c7d5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = scaler.fit_transform(x)\n",
    "# X verisi önce \"fit\" edilip (ortalama ve std hesaplanır)\n",
    "# ardından \"transform\" edilip ölçeklendirilir\n",
    "# Modelin daha hızlı ve stabil öğrenmesini sağlar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "66fbbfbb-98c0-4735-b0ba-a1a96760a944",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "22/22 - 0s - 5ms/step - accuracy: 0.6715 - loss: 1.4662 - val_accuracy: 0.5714 - val_loss: 0.8763\n",
      "Epoch 2/100\n",
      "22/22 - 0s - 4ms/step - accuracy: 0.7149 - loss: 0.5764 - val_accuracy: 0.6104 - val_loss: 0.6697\n",
      "Epoch 3/100\n",
      "22/22 - 0s - 4ms/step - accuracy: 0.7366 - loss: 0.4995 - val_accuracy: 0.6494 - val_loss: 0.6356\n",
      "Epoch 4/100\n",
      "22/22 - 0s - 5ms/step - accuracy: 0.7815 - loss: 0.4454 - val_accuracy: 0.7792 - val_loss: 0.6329\n",
      "Epoch 5/100\n",
      "22/22 - 0s - 4ms/step - accuracy: 0.7858 - loss: 0.4284 - val_accuracy: 0.7403 - val_loss: 0.6054\n",
      "Epoch 6/100\n",
      "22/22 - 0s - 4ms/step - accuracy: 0.8133 - loss: 0.4073 - val_accuracy: 0.7662 - val_loss: 0.6167\n",
      "Epoch 7/100\n",
      "22/22 - 0s - 5ms/step - accuracy: 0.8191 - loss: 0.3954 - val_accuracy: 0.7532 - val_loss: 0.6437\n",
      "Epoch 8/100\n",
      "22/22 - 0s - 4ms/step - accuracy: 0.8191 - loss: 0.3888 - val_accuracy: 0.7273 - val_loss: 0.6103\n",
      "Epoch 9/100\n",
      "22/22 - 0s - 4ms/step - accuracy: 0.8394 - loss: 0.3496 - val_accuracy: 0.7143 - val_loss: 0.6506\n",
      "Epoch 10/100\n",
      "22/22 - 0s - 4ms/step - accuracy: 0.8495 - loss: 0.3446 - val_accuracy: 0.7532 - val_loss: 0.6819\n",
      "Epoch 11/100\n",
      "22/22 - 0s - 4ms/step - accuracy: 0.8466 - loss: 0.3321 - val_accuracy: 0.7532 - val_loss: 0.6877\n",
      "Epoch 12/100\n",
      "22/22 - 0s - 4ms/step - accuracy: 0.8553 - loss: 0.3252 - val_accuracy: 0.7143 - val_loss: 0.6870\n",
      "Epoch 13/100\n",
      "22/22 - 0s - 4ms/step - accuracy: 0.8625 - loss: 0.3184 - val_accuracy: 0.7662 - val_loss: 0.7346\n",
      "Epoch 14/100\n",
      "22/22 - 0s - 5ms/step - accuracy: 0.8741 - loss: 0.2990 - val_accuracy: 0.7662 - val_loss: 0.7207\n",
      "Epoch 15/100\n",
      "22/22 - 0s - 4ms/step - accuracy: 0.8726 - loss: 0.2876 - val_accuracy: 0.7662 - val_loss: 0.7255\n",
      "Epoch 16/100\n",
      "22/22 - 0s - 4ms/step - accuracy: 0.8813 - loss: 0.2808 - val_accuracy: 0.7273 - val_loss: 0.7382\n",
      "Epoch 17/100\n",
      "22/22 - 0s - 4ms/step - accuracy: 0.8886 - loss: 0.2638 - val_accuracy: 0.7403 - val_loss: 0.7807\n",
      "Epoch 18/100\n",
      "22/22 - 0s - 4ms/step - accuracy: 0.8857 - loss: 0.2561 - val_accuracy: 0.7143 - val_loss: 0.7346\n",
      "Epoch 19/100\n",
      "22/22 - 0s - 4ms/step - accuracy: 0.9001 - loss: 0.2461 - val_accuracy: 0.7662 - val_loss: 0.7620\n",
      "Epoch 20/100\n",
      "22/22 - 0s - 4ms/step - accuracy: 0.9059 - loss: 0.2443 - val_accuracy: 0.7532 - val_loss: 0.8021\n",
      "Epoch 21/100\n",
      "22/22 - 0s - 4ms/step - accuracy: 0.8929 - loss: 0.2421 - val_accuracy: 0.7532 - val_loss: 0.7865\n",
      "Epoch 22/100\n",
      "22/22 - 0s - 4ms/step - accuracy: 0.9059 - loss: 0.2324 - val_accuracy: 0.7662 - val_loss: 0.8182\n",
      "Epoch 23/100\n",
      "22/22 - 0s - 4ms/step - accuracy: 0.9146 - loss: 0.2216 - val_accuracy: 0.7532 - val_loss: 0.8626\n",
      "Epoch 24/100\n",
      "22/22 - 0s - 4ms/step - accuracy: 0.9190 - loss: 0.2096 - val_accuracy: 0.7403 - val_loss: 0.8491\n",
      "Epoch 25/100\n",
      "22/22 - 0s - 5ms/step - accuracy: 0.9291 - loss: 0.1964 - val_accuracy: 0.7792 - val_loss: 0.8880\n",
      "Epoch 26/100\n",
      "22/22 - 0s - 4ms/step - accuracy: 0.9233 - loss: 0.2030 - val_accuracy: 0.7792 - val_loss: 0.8662\n",
      "Epoch 27/100\n",
      "22/22 - 0s - 4ms/step - accuracy: 0.9334 - loss: 0.1910 - val_accuracy: 0.7273 - val_loss: 0.9356\n",
      "Epoch 28/100\n",
      "22/22 - 0s - 5ms/step - accuracy: 0.9276 - loss: 0.1835 - val_accuracy: 0.7273 - val_loss: 0.9824\n",
      "Epoch 29/100\n",
      "22/22 - 0s - 4ms/step - accuracy: 0.9334 - loss: 0.1766 - val_accuracy: 0.7662 - val_loss: 0.9921\n",
      "Epoch 30/100\n",
      "22/22 - 0s - 4ms/step - accuracy: 0.9363 - loss: 0.1826 - val_accuracy: 0.7662 - val_loss: 0.8799\n",
      "Epoch 31/100\n",
      "22/22 - 0s - 5ms/step - accuracy: 0.9421 - loss: 0.1629 - val_accuracy: 0.7013 - val_loss: 1.0133\n",
      "Epoch 32/100\n",
      "22/22 - 0s - 5ms/step - accuracy: 0.9450 - loss: 0.1656 - val_accuracy: 0.7532 - val_loss: 0.9733\n",
      "Epoch 33/100\n",
      "22/22 - 0s - 5ms/step - accuracy: 0.9436 - loss: 0.1556 - val_accuracy: 0.7143 - val_loss: 1.0265\n",
      "Epoch 34/100\n",
      "22/22 - 0s - 5ms/step - accuracy: 0.9493 - loss: 0.1420 - val_accuracy: 0.7403 - val_loss: 1.0833\n",
      "Epoch 35/100\n",
      "22/22 - 0s - 5ms/step - accuracy: 0.9537 - loss: 0.1348 - val_accuracy: 0.7662 - val_loss: 1.0860\n",
      "Epoch 36/100\n",
      "22/22 - 0s - 5ms/step - accuracy: 0.9508 - loss: 0.1409 - val_accuracy: 0.7922 - val_loss: 1.0735\n",
      "Epoch 37/100\n",
      "22/22 - 0s - 5ms/step - accuracy: 0.9566 - loss: 0.1314 - val_accuracy: 0.7532 - val_loss: 1.1962\n",
      "Epoch 38/100\n",
      "22/22 - 0s - 5ms/step - accuracy: 0.9522 - loss: 0.1246 - val_accuracy: 0.7922 - val_loss: 1.1693\n",
      "Epoch 39/100\n",
      "22/22 - 0s - 5ms/step - accuracy: 0.9580 - loss: 0.1227 - val_accuracy: 0.7922 - val_loss: 1.1851\n",
      "Epoch 40/100\n",
      "22/22 - 0s - 5ms/step - accuracy: 0.9580 - loss: 0.1130 - val_accuracy: 0.7403 - val_loss: 1.2549\n",
      "Epoch 41/100\n",
      "22/22 - 0s - 4ms/step - accuracy: 0.9566 - loss: 0.1166 - val_accuracy: 0.7662 - val_loss: 1.2538\n",
      "Epoch 42/100\n",
      "22/22 - 0s - 5ms/step - accuracy: 0.9609 - loss: 0.1121 - val_accuracy: 0.7532 - val_loss: 1.3275\n",
      "Epoch 43/100\n",
      "22/22 - 0s - 5ms/step - accuracy: 0.9711 - loss: 0.1018 - val_accuracy: 0.7532 - val_loss: 1.3110\n",
      "Epoch 44/100\n",
      "22/22 - 0s - 5ms/step - accuracy: 0.9638 - loss: 0.0976 - val_accuracy: 0.7922 - val_loss: 1.3650\n",
      "Epoch 45/100\n",
      "22/22 - 0s - 5ms/step - accuracy: 0.9653 - loss: 0.1002 - val_accuracy: 0.7403 - val_loss: 1.3096\n",
      "Epoch 46/100\n",
      "22/22 - 0s - 5ms/step - accuracy: 0.9653 - loss: 0.0922 - val_accuracy: 0.7662 - val_loss: 1.3948\n",
      "Epoch 47/100\n",
      "22/22 - 0s - 5ms/step - accuracy: 0.9768 - loss: 0.0834 - val_accuracy: 0.7922 - val_loss: 1.4253\n",
      "Epoch 48/100\n",
      "22/22 - 0s - 5ms/step - accuracy: 0.9740 - loss: 0.0811 - val_accuracy: 0.7792 - val_loss: 1.4312\n",
      "Epoch 49/100\n",
      "22/22 - 0s - 5ms/step - accuracy: 0.9740 - loss: 0.0749 - val_accuracy: 0.7792 - val_loss: 1.4348\n",
      "Epoch 50/100\n",
      "22/22 - 0s - 6ms/step - accuracy: 0.9768 - loss: 0.0711 - val_accuracy: 0.7792 - val_loss: 1.5058\n",
      "Epoch 51/100\n",
      "22/22 - 0s - 5ms/step - accuracy: 0.9754 - loss: 0.0777 - val_accuracy: 0.7403 - val_loss: 1.5795\n",
      "Epoch 52/100\n",
      "22/22 - 0s - 7ms/step - accuracy: 0.9812 - loss: 0.0698 - val_accuracy: 0.7662 - val_loss: 1.5258\n",
      "Epoch 53/100\n",
      "22/22 - 0s - 6ms/step - accuracy: 0.9812 - loss: 0.0626 - val_accuracy: 0.7273 - val_loss: 1.6046\n",
      "Epoch 54/100\n",
      "22/22 - 0s - 6ms/step - accuracy: 0.9826 - loss: 0.0612 - val_accuracy: 0.7922 - val_loss: 1.6398\n",
      "Epoch 55/100\n",
      "22/22 - 0s - 5ms/step - accuracy: 0.9812 - loss: 0.0620 - val_accuracy: 0.7662 - val_loss: 1.6488\n",
      "Epoch 56/100\n",
      "22/22 - 0s - 4ms/step - accuracy: 0.9797 - loss: 0.0658 - val_accuracy: 0.7922 - val_loss: 1.6738\n",
      "Epoch 57/100\n",
      "22/22 - 0s - 4ms/step - accuracy: 0.9884 - loss: 0.0536 - val_accuracy: 0.7532 - val_loss: 1.7277\n",
      "Epoch 58/100\n",
      "22/22 - 0s - 4ms/step - accuracy: 0.9841 - loss: 0.0543 - val_accuracy: 0.7662 - val_loss: 1.7626\n",
      "Epoch 59/100\n",
      "22/22 - 0s - 4ms/step - accuracy: 0.9884 - loss: 0.0479 - val_accuracy: 0.7532 - val_loss: 1.8096\n",
      "Epoch 60/100\n",
      "22/22 - 0s - 4ms/step - accuracy: 0.9855 - loss: 0.0478 - val_accuracy: 0.7403 - val_loss: 1.8853\n",
      "Epoch 61/100\n",
      "22/22 - 0s - 4ms/step - accuracy: 0.9884 - loss: 0.0425 - val_accuracy: 0.8052 - val_loss: 1.8768\n",
      "Epoch 62/100\n",
      "22/22 - 0s - 6ms/step - accuracy: 0.9942 - loss: 0.0374 - val_accuracy: 0.7532 - val_loss: 1.9226\n",
      "Epoch 63/100\n",
      "22/22 - 0s - 4ms/step - accuracy: 0.9942 - loss: 0.0355 - val_accuracy: 0.7922 - val_loss: 1.9082\n",
      "Epoch 64/100\n",
      "22/22 - 0s - 4ms/step - accuracy: 0.9913 - loss: 0.0352 - val_accuracy: 0.7792 - val_loss: 1.9822\n",
      "Epoch 65/100\n",
      "22/22 - 0s - 4ms/step - accuracy: 0.9899 - loss: 0.0383 - val_accuracy: 0.7662 - val_loss: 1.9211\n",
      "Epoch 66/100\n",
      "22/22 - 0s - 4ms/step - accuracy: 0.9884 - loss: 0.0418 - val_accuracy: 0.7792 - val_loss: 1.8999\n",
      "Epoch 67/100\n",
      "22/22 - 0s - 4ms/step - accuracy: 0.9928 - loss: 0.0349 - val_accuracy: 0.7922 - val_loss: 1.8574\n",
      "Epoch 68/100\n",
      "22/22 - 0s - 4ms/step - accuracy: 0.9942 - loss: 0.0298 - val_accuracy: 0.7792 - val_loss: 2.0005\n",
      "Epoch 69/100\n",
      "22/22 - 0s - 5ms/step - accuracy: 0.9928 - loss: 0.0283 - val_accuracy: 0.7662 - val_loss: 2.0368\n",
      "Epoch 70/100\n",
      "22/22 - 0s - 4ms/step - accuracy: 0.9942 - loss: 0.0291 - val_accuracy: 0.8052 - val_loss: 1.9370\n",
      "Epoch 71/100\n",
      "22/22 - 0s - 4ms/step - accuracy: 0.9913 - loss: 0.0285 - val_accuracy: 0.7792 - val_loss: 1.9807\n",
      "Epoch 72/100\n",
      "22/22 - 0s - 6ms/step - accuracy: 0.9957 - loss: 0.0242 - val_accuracy: 0.8052 - val_loss: 2.0175\n",
      "Epoch 73/100\n",
      "22/22 - 0s - 5ms/step - accuracy: 0.9957 - loss: 0.0255 - val_accuracy: 0.7922 - val_loss: 2.1029\n",
      "Epoch 74/100\n",
      "22/22 - 0s - 4ms/step - accuracy: 0.9986 - loss: 0.0199 - val_accuracy: 0.7792 - val_loss: 2.0688\n",
      "Epoch 75/100\n",
      "22/22 - 0s - 4ms/step - accuracy: 0.9942 - loss: 0.0230 - val_accuracy: 0.7662 - val_loss: 2.0990\n",
      "Epoch 76/100\n",
      "22/22 - 0s - 4ms/step - accuracy: 0.9928 - loss: 0.0242 - val_accuracy: 0.7792 - val_loss: 2.1611\n",
      "Epoch 77/100\n",
      "22/22 - 0s - 4ms/step - accuracy: 0.9957 - loss: 0.0240 - val_accuracy: 0.7792 - val_loss: 2.1466\n",
      "Epoch 78/100\n",
      "22/22 - 0s - 4ms/step - accuracy: 1.0000 - loss: 0.0179 - val_accuracy: 0.7792 - val_loss: 2.2269\n",
      "Epoch 79/100\n",
      "22/22 - 0s - 4ms/step - accuracy: 0.9957 - loss: 0.0207 - val_accuracy: 0.7532 - val_loss: 2.2166\n",
      "Epoch 80/100\n",
      "22/22 - 0s - 4ms/step - accuracy: 0.9971 - loss: 0.0164 - val_accuracy: 0.7792 - val_loss: 2.2758\n",
      "Epoch 81/100\n",
      "22/22 - 0s - 4ms/step - accuracy: 0.9986 - loss: 0.0149 - val_accuracy: 0.7662 - val_loss: 2.2984\n",
      "Epoch 82/100\n",
      "22/22 - 0s - 4ms/step - accuracy: 1.0000 - loss: 0.0139 - val_accuracy: 0.8052 - val_loss: 2.3067\n",
      "Epoch 83/100\n",
      "22/22 - 0s - 5ms/step - accuracy: 0.9986 - loss: 0.0116 - val_accuracy: 0.7922 - val_loss: 2.3218\n",
      "Epoch 84/100\n",
      "22/22 - 0s - 4ms/step - accuracy: 1.0000 - loss: 0.0123 - val_accuracy: 0.7922 - val_loss: 2.3778\n",
      "Epoch 85/100\n",
      "22/22 - 0s - 4ms/step - accuracy: 0.9971 - loss: 0.0162 - val_accuracy: 0.7662 - val_loss: 2.3542\n",
      "Epoch 86/100\n",
      "22/22 - 0s - 4ms/step - accuracy: 0.9971 - loss: 0.0139 - val_accuracy: 0.7532 - val_loss: 2.3972\n",
      "Epoch 87/100\n",
      "22/22 - 0s - 4ms/step - accuracy: 0.9986 - loss: 0.0111 - val_accuracy: 0.8052 - val_loss: 2.4246\n",
      "Epoch 88/100\n",
      "22/22 - 0s - 4ms/step - accuracy: 0.9971 - loss: 0.0117 - val_accuracy: 0.7922 - val_loss: 2.4295\n",
      "Epoch 89/100\n",
      "22/22 - 0s - 4ms/step - accuracy: 0.9986 - loss: 0.0104 - val_accuracy: 0.7792 - val_loss: 2.4539\n",
      "Epoch 90/100\n",
      "22/22 - 0s - 4ms/step - accuracy: 0.9986 - loss: 0.0096 - val_accuracy: 0.8052 - val_loss: 2.4670\n",
      "Epoch 91/100\n",
      "22/22 - 0s - 5ms/step - accuracy: 0.9971 - loss: 0.0108 - val_accuracy: 0.7662 - val_loss: 2.4690\n",
      "Epoch 92/100\n",
      "22/22 - 0s - 4ms/step - accuracy: 0.9971 - loss: 0.0127 - val_accuracy: 0.7273 - val_loss: 2.4885\n",
      "Epoch 93/100\n",
      "22/22 - 0s - 5ms/step - accuracy: 0.9986 - loss: 0.0158 - val_accuracy: 0.7792 - val_loss: 2.5510\n",
      "Epoch 94/100\n",
      "22/22 - 0s - 4ms/step - accuracy: 0.9986 - loss: 0.0092 - val_accuracy: 0.7143 - val_loss: 2.5032\n",
      "Epoch 95/100\n",
      "22/22 - 0s - 4ms/step - accuracy: 0.9986 - loss: 0.0099 - val_accuracy: 0.7922 - val_loss: 2.4802\n",
      "Epoch 96/100\n",
      "22/22 - 0s - 5ms/step - accuracy: 0.9986 - loss: 0.0081 - val_accuracy: 0.7792 - val_loss: 2.4919\n",
      "Epoch 97/100\n",
      "22/22 - 0s - 5ms/step - accuracy: 0.9986 - loss: 0.0069 - val_accuracy: 0.7662 - val_loss: 2.5078\n",
      "Epoch 98/100\n",
      "22/22 - 0s - 4ms/step - accuracy: 0.9986 - loss: 0.0078 - val_accuracy: 0.7792 - val_loss: 2.5710\n",
      "Epoch 99/100\n",
      "22/22 - 0s - 4ms/step - accuracy: 1.0000 - loss: 0.0066 - val_accuracy: 0.7662 - val_loss: 2.5111\n",
      "Epoch 100/100\n",
      "22/22 - 0s - 4ms/step - accuracy: 1.0000 - loss: 0.0057 - val_accuracy: 0.7662 - val_loss: 2.5789\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    x, y,\n",
    "    batch_size=32,          # Her adımda 32 örnek kullanılır\n",
    "    validation_split=0.10,  # Verinin %10'u doğrulama için ayrılır\n",
    "    verbose=2,              # Eğitim çıktısı detay seviyesi\n",
    "    epochs=100              # Model veri üzerinde 100 kez eğitilir\n",
    ")\n",
    "# Ölçeklendirilmiş veri ile model yeniden eğitilir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "fbbc0311-8ef6-4849-b78d-bdcb601c7384",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9753 - loss: 0.2642 \n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = model.evaluate(x, y)\n",
    "# Modelin ölçeklendirilmiş veri üzerindeki performansını ölçer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1aea25ae-20cd-4b5d-8ddb-e22f61c07a6f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9752604365348816"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy\n",
    "# Doğruluk oranını ekranda gösterir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4aed1ba9-9713-4959-97cb-ddf6200063aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "# Grafik çizimleri (plot) yapmak için kullanılan kütüphane"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ea0eeecd-8852-4ae8-a37b-9b066a8c29de",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x143e82bdf90>]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['accuracy'])\n",
    "# Eğitim (train) doğruluk değerlerinin epoch’lara göre değişimini çizer\n",
    "\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "# Doğrulama (validation) doğruluk değerlerini çizer; modelin aşırı öğrenip öğrenmediğini anlamak için kullanılır"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa3fd5c0-5860-4350-9c55-9f57bb3617aa",
   "metadata": {},
   "source": [
    "#### _Regression_ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3b241c8d-9809-48b9-bc2a-ab5d6c068e8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_pickle('kc_house.pkl')\n",
    "# Pickle formatındaki veri dosyasını okur ve DataFrame’e aktarır"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9f407c2f-c7b1-4324-ba5e-8677445a87d8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bedrooms</th>\n",
       "      <th>bathrooms</th>\n",
       "      <th>sqft_living</th>\n",
       "      <th>grade</th>\n",
       "      <th>view</th>\n",
       "      <th>basement</th>\n",
       "      <th>waterfront</th>\n",
       "      <th>floors</th>\n",
       "      <th>age</th>\n",
       "      <th>renovated</th>\n",
       "      <th>...</th>\n",
       "      <th>zipcode_98146</th>\n",
       "      <th>zipcode_98148</th>\n",
       "      <th>zipcode_98155</th>\n",
       "      <th>zipcode_98166</th>\n",
       "      <th>zipcode_98168</th>\n",
       "      <th>zipcode_98177</th>\n",
       "      <th>zipcode_98178</th>\n",
       "      <th>zipcode_98188</th>\n",
       "      <th>zipcode_98198</th>\n",
       "      <th>zipcode_98199</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1180</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>65</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9</td>\n",
       "      <td>5.0625</td>\n",
       "      <td>2570</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>69</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>770</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>87</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>16</td>\n",
       "      <td>9.0000</td>\n",
       "      <td>1960</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>55</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9</td>\n",
       "      <td>4.0000</td>\n",
       "      <td>1680</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>33</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 82 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   bedrooms  bathrooms  sqft_living  grade  view  basement  waterfront  \\\n",
       "0         9     1.0000         1180      7     0         0           0   \n",
       "1         9     5.0625         2570      7     0         1           0   \n",
       "2         4     1.0000          770      6     0         0           0   \n",
       "3        16     9.0000         1960      7     0         1           0   \n",
       "4         9     4.0000         1680      8     0         0           0   \n",
       "\n",
       "   floors  age  renovated  ...  zipcode_98146  zipcode_98148  zipcode_98155  \\\n",
       "0     1.0   65          0  ...              0              0              0   \n",
       "1     2.0   69          1  ...              0              0              0   \n",
       "2     1.0   87          0  ...              0              0              0   \n",
       "3     1.0   55          0  ...              0              0              0   \n",
       "4     1.0   33          0  ...              0              0              0   \n",
       "\n",
       "   zipcode_98166  zipcode_98168  zipcode_98177  zipcode_98178  zipcode_98188  \\\n",
       "0              0              0              0              1              0   \n",
       "1              0              0              0              0              0   \n",
       "2              0              0              0              0              0   \n",
       "3              0              0              0              0              0   \n",
       "4              0              0              0              0              0   \n",
       "\n",
       "   zipcode_98198  zipcode_98199  \n",
       "0              0              0  \n",
       "1              0              0  \n",
       "2              0              0  \n",
       "3              0              0  \n",
       "4              0              0  \n",
       "\n",
       "[5 rows x 82 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()\n",
    "# Veri kümesinin ilk 5 satırını gösterir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "69fa59b3-98bb-4473-96c6-da6182c36c0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df.drop('price', axis=1)\n",
    "# 'price' dışındaki tüm sütunları bağımsız değişken (X) olarak alır\n",
    "# Ev özellikleri burada yer alır (metrekare, oda sayısı vb.)\n",
    "\n",
    "y = df[['price']]\n",
    "# 'price' sütunu bağımlı değişken (Y) olarak alınır\n",
    "# Tahmin edilmek istenen değer: evin fiyatı"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "24f35553-e57b-42b1-abc4-d83ca0c3c2e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = scaler.fit_transform(x)\n",
    "# X verisi önce \"fit\" edilip (ortalama ve std hesaplanır)\n",
    "# ardından \"transform\" edilip ölçeklendirilir\n",
    "# Modelin daha hızlı ve stabil öğrenmesini sağlar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "01a16e4b-3603-4e61-9f53-b62a7d13484e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "# Boş bir yapay sinir ağı (ANN) modeli oluşturur\n",
    "\n",
    "model.add(Dense(80, activation='relu'))\n",
    "# İlk gizli katman: 80 nöron, aktivasyon: ReLU\n",
    "\n",
    "model.add(Dense(128, activation='relu'))\n",
    "# İkinci gizli katman: 128 nöron, daha yüksek öğrenme kapasitesi\n",
    "\n",
    "model.add(Dense(100, activation='relu'))\n",
    "# Üçüncü gizli katman: 100 nöron\n",
    "\n",
    "model.add(Dense(80, activation='relu'))\n",
    "# Dördüncü gizli katman: 80 nöron\n",
    "\n",
    "model.add(Dense(30, activation='relu'))\n",
    "# Beşinci gizli katman: 30 nöron (katmanlar küçülmeye başlıyor)\n",
    "\n",
    "model.add(Dense(8, activation='relu'))\n",
    "# Altıncı gizli katman: 8 nöron\n",
    "\n",
    "model.add(Dense(1))\n",
    "# Çıkış katmanı: 1 nöron\n",
    "# REGRESYON olduğundan *sigmoid veya softmax kullanılmaz*\n",
    "# Doğrudan sayısal (sürekli) bir değer üretir\n",
    "\n",
    "model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "# loss = MSE: regresyon problemlerinde kullanılan hata fonksiyonu\n",
    "# optimizer = adam: parametre güncellemesi için kullanılan yöntem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "2df41740-279c-4e8f-9e52-e04515c35932",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "# Veriyi eğitim ve test seti olarak ayırmak için kullanılır"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b673aea5-6ce4-488f-9422-82a521b698f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    x, y,\n",
    "    test_size=0.20,      # Verinin %20’si test için ayrılır\n",
    "    random_state=42      # Tekrar çalıştırıldığında aynı bölünmeyi sağlar (sabitlik)\n",
    ")\n",
    "# train_test_split: veriyi eğitim ve test seti olarak ikiye ayırır"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "2ed1dbf0-7c05-400d-bc02-acbef3d4a14f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/120\n",
      "\u001b[1m238/238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 132697767936.0000 - val_loss: 9943131136.0000\n",
      "Epoch 2/120\n",
      "\u001b[1m238/238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 8666306560.0000 - val_loss: 8703791104.0000\n",
      "Epoch 3/120\n",
      "\u001b[1m238/238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 8106599424.0000 - val_loss: 8425548288.0000\n",
      "Epoch 4/120\n",
      "\u001b[1m238/238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 7926225408.0000 - val_loss: 8301946880.0000\n",
      "Epoch 5/120\n",
      "\u001b[1m238/238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 7730360320.0000 - val_loss: 8187610624.0000\n",
      "Epoch 6/120\n",
      "\u001b[1m238/238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 7609027584.0000 - val_loss: 8174631936.0000\n",
      "Epoch 7/120\n",
      "\u001b[1m238/238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 7556698112.0000 - val_loss: 8225725440.0000\n",
      "Epoch 8/120\n",
      "\u001b[1m238/238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 7391961600.0000 - val_loss: 8211951616.0000\n",
      "Epoch 9/120\n",
      "\u001b[1m238/238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 7342803456.0000 - val_loss: 8081488384.0000\n",
      "Epoch 10/120\n",
      "\u001b[1m238/238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 7285623296.0000 - val_loss: 8062837248.0000\n",
      "Epoch 11/120\n",
      "\u001b[1m238/238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 7249266688.0000 - val_loss: 7945489408.0000\n",
      "Epoch 12/120\n",
      "\u001b[1m238/238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 7188910592.0000 - val_loss: 8290976768.0000\n",
      "Epoch 13/120\n",
      "\u001b[1m238/238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 7136030720.0000 - val_loss: 7910629888.0000\n",
      "Epoch 14/120\n",
      "\u001b[1m238/238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 7103869952.0000 - val_loss: 8000137216.0000\n",
      "Epoch 15/120\n",
      "\u001b[1m238/238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 7089110016.0000 - val_loss: 8004645888.0000\n",
      "Epoch 16/120\n",
      "\u001b[1m238/238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 7050969088.0000 - val_loss: 7911169024.0000\n",
      "Epoch 17/120\n",
      "\u001b[1m238/238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 7029463552.0000 - val_loss: 7879185920.0000\n",
      "Epoch 18/120\n",
      "\u001b[1m238/238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 6958480384.0000 - val_loss: 8029948928.0000\n",
      "Epoch 19/120\n",
      "\u001b[1m238/238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 6962437120.0000 - val_loss: 8073469440.0000\n",
      "Epoch 20/120\n",
      "\u001b[1m238/238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 6949307392.0000 - val_loss: 7937954816.0000\n",
      "Epoch 21/120\n",
      "\u001b[1m238/238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 6884754944.0000 - val_loss: 7939895808.0000\n",
      "Epoch 22/120\n",
      "\u001b[1m238/238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 6881569280.0000 - val_loss: 7826935296.0000\n",
      "Epoch 23/120\n",
      "\u001b[1m238/238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 6815749632.0000 - val_loss: 7870410240.0000\n",
      "Epoch 24/120\n",
      "\u001b[1m238/238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 6836101632.0000 - val_loss: 8019393536.0000\n",
      "Epoch 25/120\n",
      "\u001b[1m238/238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 6823954432.0000 - val_loss: 7894654464.0000\n",
      "Epoch 26/120\n",
      "\u001b[1m238/238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 6790286336.0000 - val_loss: 8026713088.0000\n",
      "Epoch 27/120\n",
      "\u001b[1m238/238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 6757340672.0000 - val_loss: 7840204288.0000\n",
      "Epoch 28/120\n",
      "\u001b[1m238/238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 6726341120.0000 - val_loss: 7846619648.0000\n",
      "Epoch 29/120\n",
      "\u001b[1m238/238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 6716852736.0000 - val_loss: 7784366592.0000\n",
      "Epoch 30/120\n",
      "\u001b[1m238/238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 6701220864.0000 - val_loss: 7727020032.0000\n",
      "Epoch 31/120\n",
      "\u001b[1m238/238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 6651599360.0000 - val_loss: 7759696896.0000\n",
      "Epoch 32/120\n",
      "\u001b[1m238/238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 6681589248.0000 - val_loss: 7844411904.0000\n",
      "Epoch 33/120\n",
      "\u001b[1m238/238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 6657951232.0000 - val_loss: 7759313920.0000\n",
      "Epoch 34/120\n",
      "\u001b[1m238/238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 6625652736.0000 - val_loss: 7810921472.0000\n",
      "Epoch 35/120\n",
      "\u001b[1m238/238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 6587813376.0000 - val_loss: 7888845312.0000\n",
      "Epoch 36/120\n",
      "\u001b[1m238/238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 6621344768.0000 - val_loss: 7871701504.0000\n",
      "Epoch 37/120\n",
      "\u001b[1m238/238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 6579483648.0000 - val_loss: 7757159424.0000\n",
      "Epoch 38/120\n",
      "\u001b[1m238/238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 6592860160.0000 - val_loss: 7783918080.0000\n",
      "Epoch 39/120\n",
      "\u001b[1m238/238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 6598643200.0000 - val_loss: 7778610176.0000\n",
      "Epoch 40/120\n",
      "\u001b[1m238/238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 6547333632.0000 - val_loss: 7696082432.0000\n",
      "Epoch 41/120\n",
      "\u001b[1m238/238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 6584335360.0000 - val_loss: 7713015296.0000\n",
      "Epoch 42/120\n",
      "\u001b[1m238/238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 6514333184.0000 - val_loss: 7771212800.0000\n",
      "Epoch 43/120\n",
      "\u001b[1m238/238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 6492745728.0000 - val_loss: 7735869952.0000\n",
      "Epoch 44/120\n",
      "\u001b[1m238/238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 6540628992.0000 - val_loss: 7686691328.0000\n",
      "Epoch 45/120\n",
      "\u001b[1m238/238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 6487875584.0000 - val_loss: 7741154816.0000\n",
      "Epoch 46/120\n",
      "\u001b[1m238/238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 6482271744.0000 - val_loss: 7787590656.0000\n",
      "Epoch 47/120\n",
      "\u001b[1m238/238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 6482406912.0000 - val_loss: 7690573824.0000\n",
      "Epoch 48/120\n",
      "\u001b[1m238/238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 6470052352.0000 - val_loss: 7784084992.0000\n",
      "Epoch 49/120\n",
      "\u001b[1m238/238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 6446178816.0000 - val_loss: 7754006016.0000\n",
      "Epoch 50/120\n",
      "\u001b[1m238/238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 6476152832.0000 - val_loss: 7721916416.0000\n",
      "Epoch 51/120\n",
      "\u001b[1m238/238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 6477553664.0000 - val_loss: 7750107136.0000\n",
      "Epoch 52/120\n",
      "\u001b[1m238/238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 6407219712.0000 - val_loss: 7931566080.0000\n",
      "Epoch 53/120\n",
      "\u001b[1m238/238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 6454245888.0000 - val_loss: 8342995968.0000\n",
      "Epoch 54/120\n",
      "\u001b[1m238/238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 6408866816.0000 - val_loss: 7752138240.0000\n",
      "Epoch 55/120\n",
      "\u001b[1m238/238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 6370602496.0000 - val_loss: 7834916864.0000\n",
      "Epoch 56/120\n",
      "\u001b[1m238/238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 6400114688.0000 - val_loss: 7954947072.0000\n",
      "Epoch 57/120\n",
      "\u001b[1m238/238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 6363606528.0000 - val_loss: 7644830720.0000\n",
      "Epoch 58/120\n",
      "\u001b[1m238/238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 6369467392.0000 - val_loss: 7777232896.0000\n",
      "Epoch 59/120\n",
      "\u001b[1m238/238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 6344202240.0000 - val_loss: 7797678080.0000\n",
      "Epoch 60/120\n",
      "\u001b[1m238/238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 6322684416.0000 - val_loss: 7826455552.0000\n",
      "Epoch 61/120\n",
      "\u001b[1m238/238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 6341200896.0000 - val_loss: 7847865344.0000\n",
      "Epoch 62/120\n",
      "\u001b[1m238/238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 6278652416.0000 - val_loss: 7694792704.0000\n",
      "Epoch 63/120\n",
      "\u001b[1m238/238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 6284942336.0000 - val_loss: 7779010560.0000\n",
      "Epoch 64/120\n",
      "\u001b[1m238/238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 6286283264.0000 - val_loss: 7681981952.0000\n",
      "Epoch 65/120\n",
      "\u001b[1m238/238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 6287971840.0000 - val_loss: 7831166976.0000\n",
      "Epoch 66/120\n",
      "\u001b[1m238/238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 6338690560.0000 - val_loss: 7764442624.0000\n",
      "Epoch 67/120\n",
      "\u001b[1m238/238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 6282755584.0000 - val_loss: 7727747072.0000\n",
      "Epoch 68/120\n",
      "\u001b[1m238/238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 6303598080.0000 - val_loss: 7765131776.0000\n",
      "Epoch 69/120\n",
      "\u001b[1m238/238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 6271635968.0000 - val_loss: 7705744384.0000\n",
      "Epoch 70/120\n",
      "\u001b[1m238/238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 6295712256.0000 - val_loss: 7891260928.0000\n",
      "Epoch 71/120\n",
      "\u001b[1m238/238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 6241252352.0000 - val_loss: 7743580160.0000\n",
      "Epoch 72/120\n",
      "\u001b[1m238/238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 6232285184.0000 - val_loss: 7704699392.0000\n",
      "Epoch 73/120\n",
      "\u001b[1m238/238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 6234942976.0000 - val_loss: 7780670464.0000\n",
      "Epoch 74/120\n",
      "\u001b[1m238/238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 6250900992.0000 - val_loss: 7773807616.0000\n",
      "Epoch 75/120\n",
      "\u001b[1m238/238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 6199771648.0000 - val_loss: 7719451136.0000\n",
      "Epoch 76/120\n",
      "\u001b[1m238/238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 6223514624.0000 - val_loss: 7750028800.0000\n",
      "Epoch 77/120\n",
      "\u001b[1m238/238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 6240586752.0000 - val_loss: 7752997888.0000\n",
      "Epoch 78/120\n",
      "\u001b[1m238/238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 6183844864.0000 - val_loss: 7697671168.0000\n",
      "Epoch 79/120\n",
      "\u001b[1m238/238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 6208798208.0000 - val_loss: 7728163840.0000\n",
      "Epoch 80/120\n",
      "\u001b[1m238/238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 6221137408.0000 - val_loss: 7753694208.0000\n",
      "Epoch 81/120\n",
      "\u001b[1m238/238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 6186066944.0000 - val_loss: 7754959360.0000\n",
      "Epoch 82/120\n",
      "\u001b[1m238/238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 6154185216.0000 - val_loss: 7876037120.0000\n",
      "Epoch 83/120\n",
      "\u001b[1m238/238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 6195483648.0000 - val_loss: 7837371392.0000\n",
      "Epoch 84/120\n",
      "\u001b[1m238/238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 6169550848.0000 - val_loss: 8051766272.0000\n",
      "Epoch 85/120\n",
      "\u001b[1m238/238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 6145349120.0000 - val_loss: 7757371904.0000\n",
      "Epoch 86/120\n",
      "\u001b[1m238/238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 6131476480.0000 - val_loss: 7722231808.0000\n",
      "Epoch 87/120\n",
      "\u001b[1m238/238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 6128212480.0000 - val_loss: 7823494144.0000\n",
      "Epoch 88/120\n",
      "\u001b[1m238/238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 6135378944.0000 - val_loss: 7778007552.0000\n",
      "Epoch 89/120\n",
      "\u001b[1m238/238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 6116468736.0000 - val_loss: 7804089344.0000\n",
      "Epoch 90/120\n",
      "\u001b[1m238/238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 6103105024.0000 - val_loss: 7966912000.0000\n",
      "Epoch 91/120\n",
      "\u001b[1m238/238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 6102536192.0000 - val_loss: 7813590016.0000\n",
      "Epoch 92/120\n",
      "\u001b[1m238/238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 6071111680.0000 - val_loss: 8363112448.0000\n",
      "Epoch 93/120\n",
      "\u001b[1m238/238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 6101267456.0000 - val_loss: 7819759104.0000\n",
      "Epoch 94/120\n",
      "\u001b[1m238/238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 6097425408.0000 - val_loss: 7776668160.0000\n",
      "Epoch 95/120\n",
      "\u001b[1m238/238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 6058857984.0000 - val_loss: 7774182912.0000\n",
      "Epoch 96/120\n",
      "\u001b[1m238/238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 6083191808.0000 - val_loss: 7773395456.0000\n",
      "Epoch 97/120\n",
      "\u001b[1m238/238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 6047968768.0000 - val_loss: 7819237888.0000\n",
      "Epoch 98/120\n",
      "\u001b[1m238/238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 6036471808.0000 - val_loss: 7871201280.0000\n",
      "Epoch 99/120\n",
      "\u001b[1m238/238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 6021291008.0000 - val_loss: 7855727104.0000\n",
      "Epoch 100/120\n",
      "\u001b[1m238/238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 6021483008.0000 - val_loss: 7825466368.0000\n",
      "Epoch 101/120\n",
      "\u001b[1m238/238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 6037308416.0000 - val_loss: 7805191168.0000\n",
      "Epoch 102/120\n",
      "\u001b[1m238/238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 5998900224.0000 - val_loss: 7825288192.0000\n",
      "Epoch 103/120\n",
      "\u001b[1m238/238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 6015558656.0000 - val_loss: 7881060352.0000\n",
      "Epoch 104/120\n",
      "\u001b[1m238/238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 5995596800.0000 - val_loss: 7798813184.0000\n",
      "Epoch 105/120\n",
      "\u001b[1m238/238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5995123712.0000 - val_loss: 7955448320.0000\n",
      "Epoch 106/120\n",
      "\u001b[1m238/238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 5986918400.0000 - val_loss: 7776122880.0000\n",
      "Epoch 107/120\n",
      "\u001b[1m238/238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 5978917888.0000 - val_loss: 7827063296.0000\n",
      "Epoch 108/120\n",
      "\u001b[1m238/238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 5974539264.0000 - val_loss: 7779579904.0000\n",
      "Epoch 109/120\n",
      "\u001b[1m238/238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 6033249792.0000 - val_loss: 7783096320.0000\n",
      "Epoch 110/120\n",
      "\u001b[1m238/238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 5942590464.0000 - val_loss: 7821287936.0000\n",
      "Epoch 111/120\n",
      "\u001b[1m238/238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 5954739200.0000 - val_loss: 7760482304.0000\n",
      "Epoch 112/120\n",
      "\u001b[1m238/238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 5923057664.0000 - val_loss: 8080829952.0000\n",
      "Epoch 113/120\n",
      "\u001b[1m238/238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 5951114240.0000 - val_loss: 7917113344.0000\n",
      "Epoch 114/120\n",
      "\u001b[1m238/238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 5890540544.0000 - val_loss: 7904274944.0000\n",
      "Epoch 115/120\n",
      "\u001b[1m238/238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 5903964160.0000 - val_loss: 7852385792.0000\n",
      "Epoch 116/120\n",
      "\u001b[1m238/238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 5917078528.0000 - val_loss: 7916400128.0000\n",
      "Epoch 117/120\n",
      "\u001b[1m238/238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 5894867968.0000 - val_loss: 7943671296.0000\n",
      "Epoch 118/120\n",
      "\u001b[1m238/238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 5924879360.0000 - val_loss: 7842409472.0000\n",
      "Epoch 119/120\n",
      "\u001b[1m238/238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 5915843584.0000 - val_loss: 7812334080.0000\n",
      "Epoch 120/120\n",
      "\u001b[1m238/238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 5888145408.0000 - val_loss: 7899352064.0000\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    x_train, y_train,\n",
    "    validation_data=(x_test, y_test),  # Test verisi doğrulama için kullanılıyor\n",
    "    batch_size=64,                     # Her adımda modele 64 örnek gösterilir\n",
    "    verbose=1,                         # Eğitim sürecini detaylı şekilde ekrana yazdırır\n",
    "    epochs=120                         # Model veri üzerinde 120 kez eğitilir\n",
    ")\n",
    "# fit: modeli eğiten fonksiyondur\n",
    "# Eğitim ve doğrulama (validation) performansları \"history\" değişkeni içinde saklanır"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "5316f273-569a-45f5-93e0-88d4ae285880",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step  \n"
     ]
    }
   ],
   "source": [
    "tahmin = model.predict(x_test)\n",
    "# Eğitilen modelin test verisi üzerindeki tahminlerini üretir\n",
    "# Regresyon olduğu için çıktılar ev fiyatı tahminleridir (sürekli sayısal değerler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "a24d7509-ed8f-4ed2-9de8-af1bb983d6d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "# R2 skorunu ve Ortalama Kare Hatasını (MSE) hesaplamak için metrikler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "330a3d6b-95ca-4633-a4d0-e71efdc991c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.845687747001648"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r2_score(y_test, tahmin)\n",
    "# R² skoru: modelin gerçek fiyatları ne kadar iyi açıkladığını gösterir\n",
    "# 1'e ne kadar yakınsa model o kadar başarılıdır"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "6cd5b14d-a140-4fdf-a860-a9d52c71f810",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "88878.29917364531"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error(y_test, tahmin)**0.5\n",
    "# RMSE (Root Mean Squared Error): Hata miktarının kök ortalama kare değeri\n",
    "# Hata ne kadar düşükse model o kadar iyidir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "61431190-1eff-459d-96a3-69ee5b4019b2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x143edff6350>]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['loss'])\n",
    "# Eğitim sürecindeki 'loss' (MSE) değerlerinin epoch'lara göre değişimini çizer\n",
    "# Eğri aşağı doğru gidiyorsa modelin öğrenmeye devam ettiği anlamına gelir"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1efb1f87-7bd8-46c1-99af-354ca6d71202",
   "metadata": {},
   "source": [
    "#### _Early Stopping - Önceden Dur_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "167fbee9-4b32-464a-bc6d-91273b8a3af9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel('cars.xls')\n",
    "# Excel formatındaki veri dosyasını okur ve DataFrame’e aktarır"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "d4845112-44c2-4189-8af8-5a1f4912f32b",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df.drop('Price', axis=1)\n",
    "# 'Price' dışındaki tüm sütunlar bağımsız değişkenler (X) olur\n",
    "\n",
    "y = df[['Price']]\n",
    "# Tahmin edilecek değer olan 'Price' bağımlı değişken (Y) olarak alınır"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "90378955-0cd8-43d5-9e73-2c2542fbd0b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Mileage</th>\n",
       "      <th>Make</th>\n",
       "      <th>Model</th>\n",
       "      <th>Trim</th>\n",
       "      <th>Type</th>\n",
       "      <th>Cylinder</th>\n",
       "      <th>Liter</th>\n",
       "      <th>Doors</th>\n",
       "      <th>Cruise</th>\n",
       "      <th>Sound</th>\n",
       "      <th>Leather</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8221</td>\n",
       "      <td>Buick</td>\n",
       "      <td>Century</td>\n",
       "      <td>Sedan 4D</td>\n",
       "      <td>Sedan</td>\n",
       "      <td>6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9135</td>\n",
       "      <td>Buick</td>\n",
       "      <td>Century</td>\n",
       "      <td>Sedan 4D</td>\n",
       "      <td>Sedan</td>\n",
       "      <td>6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>13196</td>\n",
       "      <td>Buick</td>\n",
       "      <td>Century</td>\n",
       "      <td>Sedan 4D</td>\n",
       "      <td>Sedan</td>\n",
       "      <td>6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>16342</td>\n",
       "      <td>Buick</td>\n",
       "      <td>Century</td>\n",
       "      <td>Sedan 4D</td>\n",
       "      <td>Sedan</td>\n",
       "      <td>6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>19832</td>\n",
       "      <td>Buick</td>\n",
       "      <td>Century</td>\n",
       "      <td>Sedan 4D</td>\n",
       "      <td>Sedan</td>\n",
       "      <td>6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Mileage   Make    Model      Trim   Type  Cylinder  Liter  Doors  Cruise  \\\n",
       "0     8221  Buick  Century  Sedan 4D  Sedan         6    3.1      4       1   \n",
       "1     9135  Buick  Century  Sedan 4D  Sedan         6    3.1      4       1   \n",
       "2    13196  Buick  Century  Sedan 4D  Sedan         6    3.1      4       1   \n",
       "3    16342  Buick  Century  Sedan 4D  Sedan         6    3.1      4       1   \n",
       "4    19832  Buick  Century  Sedan 4D  Sedan         6    3.1      4       1   \n",
       "\n",
       "   Sound  Leather  \n",
       "0      1        1  \n",
       "1      1        0  \n",
       "2      1        0  \n",
       "3      0        0  \n",
       "4      0        1  "
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.head()\n",
    "# x değişkenlerinin ilk 5 satırını görüntüler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "80274022-e714-4c88-8269-46dc835705ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = pd.get_dummies(x, drop_first=True)\n",
    "# Kategorik değişkenleri dummy (0-1) değişkenlere dönüştürür\n",
    "# drop_first=True → multicollinearity (sahte bağıntı) oluşmasını engeller"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "9fcee927-fb90-4c0b-90b9-46f3167b7772",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = scaler.fit_transform(x)\n",
    "# X verisi önce \"fit\" edilip (ortalama ve std hesaplanır)\n",
    "# ardından \"transform\" edilip ölçeklendirilir\n",
    "# Modelin daha hızlı ve stabil öğrenmesini sağlar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "853c50a9-dde1-4246-826e-a8a22ea8211e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "# Boş bir yapay sinir ağı modeli oluşturulur\n",
    "\n",
    "model.add(Dense(64, activation='relu'))\n",
    "# İlk gizli katman: 64 nöron, ReLU aktivasyonu\n",
    "\n",
    "model.add(Dense(128, activation='relu'))\n",
    "# İkinci gizli katman: 128 nöron, öğrenme kapasitesini artırır\n",
    "\n",
    "model.add(Dense(256, activation='relu'))\n",
    "# Üçüncü gizli katman: 256 nöron, modelin en geniş katmanı\n",
    "\n",
    "model.add(Dense(128, activation='relu'))\n",
    "# Dördüncü gizli katman: 128 nöron, daralmaya başlıyor\n",
    "\n",
    "model.add(Dense(64, activation='relu'))\n",
    "# Beşinci gizli katman: 64 nöron\n",
    "\n",
    "model.add(Dense(32, activation='relu'))\n",
    "# Altıncı gizli katman: 32 nöron\n",
    "\n",
    "model.add(Dense(1))\n",
    "# Çıkış katmanı: 1 nöron (regresyon problemi olduğu için aktivasyon kullanılmaz)\n",
    "\n",
    "model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "# loss = MSE → regresyon için uygun hata fonksiyonu\n",
    "# optimizer = adam → ağırlıkları güncellemek için kullanılan optimizasyon algoritması"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "282a385b-678c-4ab7-90c4-0b9efd07a736",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "# EarlyStopping: Eğitim sırasında belirli bir metrik iyileşmeyi durdurduğunda\n",
    "# modeli otomatik olarak durduran callback yapısıdır.\n",
    "# Overfitting'i engellemek ve gereksiz yere uzun eğitim süresini azaltmak için kullanılır."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "2fade47a-524e-43bf-8666-d283c8f117db",
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stop = EarlyStopping(\n",
    "    monitor='val_loss',  # İzlenen metrik: doğrulama kaybı (validation loss)\n",
    "    patience=10          # 10 epoch boyunca iyileşme olmazsa eğitim durur\n",
    ")\n",
    "# EarlyStopping overfitting'i önler ve gereksiz uzun eğitim süresini kısaltır"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "124c1ad6-6988-465d-9ce4-50bedc009f38",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/130\n",
      "\u001b[1m476/476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 53259542528.0000 - val_loss: 9275729920.0000\n",
      "Epoch 2/130\n",
      "\u001b[1m476/476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 8287040000.0000 - val_loss: 8753887232.0000\n",
      "Epoch 3/130\n",
      "\u001b[1m476/476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 7920232448.0000 - val_loss: 8315781120.0000\n",
      "Epoch 4/130\n",
      "\u001b[1m476/476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 7743825920.0000 - val_loss: 8447545344.0000\n",
      "Epoch 5/130\n",
      "\u001b[1m476/476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 7598310400.0000 - val_loss: 8160165376.0000\n",
      "Epoch 6/130\n",
      "\u001b[1m476/476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 7465452544.0000 - val_loss: 8288015872.0000\n",
      "Epoch 7/130\n",
      "\u001b[1m476/476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 7349441536.0000 - val_loss: 8095821312.0000\n",
      "Epoch 8/130\n",
      "\u001b[1m476/476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 7287433728.0000 - val_loss: 8221070336.0000\n",
      "Epoch 9/130\n",
      "\u001b[1m476/476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 7273738240.0000 - val_loss: 7926161920.0000\n",
      "Epoch 10/130\n",
      "\u001b[1m476/476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 7134855680.0000 - val_loss: 8455653888.0000\n",
      "Epoch 11/130\n",
      "\u001b[1m476/476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 7192269824.0000 - val_loss: 8282528768.0000\n",
      "Epoch 12/130\n",
      "\u001b[1m476/476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 7131696640.0000 - val_loss: 8193457664.0000\n",
      "Epoch 13/130\n",
      "\u001b[1m476/476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 7093976064.0000 - val_loss: 7926779904.0000\n",
      "Epoch 14/130\n",
      "\u001b[1m476/476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 7011522560.0000 - val_loss: 8269026816.0000\n",
      "Epoch 15/130\n",
      "\u001b[1m476/476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 6952993792.0000 - val_loss: 8253262336.0000\n",
      "Epoch 16/130\n",
      "\u001b[1m476/476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 6962540032.0000 - val_loss: 8587832832.0000\n",
      "Epoch 17/130\n",
      "\u001b[1m476/476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 6942796800.0000 - val_loss: 8047982592.0000\n",
      "Epoch 18/130\n",
      "\u001b[1m476/476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 6936065024.0000 - val_loss: 8093383680.0000\n",
      "Epoch 19/130\n",
      "\u001b[1m476/476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 6852306432.0000 - val_loss: 7897989120.0000\n",
      "Epoch 20/130\n",
      "\u001b[1m476/476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 6799403008.0000 - val_loss: 8114758144.0000\n",
      "Epoch 21/130\n",
      "\u001b[1m476/476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 6850772480.0000 - val_loss: 8003493888.0000\n",
      "Epoch 22/130\n",
      "\u001b[1m476/476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 6812570112.0000 - val_loss: 7968055296.0000\n",
      "Epoch 23/130\n",
      "\u001b[1m476/476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 6803066880.0000 - val_loss: 8082158080.0000\n",
      "Epoch 24/130\n",
      "\u001b[1m476/476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 6734270464.0000 - val_loss: 8069232640.0000\n",
      "Epoch 25/130\n",
      "\u001b[1m476/476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 6699088384.0000 - val_loss: 8278793216.0000\n",
      "Epoch 26/130\n",
      "\u001b[1m476/476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 6697908224.0000 - val_loss: 8150318080.0000\n",
      "Epoch 27/130\n",
      "\u001b[1m476/476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 6828631040.0000 - val_loss: 8040071168.0000\n",
      "Epoch 28/130\n",
      "\u001b[1m476/476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 6669123584.0000 - val_loss: 8202458112.0000\n",
      "Epoch 29/130\n",
      "\u001b[1m476/476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 6693788672.0000 - val_loss: 7882432512.0000\n",
      "Epoch 30/130\n",
      "\u001b[1m476/476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 6707216896.0000 - val_loss: 8014436864.0000\n",
      "Epoch 31/130\n",
      "\u001b[1m476/476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 6594156032.0000 - val_loss: 7956860416.0000\n",
      "Epoch 32/130\n",
      "\u001b[1m476/476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 6622665728.0000 - val_loss: 8021445632.0000\n",
      "Epoch 33/130\n",
      "\u001b[1m476/476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 6631102464.0000 - val_loss: 7898353152.0000\n",
      "Epoch 34/130\n",
      "\u001b[1m476/476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 6637308416.0000 - val_loss: 8802494464.0000\n",
      "Epoch 35/130\n",
      "\u001b[1m476/476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 6712232960.0000 - val_loss: 7974082560.0000\n",
      "Epoch 36/130\n",
      "\u001b[1m476/476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 6596322816.0000 - val_loss: 8079804416.0000\n",
      "Epoch 37/130\n",
      "\u001b[1m476/476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 6575117824.0000 - val_loss: 7999347200.0000\n",
      "Epoch 38/130\n",
      "\u001b[1m476/476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 6580683264.0000 - val_loss: 8033417728.0000\n",
      "Epoch 39/130\n",
      "\u001b[1m476/476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 6554611200.0000 - val_loss: 7881094144.0000\n",
      "Epoch 40/130\n",
      "\u001b[1m476/476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 6549307904.0000 - val_loss: 7893751808.0000\n",
      "Epoch 41/130\n",
      "\u001b[1m476/476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 6510564864.0000 - val_loss: 7993989632.0000\n",
      "Epoch 42/130\n",
      "\u001b[1m476/476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 6637447168.0000 - val_loss: 8097894912.0000\n",
      "Epoch 43/130\n",
      "\u001b[1m476/476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 6481595904.0000 - val_loss: 8346036224.0000\n",
      "Epoch 44/130\n",
      "\u001b[1m476/476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 6502504960.0000 - val_loss: 7924637184.0000\n",
      "Epoch 45/130\n",
      "\u001b[1m476/476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 6489583104.0000 - val_loss: 7996340736.0000\n",
      "Epoch 46/130\n",
      "\u001b[1m476/476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 6573128192.0000 - val_loss: 7930052096.0000\n",
      "Epoch 47/130\n",
      "\u001b[1m476/476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 6474490880.0000 - val_loss: 8089219072.0000\n",
      "Epoch 48/130\n",
      "\u001b[1m476/476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 6524806656.0000 - val_loss: 8783622144.0000\n",
      "Epoch 49/130\n",
      "\u001b[1m476/476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 6466944512.0000 - val_loss: 8066540032.0000\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    x_train, y_train,\n",
    "    validation_data=(x_test, y_test),  # Test verisi doğrulama için kullanılıyor\n",
    "    epochs=130,                        # Maksimum eğitim sayısı\n",
    "    batch_size=32,                     # Her adımda 32 örnek işlenir\n",
    "    callbacks=[early_stop],            # EarlyStopping aktif: val_loss iyileşmezse durdurur\n",
    "    verbose=1                          # Eğitim bilgilerini ekrana yazdırır\n",
    ")\n",
    "# EarlyStopping sayesinde model gereksiz yere uzun süre eğitilmez\n",
    "# En iyi validation loss değerinin olduğu epoch’ta eğitim sonlanır"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "03aea036-2fb6-4950-aac1-0a45e15e5023",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step  \n"
     ]
    }
   ],
   "source": [
    "tahmin = model.predict(x_test)\n",
    "# Eğitilen modelin test verisi üzerindeki tahminlerini üretir\n",
    "# Regresyon problemi olduğu için çıktı, aracın fiyat tahminidir (sürekli sayısal değer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "6d13ebb7-33c1-43f8-9ae1-e65a33e61473",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8263247013092041"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r2_score(tahmin, y_test)\n",
    "# Yanlış kullanım! r2_score fonksiyonu önce gerçek değerleri (y_true),\n",
    "# sonra tahmin değerlerini (y_pred) ister.\n",
    "# Bu nedenle doğru kullanım aşağıdaki gibi olmalıdır:\n",
    "# r2_score(y_test, tahmin)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "601f0723-b4f6-4698-82bc-dd469b479293",
   "metadata": {},
   "source": [
    "#### _Torch_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "529f8283-f6d1-496f-9f9f-b29d5cdc2534",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "10ef11b8-2c05-44e8-8a92-05f1782006cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PyTorch kütüphanesini yüklemek için kullanılan terminal komutu\n",
    "# Derin öğrenme modelleri ve tensor işlemleri için gereklidir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "db360512-2e0a-4604-bfae-c3e38b65a957",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/130] Loss: 1077168128.0000 | Val Loss: 505517472.0000\n",
      "Epoch [2/130] Loss: 206119472.0000 | Val Loss: 481048992.0000\n",
      "Epoch [3/130] Loss: 15093457.0000 | Val Loss: 56956552.0000\n",
      "Epoch [4/130] Loss: 7486129.5000 | Val Loss: 17512196.0000\n",
      "Epoch [5/130] Loss: 1816849.3750 | Val Loss: 2826022.5000\n",
      "Epoch [6/130] Loss: 242161.9375 | Val Loss: 1601360.3750\n",
      "Epoch [7/130] Loss: 950148.0000 | Val Loss: 1055032.0000\n",
      "Epoch [8/130] Loss: 1033175.5000 | Val Loss: 816629.0000\n",
      "Epoch [9/130] Loss: 1420885.6250 | Val Loss: 739178.0625\n",
      "Epoch [10/130] Loss: 742661.1875 | Val Loss: 689806.8750\n",
      "Epoch [11/130] Loss: 761284.1875 | Val Loss: 638503.5625\n",
      "Epoch [12/130] Loss: 689513.1250 | Val Loss: 603953.3125\n",
      "Epoch [13/130] Loss: 514922.6250 | Val Loss: 573252.1875\n",
      "Epoch [14/130] Loss: 5600.0171 | Val Loss: 612740.2500\n",
      "Epoch [15/130] Loss: 605771.2500 | Val Loss: 556108.4375\n",
      "Epoch [16/130] Loss: 730104.5625 | Val Loss: 546642.3750\n",
      "Epoch [17/130] Loss: 1434847.0000 | Val Loss: 591025.4375\n",
      "Epoch [18/130] Loss: 244673.1250 | Val Loss: 548557.4375\n",
      "Epoch [19/130] Loss: 1274046.6250 | Val Loss: 544460.8125\n",
      "Epoch [20/130] Loss: 253842.4844 | Val Loss: 698063.6875\n",
      "Epoch [21/130] Loss: 301365.3438 | Val Loss: 550395.7500\n",
      "Epoch [22/130] Loss: 124836.7578 | Val Loss: 508766.3750\n",
      "Epoch [23/130] Loss: 235644.6094 | Val Loss: 528248.6250\n",
      "Epoch [24/130] Loss: 143879.0781 | Val Loss: 633396.6250\n",
      "Epoch [25/130] Loss: 56154.7773 | Val Loss: 536731.2500\n",
      "Epoch [26/130] Loss: 473666.7500 | Val Loss: 512142.8125\n",
      "Epoch [27/130] Loss: 1369357.8750 | Val Loss: 513055.1562\n",
      "Epoch [28/130] Loss: 1937585.1250 | Val Loss: 648941.9375\n",
      "Epoch [29/130] Loss: 182364.0000 | Val Loss: 571783.3750\n",
      "Epoch [30/130] Loss: 70125.2891 | Val Loss: 486928.8438\n",
      "Epoch [31/130] Loss: 938597.5625 | Val Loss: 480290.1875\n",
      "Epoch [32/130] Loss: 98126.7812 | Val Loss: 518198.4062\n",
      "Epoch [33/130] Loss: 682863.2500 | Val Loss: 470147.8750\n",
      "Epoch [34/130] Loss: 103490.0859 | Val Loss: 534883.2500\n",
      "Epoch [35/130] Loss: 211080.7656 | Val Loss: 472344.7812\n",
      "Epoch [36/130] Loss: 124069.8516 | Val Loss: 468231.3125\n",
      "Epoch [37/130] Loss: 192176.9375 | Val Loss: 451685.2188\n",
      "Epoch [38/130] Loss: 254742.6094 | Val Loss: 493009.8750\n",
      "Epoch [39/130] Loss: 426591.3438 | Val Loss: 441936.0625\n",
      "Epoch [40/130] Loss: 125446.1641 | Val Loss: 492381.9688\n",
      "Epoch [41/130] Loss: 348499.1250 | Val Loss: 507653.4688\n",
      "Epoch [42/130] Loss: 1299456.5000 | Val Loss: 527028.7500\n",
      "Epoch [43/130] Loss: 2000695.6250 | Val Loss: 435409.4062\n",
      "Epoch [44/130] Loss: 235127.9844 | Val Loss: 536382.1250\n",
      "Epoch [45/130] Loss: 348450.4062 | Val Loss: 463218.5938\n",
      "Epoch [46/130] Loss: 1126136.6250 | Val Loss: 461029.6250\n",
      "Epoch [47/130] Loss: 44628.9883 | Val Loss: 458069.1562\n",
      "Epoch [48/130] Loss: 975835.5000 | Val Loss: 468081.9375\n",
      "Epoch [49/130] Loss: 1786981.0000 | Val Loss: 616624.8750\n",
      "Epoch [50/130] Loss: 61356.0508 | Val Loss: 575265.5000\n",
      "Epoch [51/130] Loss: 177300.8125 | Val Loss: 536906.8125\n",
      "Epoch [52/130] Loss: 193047.2031 | Val Loss: 490460.8125\n",
      "Epoch [53/130] Loss: 154814.8906 | Val Loss: 449141.2188\n",
      "Early stopping triggered.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# df: Price içeren araç veri seti\n",
    "\n",
    "x = df.drop('Price', axis=1)\n",
    "# Bağımsız değişkenler (araç özellikleri)\n",
    "\n",
    "y = df[['Price']]\n",
    "# Bağımlı değişken: Tahmin edilmek istenen fiyat\n",
    "\n",
    "x = pd.get_dummies(x, drop_first=True)\n",
    "# Kategorik değişkenleri dummy değişkenlere dönüştürür\n",
    "# drop_first=True → multicollinearity riskini azaltır\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    x, y, test_size=0.2, random_state=42\n",
    ")\n",
    "# Veriyi %80 eğitim, %20 test olarak böler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "x_train = scaler.fit_transform(x_train)\n",
    "x_test = scaler.transform(x_test)\n",
    "# Sayısal verileri ölçeklendirir (ortalama=0, std=1)\n",
    "\n",
    "# PyTorch tensörlerine dönüştürme\n",
    "x_train_tensor = torch.tensor(x_train, dtype=torch.float32)\n",
    "x_test_tensor = torch.tensor(x_test, dtype=torch.float32)\n",
    "y_train_tensor = torch.tensor(y_train.values, dtype=torch.float32)\n",
    "y_test_tensor = torch.tensor(y_test.values, dtype=torch.float32)\n",
    "\n",
    "# PyTorch Yapay Sinir Ağı Modeli\n",
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NeuralNetwork, self).__init__()\n",
    "        self.fc1 = nn.Linear(x_train.shape[1], 64)\n",
    "        # Giriş katmanı → 64 nöron\n",
    "        self.fc2 = nn.Linear(64, 128)\n",
    "        self.fc3 = nn.Linear(128, 256)\n",
    "        self.fc4 = nn.Linear(256, 128)\n",
    "        self.fc5 = nn.Linear(128, 64)\n",
    "        self.fc6 = nn.Linear(64, 32)\n",
    "        self.fc7 = nn.Linear(32, 1)\n",
    "        # Çıkış katmanı → 1 nöron (regresyon)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = torch.relu(self.fc2(x))\n",
    "        x = torch.relu(self.fc3(x))\n",
    "        x = torch.relu(self.fc4(x))\n",
    "        x = torch.relu(self.fc5(x))\n",
    "        x = torch.relu(self.fc6(x))\n",
    "        return self.fc7(x)\n",
    "        # Son katmanda aktivasyon yok → regresyon için doğru kullanım\n",
    "\n",
    "model = NeuralNetwork()\n",
    "criterion = nn.MSELoss()\n",
    "# Regresyon için MSE kayıp fonksiyonu\n",
    "\n",
    "optimizer = optim.Adam(model.parameters())\n",
    "# Adam optimizasyon algoritması\n",
    "\n",
    "num_epochs = 130\n",
    "batch_size = 32\n",
    "\n",
    "# DataLoader: batch halinde eğitim için gerekli yapı\n",
    "train_data = torch.utils.data.TensorDataset(x_train_tensor, y_train_tensor)\n",
    "train_loader = torch.utils.data.DataLoader(train_data, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "# Early Stopping için takip değişkenleri\n",
    "best_loss = float('inf')\n",
    "patience = 10\n",
    "patience_counter = 0\n",
    "\n",
    "# Eğitim döngüsü\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    for batch_x, batch_y in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(batch_x)\n",
    "        loss = criterion(outputs, batch_y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    # Doğrulama (Validation)\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        val_outputs = model(x_test_tensor)\n",
    "        val_loss = criterion(val_outputs, y_test_tensor)\n",
    "\n",
    "    print(f'Epoch [{epoch+1}/{num_epochs}] '\n",
    "          f'Loss: {loss.item():.4f} | Val Loss: {val_loss.item():.4f}')\n",
    "\n",
    "    # Early Stopping kontrolü\n",
    "    if val_loss < best_loss:\n",
    "        best_loss = val_loss\n",
    "        patience_counter = 0\n",
    "    else:\n",
    "        patience_counter += 1\n",
    "        if patience_counter >= patience:\n",
    "            print(\"Early stopping triggered.\")\n",
    "            break\n",
    "# Bu eğitim döngüsü hem modeli eğitir hem de validation loss iyileşmediğinde durdurur"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
